{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgbHLsEwNH6p",
        "outputId": "57e7dca2-e924-4c13-9462-4cbc0b7f6a4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49979, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# === Cell 1: Setup & Load ===\n",
        "# If you're in Colab: upload files: corpus.txt and test.txt\n",
        "# from google.colab import files\n",
        "# files.upload()   # then select corpus.txt and test.txt\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "CORPUS_PATH = 'corpus.txt'   # adjust if needed, e.g., 'data/corpus.txt'\n",
        "TEST_PATH   = 'test.txt'     # adjust if needed, e.g., 'data/test.txt'\n",
        "\n",
        "def load_words(path: str):\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"Missing file: {path}\")\n",
        "    return [w.strip().lower() for w in p.read_text().splitlines()\n",
        "            if w.strip() and w.strip().isalpha()]\n",
        "\n",
        "corpus_words = load_words(CORPUS_PATH)\n",
        "test_words   = load_words(TEST_PATH)\n",
        "len(corpus_words), len(test_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZZC_Jnz8NK70"
      },
      "outputs": [],
      "source": [
        "# === Cell 2: Utilities ===\n",
        "ALPHABET = 'abcdefghijklmnopqrstuvwxyz'\n",
        "ALPHABET_SET = set(ALPHABET)\n",
        "\n",
        "def matches_mask(word: str, mask: str, guessed_wrong: set[str]) -> bool:\n",
        "    \"\"\"Returns True if `word` is consistent with `mask` and `guessed_wrong` letters.\"\"\"\n",
        "    if len(word) != len(mask):\n",
        "        return False\n",
        "    if any(gw in word for gw in guessed_wrong):\n",
        "        return False\n",
        "    for wc, mc in zip(word, mask):\n",
        "        if mc == '_':\n",
        "            # blank: can't be a wrong letter (already covered above)\n",
        "            continue\n",
        "        if wc != mc:\n",
        "            return False\n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bIXI3I-1NSAz"
      },
      "outputs": [],
      "source": [
        "# === Cell 3: CFP Oracle (Option A) ===\n",
        "from collections import Counter, defaultdict\n",
        "from typing import List, Set, Dict\n",
        "\n",
        "class CandidateFilterOracle:\n",
        "    \"\"\"\n",
        "    Fast, strong baseline:\n",
        "    - Filters corpus by (mask, wrong guesses)\n",
        "    - Tallies letters in blank positions across candidates\n",
        "    - Returns P(letter) over unguessed letters\n",
        "    \"\"\"\n",
        "    def __init__(self, words: List[str]):\n",
        "        self.by_len = defaultdict(list)\n",
        "        for w in words:\n",
        "            w = w.strip().lower()\n",
        "            if w and all('a' <= c <= 'z' for c in w):\n",
        "                self.by_len[len(w)].append(w)\n",
        "\n",
        "    def letter_posteriors(self, mask: str, guessed: Set[str]) -> Dict[str, float]:\n",
        "        L = len(mask)\n",
        "        pool = self.by_len.get(L, [])\n",
        "        guessed_wrong = {g for g in guessed if g not in mask}\n",
        "        cands = [w for w in pool if matches_mask(w, mask, guessed_wrong)]\n",
        "        if not cands:\n",
        "            rem = [c for c in ALPHABET if c not in guessed]\n",
        "            return {c: 1.0/len(rem) for c in rem} if rem else {c: 0.0 for c in ALPHABET}\n",
        "\n",
        "        scores = Counter()\n",
        "        blanks = [i for i,ch in enumerate(mask) if ch == '_']\n",
        "        for w in cands:\n",
        "            for i in blanks:\n",
        "                scores[w[i]] += 1\n",
        "\n",
        "        dist = {c: float(scores[c]) for c in ALPHABET if c not in guessed}\n",
        "        s = sum(dist.values())\n",
        "        if s <= 0:\n",
        "            rem = [c for c in ALPHABET if c not in guessed]\n",
        "            return {c: 1.0/len(rem) for c in rem} if rem else {c: 0.0 for c in ALPHABET}\n",
        "        for c in dist:\n",
        "            dist[c] /= s\n",
        "        return dist\n",
        "\n",
        "# Instantiate right now:\n",
        "cfp = CandidateFilterOracle(corpus_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UmIWMeaNUFr",
        "outputId": "e41c0433-3596-413b-ff8c-165463a80a6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'top1': 0.43150742387383606,\n",
              " 'top3': 0.6685680731482259,\n",
              " 'top5': 0.7844979448032883,\n",
              " 'cases': 11921}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# === Cell 4: HMM-only evaluation helpers ===\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_oracle_topk(oracle, words: list[str],\n",
        "                         revelation_levels=(0.2, 0.4, 0.6),\n",
        "                         tests_per_word=2):\n",
        "    \"\"\"\n",
        "    For each word, reveal some letters, ask oracle for letter probs,\n",
        "    and check if the top-k prediction hits any actually-missing letter.\n",
        "    \"\"\"\n",
        "    top1 = top3 = top5 = total = 0\n",
        "\n",
        "    rng = np.random.default_rng(0)\n",
        "    for w in words:\n",
        "        L = len(w)\n",
        "        for r in revelation_levels:\n",
        "            for _ in range(tests_per_word):\n",
        "                mask = ['_'] * L\n",
        "                # reveal ceil(r*L) positions\n",
        "                k = max(1, int(np.ceil(r * L)))\n",
        "                idx = rng.choice(L, size=k, replace=False)\n",
        "                for i in idx:\n",
        "                    mask[i] = w[i]\n",
        "                guessed = set(ch for ch in mask if ch != '_')\n",
        "                actual_missing = set(w) - guessed\n",
        "                if not actual_missing:\n",
        "                    continue\n",
        "\n",
        "                probs = oracle.letter_posteriors(''.join(mask), guessed)\n",
        "                if not probs:\n",
        "                    continue\n",
        "                ranked = sorted(probs.items(), key=lambda kv: kv[1], reverse=True)\n",
        "                pred_letters = [c for c,_ in ranked]\n",
        "\n",
        "                total += 1\n",
        "                if pred_letters[0] in actual_missing: top1 += 1\n",
        "                if any(c in actual_missing for c in pred_letters[:3]): top3 += 1\n",
        "                if any(c in actual_missing for c in pred_letters[:5]): top5 += 1\n",
        "\n",
        "    return {\n",
        "        \"top1\": top1/total if total else 0.0,\n",
        "        \"top3\": top3/total if total else 0.0,\n",
        "        \"top5\": top5/total if total else 0.0,\n",
        "        \"cases\": total\n",
        "    }\n",
        "\n",
        "# Evaluate CFP on test set:\n",
        "cfp_stats = evaluate_oracle_topk(cfp, test_words, revelation_levels=(0.2,0.4,0.6), tests_per_word=2)\n",
        "cfp_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_MMPOeIaswG",
        "outputId": "a94660ee-8c14-46ae-8590-1570d7ab4d82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Cell 4.9: preparing Role-B classes (no retraining on import)\n",
            "   - Converting rl.ipynb → rl.py …\n",
            "   - Sanitizing rl.py so it does NOT auto-train on import …\n",
            "   - Importing rl.py …\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Loaded Role-B pack. Use train_qlearning(), train_dqn(), and eval_agent().\n",
            ">> Loaded Role-B classes:\n",
            "   - HangmanEnv     : <class 'rl.HangmanEnv'>\n",
            "   - TabularQAgent  : <class 'rl.TabularQAgent'>\n",
            "   - DQNAgent       : <class 'rl.DQNAgent'>\n",
            "   - DQNConfig      : <class 'rl.DQNConfig'>\n",
            "   - ALPHABET len   : 26\n",
            ">> Cell 4.9 ready. Now run Cell 5 (evaluation).\n"
          ]
        }
      ],
      "source": [
        "# === Cell 4.9 (fixed & sanitized): Wire Role-B (rl.ipynb) without retraining on import ===\n",
        "import os, importlib.util, re, io\n",
        "\n",
        "print(\">> Cell 4.9: preparing Role-B classes (no retraining on import)\")\n",
        "\n",
        "# 1) Convert rl.ipynb -> rl.py if present\n",
        "if os.path.exists('rl.ipynb'):\n",
        "    print(\"   - Converting rl.ipynb → rl.py …\")\n",
        "    !jupyter nbconvert --to python rl.ipynb --output rl.py >/dev/null 2>&1\n",
        "\n",
        "if not os.path.exists('rl.py'):\n",
        "    print(\"   [WARN] rl.py not found; ensure rl.ipynb is in this folder.\")\n",
        "else:\n",
        "    print(\"   - Sanitizing rl.py so it does NOT auto-train on import …\")\n",
        "    src = open('rl.py', 'r', encoding='utf-8').read()\n",
        "    lines = src.splitlines()\n",
        "\n",
        "    # (a) Move any \"from __future__\" lines to the very top\n",
        "    future = [ln for ln in lines if ln.strip().startswith('from __future__')]\n",
        "    body   = [ln for ln in lines if not ln.strip().startswith('from __future__')]\n",
        "    sanitized = []\n",
        "    if future:\n",
        "        sanitized.extend(future + [\"\"])  # keep a blank line after futures\n",
        "    sanitized.extend(body)\n",
        "\n",
        "    text = \"\\n\".join(sanitized)\n",
        "\n",
        "    # (b) Comment out any top-level calls that would start training/eval on import\n",
        "    # We’ll conservatively comment lines that start with those call names.\n",
        "    patterns = [\n",
        "        r'^\\s*train_qlearning\\s*\\(',\n",
        "        r'^\\s*train_dqn\\s*\\(',\n",
        "        r'^\\s*eval_agent\\s*\\(',\n",
        "    ]\n",
        "    def comment_calls(code: str) -> str:\n",
        "        buf = io.StringIO()\n",
        "        for ln in code.splitlines():\n",
        "            if any(re.match(pat, ln) for pat in patterns):\n",
        "                buf.write(\"# [SANITIZED ON IMPORT] \" + ln + \"\\n\")\n",
        "            else:\n",
        "                buf.write(ln + \"\\n\")\n",
        "        return buf.getvalue()\n",
        "\n",
        "    text = comment_calls(text)\n",
        "\n",
        "    # (c) If there is a __main__ block, comment it out entirely to avoid demo runs\n",
        "    text = re.sub(\n",
        "        r'(?ms)^\\s*if\\s+__name__\\s*==\\s*[\\'\"]__main__[\\'\"]\\s*:\\s*\\n.*$',\n",
        "        \"# [SANITIZED] __main__ block removed to prevent auto-execution on import\\n\",\n",
        "        text\n",
        "    )\n",
        "\n",
        "    with open('rl.py', 'w', encoding='utf-8') as f:\n",
        "        f.write(text)\n",
        "\n",
        "    print(\"   - Importing rl.py …\")\n",
        "    spec = importlib.util.spec_from_file_location(\"rl\", \"rl.py\")\n",
        "    rl = importlib.util.module_from_spec(spec)\n",
        "    spec.loader.exec_module(rl)\n",
        "\n",
        "    # 2) Expose Role-B classes for Cell 5\n",
        "    HangmanEnv    = getattr(rl, \"HangmanEnv\", None)\n",
        "    TabularQAgent = getattr(rl, \"TabularQAgent\", None)\n",
        "    DQNAgent      = getattr(rl, \"DQNAgent\", None)\n",
        "    DQNConfig     = getattr(rl, \"DQNConfig\", None)\n",
        "    ALPHABET      = getattr(rl, \"ALPHABET\", \"abcdefghijklmnopqrstuvwxyz\")\n",
        "\n",
        "    print(\">> Loaded Role-B classes:\")\n",
        "    print(\"   - HangmanEnv     :\", HangmanEnv)\n",
        "    print(\"   - TabularQAgent  :\", TabularQAgent)\n",
        "    print(\"   - DQNAgent       :\", DQNAgent)\n",
        "    print(\"   - DQNConfig      :\", DQNConfig)\n",
        "    print(\"   - ALPHABET len   :\", len(ALPHABET))\n",
        "\n",
        "print(\">> Cell 4.9 ready. Now run Cell 5 (evaluation).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 4.95 (patched): Quick Q-table refresh (train RL here) ===\n",
        "# Trains a small/medium Q-learning run against your chosen oracle and saves models/q_table.pkl\n",
        "\n",
        "from pathlib import Path\n",
        "from contextlib import suppress\n",
        "import inspect\n",
        "\n",
        "assert 'HangmanEnv' in globals() and 'TabularQAgent' in globals(), \\\n",
        "    \"Role-B classes not loaded. Re-run Cell 4.9 before this.\"\n",
        "\n",
        "# 1) pick the oracle RL should learn from (MUST match what you'll evaluate)\n",
        "BEST_ORACLE_FOR_RL = 'improved_hmm'   # 'improved_hmm'|'hyb_improved'|'hyb_basic'|'count_hmm'|'cfp'\n",
        "\n",
        "_oracle_map = {\n",
        "    'improved_hmm': globals().get('improved_hmm', None),\n",
        "    'hyb_improved': globals().get('hyb_improved', None),\n",
        "    'hyb_basic':    globals().get('hyb_basic', None),\n",
        "    'count_hmm':    globals().get('count_hmm', None),\n",
        "    'cfp':          globals().get('cfp', None),\n",
        "}\n",
        "ORACLE_FOR_RL = _oracle_map.get(BEST_ORACLE_FOR_RL)\n",
        "if ORACLE_FOR_RL is None:\n",
        "    raise RuntimeError(f\"Chosen oracle '{BEST_ORACLE_FOR_RL}' not built yet. Build it (A/6/7/B) and retry.\")\n",
        "\n",
        "# 2) training knobs (safe defaults)\n",
        "EPISODES     = 20000\n",
        "EPS_START    = 0.20\n",
        "EPS_END      = 0.01\n",
        "EPS_DECAY_EP = int(0.8 * EPISODES)\n",
        "\n",
        "SAVE_DIR  = Path('models')\n",
        "SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
        "SAVE_PATH = SAVE_DIR / 'q_table.pkl'\n",
        "\n",
        "def _call_train_qlearning_or_fallback():\n",
        "    \"\"\"Try rl.train_qlearning with adaptive kwargs; else fallback to inline trainer.\"\"\"\n",
        "    used_rl_trainer = False\n",
        "    if 'rl' in globals() and hasattr(rl, 'train_qlearning'):\n",
        "        fn = rl.train_qlearning\n",
        "        sig = inspect.signature(fn)\n",
        "        params = set(sig.parameters.keys())\n",
        "\n",
        "        # Map 'corpus_words' to the parameter name your function uses\n",
        "        corpus_arg_name = None\n",
        "        for candidate in ['words','train_words','word_list','dataset','corpus','train_set']:\n",
        "            if candidate in params:\n",
        "                corpus_arg_name = candidate\n",
        "                break\n",
        "\n",
        "        # Candidate kwargs (we'll filter by signature)\n",
        "        candidate_kwargs = {\n",
        "            corpus_arg_name: corpus_words if corpus_arg_name else None,\n",
        "            'hmm': ORACLE_FOR_RL,\n",
        "            'episodes': EPISODES,\n",
        "            'eps_start': EPS_START,\n",
        "            'eps_end': EPS_END,\n",
        "            'eps_decay_episodes': EPS_DECAY_EP,\n",
        "            'wrong_penalty': 5.0,\n",
        "            'repeat_penalty': 2.0,\n",
        "            'save_path': str(SAVE_PATH),\n",
        "            'log_every': 1000,\n",
        "        }\n",
        "        call_kwargs = {k:v for k,v in candidate_kwargs.items() if k and (k in params) and (v is not None)}\n",
        "\n",
        "        print(\"[RL] Detected train_qlearning signature:\", str(sig))\n",
        "        print(\"[RL] Passing kwargs:\", sorted(call_kwargs.keys()))\n",
        "        try:\n",
        "            fn(**call_kwargs)\n",
        "            print(f\"[RL] Q-table saved → {SAVE_PATH}\")\n",
        "            used_rl_trainer = True\n",
        "        except TypeError as e:\n",
        "            print(\"[WARN] train_qlearning kwargs mismatch → falling back to inline trainer.\\n\", e)\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] train_qlearning raised an exception → falling back to inline trainer.\\n\", e)\n",
        "\n",
        "    if not used_rl_trainer:\n",
        "        # Fallback: inline trainer via env + TabularQAgent (works with your eval API)\n",
        "        print(\"[INFO] Using inline TabularQAgent trainer (fallback).\")\n",
        "        import numpy as np\n",
        "        env = HangmanEnv(corpus_words, lives=6, hmm=ORACLE_FOR_RL, seed=123)\n",
        "        agent = TabularQAgent()\n",
        "\n",
        "        def eps_at(ep):\n",
        "            if ep >= EPS_DECAY_EP: return EPS_END\n",
        "            return EPS_START - (EPS_START - EPS_END) * (ep / EPS_DECAY_EP)\n",
        "\n",
        "        for ep in range(1, EPISODES + 1):\n",
        "            env.reset()\n",
        "            done = False\n",
        "            with suppress(Exception):\n",
        "                agent.eps = eps_at(ep)\n",
        "            while not done:\n",
        "                hmm_probs = env._hmm_probs()\n",
        "                a = agent.act(env.mask, env.lives, hmm_probs, env.guessed)\n",
        "                letter = (ALPHABET[a] if isinstance(a, int) else a)\n",
        "                _, reward, done, _ = env.step(letter)\n",
        "                with suppress(Exception):\n",
        "                    agent.update(env.mask, env.lives, hmm_probs, env.guessed, a, reward, done)\n",
        "            if ep % 1000 == 0:\n",
        "                print(f\"[Q] ep={ep}  ε≈{eps_at(ep):.3f}\")\n",
        "\n",
        "        with suppress(Exception):\n",
        "            agent.save(str(SAVE_PATH))\n",
        "        print(f\"[RL] (fallback) Q-table saved → {SAVE_PATH}\")\n",
        "\n",
        "_call_train_qlearning_or_fallback()\n"
      ],
      "metadata": {
        "id": "C4WG4H9s3UGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d38444a-abe2-483a-d260-785d4adb0905"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RL] Detected train_qlearning signature: (corpus_path='corpus.txt', episodes=30000, seed=42, save_path='q_table.pkl')\n",
            "[RL] Passing kwargs: ['episodes', 'save_path']\n",
            "[Q] ep=1000 avg_reward/ep=-5.534 wrong=6 repeated=0\n",
            "[Q] ep=2000 avg_reward/ep=-5.369 wrong=6 repeated=0\n",
            "[Q] ep=3000 avg_reward/ep=-5.228 wrong=6 repeated=0\n",
            "[Q] ep=4000 avg_reward/ep=-5.131 wrong=6 repeated=0\n",
            "[Q] ep=5000 avg_reward/ep=-5.064 wrong=6 repeated=0\n",
            "[Q] ep=6000 avg_reward/ep=-4.830 wrong=6 repeated=0\n",
            "[Q] ep=7000 avg_reward/ep=-4.777 wrong=6 repeated=0\n",
            "[Q] ep=8000 avg_reward/ep=-4.987 wrong=6 repeated=0\n",
            "[Q] ep=9000 avg_reward/ep=-4.643 wrong=6 repeated=0\n",
            "[Q] ep=10000 avg_reward/ep=-4.879 wrong=6 repeated=0\n",
            "[Q] ep=11000 avg_reward/ep=-4.812 wrong=6 repeated=0\n",
            "[Q] ep=12000 avg_reward/ep=-4.365 wrong=6 repeated=0\n",
            "[Q] ep=13000 avg_reward/ep=-4.598 wrong=6 repeated=0\n",
            "[Q] ep=14000 avg_reward/ep=-4.723 wrong=6 repeated=0\n",
            "[Q] ep=15000 avg_reward/ep=-4.448 wrong=6 repeated=0\n",
            "[Q] ep=16000 avg_reward/ep=-4.562 wrong=6 repeated=0\n",
            "[Q] ep=17000 avg_reward/ep=-4.526 wrong=6 repeated=0\n",
            "[Q] ep=18000 avg_reward/ep=-4.359 wrong=6 repeated=0\n",
            "[Q] ep=19000 avg_reward/ep=-4.545 wrong=6 repeated=0\n",
            "[Q] ep=20000 avg_reward/ep=-4.176 wrong=6 repeated=0\n",
            "Saved Q-table to models/q_table.pkl\n",
            "[RL] Q-table saved → models/q_table.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 4.96: Stable DQN training (signature-safe; same oracle as Q-table) ===\n",
        "from pathlib import Path\n",
        "import inspect\n",
        "\n",
        "assert 'HangmanEnv' in globals() and 'DQNAgent' in globals() and 'DQNConfig' in globals(), \\\n",
        "    \"Role-B classes not loaded. Re-run Cell 4.9 first.\"\n",
        "assert 'ORACLE_FOR_RL' in globals() and ORACLE_FOR_RL is not None, \\\n",
        "    \"Choose/build your oracle first (4.95).\"\n",
        "\n",
        "SAVE_DIR  = Path('models'); SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
        "DQN_SAVE  = SAVE_DIR / 'dqn.pt'\n",
        "\n",
        "# Stabilized hyperparams\n",
        "STEPS            = 80000\n",
        "BATCH_SIZE       = 64\n",
        "LR               = 1e-4\n",
        "GAMMA            = 0.995\n",
        "REPLAY_SIZE      = 100_000\n",
        "WARMUP_STEPS     = 5_000\n",
        "TARGET_UPDATE    = 2000\n",
        "GRAD_CLIP        = 1.0\n",
        "EPS_START        = 0.20\n",
        "EPS_END          = 0.02\n",
        "EPS_DECAY_STEPS  = int(0.8 * STEPS)\n",
        "LOG_EVERY        = 2000\n",
        "\n",
        "def _call_signature_safe(fn, kw):\n",
        "    params = set(inspect.signature(fn).parameters.keys())\n",
        "    filtered = {k: v for k, v in kw.items() if k in params}\n",
        "    return fn(**filtered)\n",
        "\n",
        "if 'rl' in globals() and hasattr(rl, 'train_dqn'):\n",
        "    print(f\"[DQN] Training via rl.train_dqn() on oracle='{BEST_ORACLE_FOR_RL}' …\")\n",
        "    superset_kwargs = dict(\n",
        "        words=corpus_words,      # some trainers expect 'words'\n",
        "        corpus=corpus_words,     # or 'corpus'\n",
        "        train_words=corpus_words,\n",
        "        hmm=ORACLE_FOR_RL,\n",
        "        steps=STEPS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        lr=LR,\n",
        "        gamma=GAMMA,\n",
        "        replay_size=REPLAY_SIZE,\n",
        "        warmup_steps=WARMUP_STEPS,\n",
        "        target_update=TARGET_UPDATE,\n",
        "        grad_clip=GRAD_CLIP,\n",
        "        eps_start=EPS_START,\n",
        "        eps_end=EPS_END,\n",
        "        eps_decay_steps=EPS_DECAY_STEPS,\n",
        "        wrong_penalty=5.0,\n",
        "        repeat_penalty=2.0,\n",
        "        log_every=LOG_EVERY,\n",
        "        save_path=str(DQN_SAVE),\n",
        "        lives=6,\n",
        "        seed=123,\n",
        "    )\n",
        "    try:\n",
        "        _call_signature_safe(rl.train_dqn, superset_kwargs)\n",
        "        print(f\"[DQN] Saved → {DQN_SAVE}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] rl.train_dqn() failed ({e}). Skipping DQN for now. Set USE_DQN=False in Cell 5.\")\n",
        "else:\n",
        "    print(\"[WARN] rl.train_dqn() not found. Skipping DQN training. (Leave USE_DQN=False in Cell 5.)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSfJDs7k6D3D",
        "outputId": "f2018b7e-2252-4e85-c846-06d55eda6312"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DQN] Training via rl.train_dqn() on oracle='improved_hmm' …\n",
            "[DQN] steps=5000 buffer=5000 avg_loss≈25.6109\n",
            "[DQN] steps=10000 buffer=10000 avg_loss≈275.2561\n",
            "[DQN] steps=15000 buffer=15000 avg_loss≈807.2449\n",
            "[DQN] steps=20000 buffer=20000 avg_loss≈7584.1524\n",
            "[DQN] steps=25000 buffer=25000 avg_loss≈30239.4428\n",
            "[DQN] steps=30000 buffer=30000 avg_loss≈57938.0791\n",
            "[DQN] steps=35000 buffer=35000 avg_loss≈106320.7648\n",
            "[DQN] steps=40000 buffer=40000 avg_loss≈231427.6960\n",
            "[DQN] steps=45000 buffer=45000 avg_loss≈612298.6240\n",
            "[DQN] steps=50000 buffer=50000 avg_loss≈1754976.1334\n",
            "[DQN] steps=55000 buffer=50000 avg_loss≈4654889.1999\n",
            "[DQN] steps=60000 buffer=50000 avg_loss≈10718675.2278\n",
            "[DQN] steps=65000 buffer=50000 avg_loss≈21742778.9120\n",
            "[DQN] steps=70000 buffer=50000 avg_loss≈39372530.6821\n",
            "[DQN] steps=75000 buffer=50000 avg_loss≈65370684.5248\n",
            "[DQN] steps=80000 buffer=50000 avg_loss≈102370013.0100\n",
            "Saved DQN weights to models/dqn.pt\n",
            "[DQN] Saved → models/dqn.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpOmxa6dlLIm",
        "outputId": "ea0c67c0-2994-4bb6-b102-45935872850e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] count_hmm ready: True\n"
          ]
        }
      ],
      "source": [
        "# === Cell A: Build Count-HMM oracle ===\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "ALPHABET = 'abcdefghijklmnopqrstuvwxyz'\n",
        "ALPHABET_SET = set(ALPHABET)\n",
        "\n",
        "def _mk_index():\n",
        "    idx = {c:i for i,c in enumerate(ALPHABET)}\n",
        "    rev = {i:c for c,i in idx.items()}\n",
        "    return idx, rev\n",
        "\n",
        "class CountHMMOracle:\n",
        "    def __init__(self, words, smooth: float = 0.5, by_length: bool = True):\n",
        "        self.idx, self.rev = _mk_index()\n",
        "        self.K = len(ALPHABET)\n",
        "        self.by_length = by_length\n",
        "        self.smooth = smooth\n",
        "        self.pi = {}   # length -> (K,)\n",
        "        self.A  = {}   # length -> (K,K)\n",
        "\n",
        "        groups = defaultdict(list)\n",
        "        for w in words:\n",
        "            w = w.strip().lower()\n",
        "            if not w or any(ch not in ALPHABET_SET for ch in w):\n",
        "                continue\n",
        "            groups[len(w)].append(w)\n",
        "\n",
        "        for L, ws in groups.items():\n",
        "            pi = np.full(self.K, smooth, dtype=np.float64)\n",
        "            A  = np.full((self.K,self.K), smooth, dtype=np.float64)\n",
        "            for w in ws:\n",
        "                pi[self.idx[w[0]]] += 1.0\n",
        "                for a,b in zip(w[:-1], w[1:]):\n",
        "                    A[self.idx[a], self.idx[b]] += 1.0\n",
        "            pi /= pi.sum()\n",
        "            A  /= A.sum(axis=1, keepdims=True)\n",
        "            self.pi[L] = pi\n",
        "            self.A[L]  = A\n",
        "\n",
        "        # global fallback (if by_length=False)\n",
        "        if not by_length:\n",
        "            pis = [self.pi[L] for L in self.pi]\n",
        "            As  = [self.A[L]  for L in self.A]\n",
        "            self.pi = {None: np.mean(pis, axis=0)} if pis else {None: np.full(self.K,1.0/self.K)}\n",
        "            self.A  = {None: np.mean(As,  axis=0)} if As  else {None: np.full((self.K,self.K),1.0/self.K)}\n",
        "\n",
        "    def _params(self, L: int):\n",
        "        if self.by_length and L in self.pi:\n",
        "            return self.pi[L], self.A[L]\n",
        "        return self.pi.get(None, np.full(self.K,1.0/self.K)), self.A.get(None, np.full((self.K,self.K),1.0/self.K))\n",
        "\n",
        "    def letter_posteriors(self, mask: str, guessed: set[str]) -> dict[str, float]:\n",
        "        L = len(mask)\n",
        "        pi, A = self._params(L)\n",
        "        if pi is None or A is None:\n",
        "            rem = [c for c in ALPHABET if c not in guessed]\n",
        "            return {c: 1.0/len(rem) for c in rem} if rem else {c:0.0 for c in ALPHABET}\n",
        "\n",
        "        # emission mask\n",
        "        E = np.ones((L, self.K), dtype=np.float64)\n",
        "        wrong = {g for g in guessed if g not in mask}\n",
        "        for t,ch in enumerate(mask):\n",
        "            if ch == '_':\n",
        "                for g in wrong:\n",
        "                    E[t, self.idx[g]] = 0.0\n",
        "            else:\n",
        "                E[t,:] = 0.0\n",
        "                E[t, self.idx[ch]] = 1.0\n",
        "\n",
        "        eps = 1e-12\n",
        "        log_pi = np.log(pi + eps)\n",
        "        log_A  = np.log(A  + eps)\n",
        "        log_E  = np.log(E  + eps)\n",
        "\n",
        "        # forward\n",
        "        alpha = np.full((L, self.K), -np.inf)\n",
        "        alpha[0,:] = log_pi + log_E[0,:]\n",
        "        for t in range(1, L):\n",
        "            prev = alpha[t-1,:].reshape(-1,1) + log_A  # (K,K)\n",
        "            m = prev.max(axis=0)\n",
        "            alpha[t,:] = log_E[t,:] + (m + np.log(np.exp(prev - m).sum(axis=0)+eps))\n",
        "\n",
        "        # backward\n",
        "        beta = np.full((L, self.K), 0.0)\n",
        "        for t in range(L-2, -1, -1):\n",
        "            nxt = log_A + (log_E[t+1,:] + beta[t+1,:]).reshape(1,-1)\n",
        "            m = nxt.max(axis=1)\n",
        "            beta[t,:] = m + np.log(np.exp(nxt - m.reshape(-1,1)).sum(axis=1)+eps)\n",
        "\n",
        "        log_Z = (alpha[-1,:].max() + np.log(np.exp(alpha[-1,:] - alpha[-1,:].max()).sum()+eps))\n",
        "        gamma = np.exp(alpha + beta - log_Z)  # (L,K)\n",
        "\n",
        "        P = {c:0.0 for c in ALPHABET}\n",
        "        for t,ch in enumerate(mask):\n",
        "            if ch == '_':\n",
        "                for s in range(self.K):\n",
        "                    c = self.rev[s]\n",
        "                    if c not in guessed and E[t,s] > 0.0:\n",
        "                        P[c] += gamma[t,s]\n",
        "        Z = sum(P.values())\n",
        "        if Z <= 0:\n",
        "            rem = [c for c in ALPHABET if c not in guessed]\n",
        "            return {c: 1.0/len(rem) for c in rem} if rem else {c:0.0 for c in ALPHABET}\n",
        "        for c in P: P[c] /= Z\n",
        "        return P\n",
        "\n",
        "# ✅ use CORPUS words (not an undefined `train_words`)\n",
        "count_hmm = CountHMMOracle(corpus_words, smooth=0.5, by_length=True)\n",
        "print(\"[OK] count_hmm ready:\", isinstance(count_hmm, CountHMMOracle))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LGwW5FHleQF",
        "outputId": "4e8331ed-cd35-4fda-eee9-7b37a3e1d708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] hyb_basic ready: True\n"
          ]
        }
      ],
      "source": [
        "# === Cell B: Hybrid oracle (Count-HMM ⊕ CFP) ===\n",
        "LAM = 0.6  # you can tune 0.3–0.7\n",
        "\n",
        "class HybridOracle:\n",
        "    def __init__(self, hmm_oracle, cfp_oracle, lam: float = 0.6):\n",
        "        self.hmm = hmm_oracle\n",
        "        self.cfp = cfp_oracle\n",
        "        self.lam = lam\n",
        "\n",
        "    def letter_posteriors(self, mask: str, guessed: set[str]) -> dict[str, float]:\n",
        "        A = self.hmm.letter_posteriors(mask, guessed)\n",
        "        B = self.cfp.letter_posteriors(mask, guessed)\n",
        "        # union of keys\n",
        "        keys = set(A.keys()) | set(B.keys())\n",
        "        out = {}\n",
        "        for k in keys:\n",
        "            if k in guessed:\n",
        "                continue\n",
        "            out[k] = self.lam * A.get(k, 0.0) + (1.0 - self.lam) * B.get(k, 0.0)\n",
        "        s = sum(out.values())\n",
        "        if s > 0:\n",
        "            for k in out: out[k] /= s\n",
        "        return out\n",
        "\n",
        "hyb_basic = HybridOracle(count_hmm, cfp, lam=LAM)\n",
        "print(\"[OK] hyb_basic ready:\", isinstance(hyb_basic, HybridOracle))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8GCcPiTNWhx",
        "outputId": "51d6afc4-1042-4dff-9341-a3e1df8b7853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluating 5 oracles on 2000 games ===\n",
            "\n",
            "Oracle       | Agent   | Success Rate   | Total Wrong | Total Rep | Final Score\n",
            "-------------------------------------------------------------------------------------\n",
            "[GREEDY] Running 2000 games …\n",
            "  200/2000 done …\n",
            "  400/2000 done …\n",
            "  600/2000 done …\n",
            "  800/2000 done …\n",
            "  1000/2000 done …\n",
            "  1200/2000 done …\n",
            "  1400/2000 done …\n",
            "  1600/2000 done …\n",
            "  1800/2000 done …\n",
            "  2000/2000 done …\n",
            "[GREEDY] Done: SR=0.028, Wrong=11875, Rep=0, Score=-59320\n",
            "CFP          | Greedy  | SR=0.028 | Wrong=11875 | Rep=   0 | Final=-59320.0\n",
            "[QTABLE] 2000 games …\n",
            "  Game 200/2000 done …\n",
            "  Game 400/2000 done …\n",
            "  Game 600/2000 done …\n",
            "  Game 800/2000 done …\n",
            "  Game 1000/2000 done …\n",
            "  Game 1200/2000 done …\n",
            "  Game 1400/2000 done …\n",
            "  Game 1600/2000 done …\n",
            "  Game 1800/2000 done …\n",
            "  Game 2000/2000 done …\n",
            "[QTABLE] SR=0.002, Wrong=11987, Rep=0, Score=-59932\n",
            "CFP          | QTable  | SR=0.002 | Wrong=11987 | Rep=   0 | Final=-59932.0\n",
            "[DQN] 2000 games …\n",
            "  Game 200/2000 done …\n",
            "  Game 400/2000 done …\n",
            "  Game 600/2000 done …\n",
            "  Game 800/2000 done …\n",
            "  Game 1000/2000 done …\n",
            "  Game 1200/2000 done …\n",
            "  Game 1400/2000 done …\n",
            "  Game 1600/2000 done …\n",
            "  Game 1800/2000 done …\n",
            "  Game 2000/2000 done …\n",
            "[DQN] SR=0.002, Wrong=11993, Rep=0, Score=-59961\n",
            "CFP          | DQN     | SR=0.002 | Wrong=11993 | Rep=   0 | Final=-59961.0\n",
            "[GREEDY] Running 2000 games …\n",
            "  200/2000 done …\n",
            "  400/2000 done …\n",
            "  600/2000 done …\n",
            "  800/2000 done …\n",
            "  1000/2000 done …\n",
            "  1200/2000 done …\n",
            "  1400/2000 done …\n",
            "  1600/2000 done …\n",
            "  1800/2000 done …\n",
            "  2000/2000 done …\n",
            "[GREEDY] Done: SR=0.357, Wrong=10246, Rep=0, Score=-50515\n",
            "Count-HMM    | Greedy  | SR=0.357 | Wrong=10246 | Rep=   0 | Final=-50515.0\n",
            "[QTABLE] 2000 games …\n",
            "  Game 200/2000 done …\n",
            "  Game 400/2000 done …\n",
            "  Game 600/2000 done …\n",
            "  Game 800/2000 done …\n",
            "  Game 1000/2000 done …\n",
            "  Game 1200/2000 done …\n",
            "  Game 1400/2000 done …\n",
            "  Game 1600/2000 done …\n",
            "  Game 1800/2000 done …\n",
            "  Game 2000/2000 done …\n",
            "[QTABLE] SR=0.002, Wrong=11985, Rep=0, Score=-59921\n",
            "Count-HMM    | QTable  | SR=0.002 | Wrong=11985 | Rep=   0 | Final=-59921.0\n",
            "[DQN] 2000 games …\n",
            "  Game 200/2000 done …\n",
            "  Game 400/2000 done …\n",
            "  Game 600/2000 done …\n",
            "  Game 800/2000 done …\n",
            "  Game 1000/2000 done …\n",
            "  Game 1200/2000 done …\n",
            "  Game 1400/2000 done …\n",
            "  Game 1600/2000 done …\n",
            "  Game 1800/2000 done …\n",
            "  Game 2000/2000 done …\n",
            "[DQN] SR=0.002, Wrong=11993, Rep=0, Score=-59961\n",
            "Count-HMM    | DQN     | SR=0.002 | Wrong=11993 | Rep=   0 | Final=-59961.0\n",
            "[GREEDY] Running 2000 games …\n",
            "  200/2000 done …\n",
            "  400/2000 done …\n",
            "  600/2000 done …\n",
            "  800/2000 done …\n",
            "  1000/2000 done …\n",
            "  1200/2000 done …\n",
            "  1400/2000 done …\n",
            "  1600/2000 done …\n",
            "  1800/2000 done …\n",
            "  2000/2000 done …\n",
            "[GREEDY] Done: SR=0.357, Wrong=10239, Rep=0, Score=-50480\n",
            "Improved-HMM | Greedy  | SR=0.357 | Wrong=10239 | Rep=   0 | Final=-50480.0\n",
            "[QTABLE] 2000 games …\n",
            "  Game 200/2000 done …\n",
            "  Game 400/2000 done …\n",
            "  Game 600/2000 done …\n",
            "  Game 800/2000 done …\n",
            "  Game 1000/2000 done …\n",
            "  Game 1200/2000 done …\n",
            "  Game 1400/2000 done …\n",
            "  Game 1600/2000 done …\n",
            "  Game 1800/2000 done …\n",
            "  Game 2000/2000 done …\n",
            "[QTABLE] SR=0.002, Wrong=11985, Rep=0, Score=-59921\n",
            "Improved-HMM | QTable  | SR=0.002 | Wrong=11985 | Rep=   0 | Final=-59921.0\n",
            "[DQN] 2000 games …\n",
            "  Game 200/2000 done …\n",
            "  Game 400/2000 done …\n",
            "  Game 600/2000 done …\n",
            "  Game 800/2000 done …\n",
            "  Game 1000/2000 done …\n",
            "  Game 1200/2000 done …\n",
            "  Game 1400/2000 done …\n",
            "  Game 1600/2000 done …\n",
            "  Game 1800/2000 done …\n",
            "  Game 2000/2000 done …\n",
            "[DQN] SR=0.002, Wrong=11993, Rep=0, Score=-59961\n",
            "Improved-HMM | DQN     | SR=0.002 | Wrong=11993 | Rep=   0 | Final=-59961.0\n",
            "[GREEDY] Running 2000 games …\n",
            "  200/2000 done …\n",
            "  400/2000 done …\n",
            "  600/2000 done …\n",
            "  800/2000 done …\n",
            "  1000/2000 done …\n",
            "  1200/2000 done …\n",
            "  1400/2000 done …\n",
            "  1600/2000 done …\n",
            "  1800/2000 done …\n",
            "  2000/2000 done …\n",
            "[GREEDY] Done: SR=0.355, Wrong=10194, Rep=0, Score=-50259\n",
            "Hybrid-Basic | Greedy  | SR=0.355 | Wrong=10194 | Rep=   0 | Final=-50259.0\n",
            "[QTABLE] 2000 games …\n",
            "  Game 200/2000 done …\n",
            "  Game 400/2000 done …\n",
            "  Game 600/2000 done …\n",
            "  Game 800/2000 done …\n",
            "  Game 1000/2000 done …\n",
            "  Game 1200/2000 done …\n",
            "  Game 1400/2000 done …\n",
            "  Game 1600/2000 done …\n",
            "  Game 1800/2000 done …\n",
            "  Game 2000/2000 done …\n",
            "[QTABLE] SR=0.002, Wrong=11985, Rep=0, Score=-59921\n",
            "Hybrid-Basic | QTable  | SR=0.002 | Wrong=11985 | Rep=   0 | Final=-59921.0\n",
            "[DQN] 2000 games …\n",
            "  Game 200/2000 done …\n",
            "  Game 400/2000 done …\n",
            "  Game 600/2000 done …\n",
            "  Game 800/2000 done …\n",
            "  Game 1000/2000 done …\n",
            "  Game 1200/2000 done …\n",
            "  Game 1400/2000 done …\n",
            "  Game 1600/2000 done …\n",
            "  Game 1800/2000 done …\n",
            "  Game 2000/2000 done …\n",
            "[DQN] SR=0.002, Wrong=11993, Rep=0, Score=-59961\n",
            "Hybrid-Basic | DQN     | SR=0.002 | Wrong=11993 | Rep=   0 | Final=-59961.0\n",
            "[GREEDY] Running 2000 games …\n",
            "  200/2000 done …\n",
            "  400/2000 done …\n",
            "  600/2000 done …\n",
            "  800/2000 done …\n",
            "  1000/2000 done …\n",
            "  1200/2000 done …\n",
            "  1400/2000 done …\n",
            "  1600/2000 done …\n",
            "  1800/2000 done …\n",
            "  2000/2000 done …\n",
            "[GREEDY] Done: SR=0.353, Wrong=10206, Rep=0, Score=-50323\n",
            "Hybrid-Improved | Greedy  | SR=0.353 | Wrong=10206 | Rep=   0 | Final=-50323.0\n",
            "[QTABLE] 2000 games …\n",
            "  Game 200/2000 done …\n",
            "  Game 400/2000 done …\n",
            "  Game 600/2000 done …\n",
            "  Game 800/2000 done …\n",
            "  Game 1000/2000 done …\n",
            "  Game 1200/2000 done …\n",
            "  Game 1400/2000 done …\n",
            "  Game 1600/2000 done …\n",
            "  Game 1800/2000 done …\n",
            "  Game 2000/2000 done …\n",
            "[QTABLE] SR=0.002, Wrong=11985, Rep=0, Score=-59921\n",
            "Hybrid-Improved | QTable  | SR=0.002 | Wrong=11985 | Rep=   0 | Final=-59921.0\n",
            "[DQN] 2000 games …\n",
            "  Game 200/2000 done …\n",
            "  Game 400/2000 done …\n",
            "  Game 600/2000 done …\n",
            "  Game 800/2000 done …\n",
            "  Game 1000/2000 done …\n",
            "  Game 1200/2000 done …\n",
            "  Game 1400/2000 done …\n",
            "  Game 1600/2000 done …\n",
            "  Game 1800/2000 done …\n",
            "  Game 2000/2000 done …\n",
            "[DQN] SR=0.002, Wrong=11993, Rep=0, Score=-59961\n",
            "Hybrid-Improved | DQN     | SR=0.002 | Wrong=11993 | Rep=   0 | Final=-59961.0\n",
            "\n",
            ">>> BEST RESULT <<<\n",
            "Oracle=Hybrid-Basic, Agent=Greedy, FinalScore=-50259, SR=0.355\n"
          ]
        }
      ],
      "source": [
        "# === Cell 5 (instrumented): 2000-game evaluation with live prints ===\n",
        "import os, time\n",
        "from contextlib import suppress\n",
        "import numpy as np\n",
        "\n",
        "GAMES = 2000                 # official scale\n",
        "USE_QTABLE = True\n",
        "QTABLE_PATH = 'models/q_table.pkl'   # ← use the model you saved in 4.95\n",
        "USE_DQN = True             # keep off unless you stabilize it\n",
        "DQN_PATH = 'models/dqn.pt'\n",
        "\n",
        "# auto-disable if files missing\n",
        "if USE_QTABLE and not os.path.exists(QTABLE_PATH):\n",
        "    print(f\"[Info] Q-table not found → disabling QTable eval.\")\n",
        "    USE_QTABLE = False\n",
        "if USE_DQN and not os.path.exists(DQN_PATH):\n",
        "    print(f\"[Info] DQN weights not found → disabling DQN eval.\")\n",
        "    USE_DQN = False\n",
        "\n",
        "# Role-B classes (from 4.9 or global)\n",
        "try:\n",
        "    from hackman.env import HangmanEnv\n",
        "    from hackman.agents.qlearning import TabularQAgent\n",
        "    from hackman.agents.dqn import DQNAgent, DQNConfig\n",
        "    from hackman.utils import ALPHABET\n",
        "    HAS_ROLEB = True\n",
        "except Exception:\n",
        "    HAS_ROLEB = False\n",
        "    with suppress(Exception):\n",
        "        HangmanEnv; TabularQAgent\n",
        "        HAS_ROLEB = True\n",
        "        ALPHABET = ALPHABET if 'ALPHABET' in globals() else 'abcdefghijklmnopqrstuvwxyz'\n",
        "    if not HAS_ROLEB:\n",
        "        ALPHABET = 'abcdefghijklmnopqrstuvwxyz'\n",
        "        print(\"[Info] Role-B not available → RL skipped.\")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "def eval_greedy(words, oracle, games=2000, seed=1):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    sample = words if len(words) <= games else list(rng.choice(words, size=games, replace=False))\n",
        "    wins = total_wrong = total_repeated = 0\n",
        "    print(f\"[GREEDY] Running {len(sample)} games …\")\n",
        "    for gi, w in enumerate(sample, 1):\n",
        "        mask = ['_'] * len(w); guessed=set(); lives=6; wrong=repeated=0\n",
        "        while lives>0 and '_' in mask:\n",
        "            probs = oracle.letter_posteriors(''.join(mask), guessed)\n",
        "            letter = max(probs.items(), key=lambda kv: kv[1])[0] if probs else next((c for c in ALPHABET if c not in guessed), None)\n",
        "            if letter is None: break\n",
        "            if letter in guessed: repeated+=1; continue\n",
        "            guessed.add(letter)\n",
        "            if letter in w:\n",
        "                for i,ch in enumerate(w):\n",
        "                    if ch==letter: mask[i]=ch\n",
        "            else:\n",
        "                wrong+=1; lives-=1\n",
        "        if '_' not in mask: wins+=1\n",
        "        total_wrong+=wrong; total_repeated+=repeated\n",
        "        if gi%200==0: print(f\"  {gi}/{len(sample)} done …\")\n",
        "    sr=wins/len(sample); score=(sr*2000)-(total_wrong*5)-(total_repeated*2)\n",
        "    print(f\"[GREEDY] Done: SR={sr:.3f}, Wrong={total_wrong}, Rep={total_repeated}, Score={score:.0f}\")\n",
        "    return dict(games=len(sample),success_rate=sr,total_wrong=total_wrong,\n",
        "                total_repeated=total_repeated,final_score=score)\n",
        "\n",
        "def eval_qtable(words, oracle, qtable_path, games=2000, seed=7):\n",
        "    if not HAS_ROLEB: raise RuntimeError(\"Role-B missing\")\n",
        "    env=HangmanEnv(words,lives=6,hmm=oracle,seed=seed)\n",
        "    ag=TabularQAgent(); ag.load(qtable_path)\n",
        "    wins=tw=tr=0\n",
        "    print(f\"[QTABLE] {games} games …\")\n",
        "    for g in range(1,games+1):\n",
        "        env.reset(); done=False\n",
        "        while not done:\n",
        "            hmm=env._hmm_probs()\n",
        "            a=ag.act(env.mask,env.lives,hmm,env.guessed)\n",
        "            letter=ALPHABET[a]\n",
        "            _,_,done,_=env.step(letter)\n",
        "        if env.mask==env.word: wins+=1\n",
        "        tw+=env.total_wrong; tr+=env.total_repeated\n",
        "        if g%200==0: print(f\"  Game {g}/{games} done …\")\n",
        "    sr=wins/games; score=(sr*2000)-(tw*5)-(tr*2)\n",
        "    print(f\"[QTABLE] SR={sr:.3f}, Wrong={tw}, Rep={tr}, Score={score:.0f}\")\n",
        "    return dict(games=games,success_rate=sr,total_wrong=tw,total_repeated=tr,final_score=score)\n",
        "\n",
        "def eval_dqn(words, oracle, dqn_path, games=2000, seed=11):\n",
        "    if not HAS_ROLEB: raise RuntimeError(\"Role-B missing\")\n",
        "    import torch\n",
        "    env=HangmanEnv(words,lives=6,hmm=oracle,seed=seed)\n",
        "    s0=env.reset()\n",
        "    agent=DQNAgent(state_dim=int(s0.shape[0]),cfg=DQNConfig())\n",
        "    agent.policy.load_state_dict(torch.load(dqn_path,map_location='cpu'))\n",
        "    wins=tw=tr=0\n",
        "    print(f\"[DQN] {games} games …\")\n",
        "    for g in range(1,games+1):\n",
        "        env.reset(); done=False\n",
        "        while not done:\n",
        "            s=env._state()\n",
        "            a=agent.act(s,env.guessed)\n",
        "            letter=ALPHABET[a]\n",
        "            _,_,done,_=env.step(letter)\n",
        "        if env.mask==env.word: wins+=1\n",
        "        tw+=env.total_wrong; tr+=env.total_repeated\n",
        "        if g%200==0: print(f\"  Game {g}/{games} done …\")\n",
        "    sr=wins/games; score=(sr*2000)-(tw*5)-(tr*2)\n",
        "    print(f\"[DQN] SR={sr:.3f}, Wrong={tw}, Rep={tr}, Score={score:.0f}\")\n",
        "    return dict(games=games,success_rate=sr,total_wrong=tw,total_repeated=tr,final_score=score)\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "# which oracles to evaluate (add the ones you've built)\n",
        "to_eval=[]\n",
        "to_eval.append((\"CFP\", cfp))\n",
        "if 'count_hmm'    in globals(): to_eval.append((\"Count-HMM\", count_hmm))\n",
        "if 'improved_hmm' in globals(): to_eval.append((\"Improved-HMM\", improved_hmm))\n",
        "if 'hyb_basic'    in globals(): to_eval.append((\"Hybrid-Basic\", hyb_basic))\n",
        "if 'hyb_improved' in globals(): to_eval.append((\"Hybrid-Improved\", hyb_improved))\n",
        "\n",
        "print(f\"\\n=== Evaluating {len(to_eval)} oracles on {GAMES} games ===\\n\")\n",
        "\n",
        "best=None\n",
        "print(\"Oracle       | Agent   | Success Rate   | Total Wrong | Total Rep | Final Score\")\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "for name,oracle in to_eval:\n",
        "    # Greedy\n",
        "    g=eval_greedy(test_words,oracle,games=GAMES)\n",
        "    print(f\"{name:<12} | Greedy  | SR={g['success_rate']:.3f} | Wrong={g['total_wrong']:>5} | Rep={g['total_repeated']:>4} | Final={g['final_score']:>8}\")\n",
        "    if best is None or g['final_score']>best[2]['final_score']:\n",
        "        best=(name,\"Greedy\",g)\n",
        "\n",
        "    # QTable (if available)\n",
        "    if HAS_ROLEB and USE_QTABLE:\n",
        "        q=eval_qtable(test_words,oracle,QTABLE_PATH,games=GAMES)\n",
        "        print(f\"{name:<12} | QTable  | SR={q['success_rate']:.3f} | Wrong={q['total_wrong']:>5} | Rep={q['total_repeated']:>4} | Final={q['final_score']:>8}\")\n",
        "        if q['final_score']>best[2]['final_score']: best=(name,\"QTable\",q)\n",
        "\n",
        "    # DQN (optional; off by default)\n",
        "    if HAS_ROLEB and USE_DQN:\n",
        "        d=eval_dqn(test_words,oracle,DQN_PATH,games=GAMES)\n",
        "        print(f\"{name:<12} | DQN     | SR={d['success_rate']:.3f} | Wrong={d['total_wrong']:>5} | Rep={d['total_repeated']:>4} | Final={d['final_score']:>8}\")\n",
        "        if d['final_score']>best[2]['final_score']: best=(name,\"DQN\",d)\n",
        "\n",
        "print(\"\\n>>> BEST RESULT <<<\")\n",
        "print(f\"Oracle={best[0]}, Agent={best[1]}, FinalScore={best[2]['final_score']:.0f}, SR={best[2]['success_rate']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMOHxTfCN50M",
        "outputId": "67cab371-5dee-40bb-af91-ae7b92a7e2bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Count-HMM (basic bigram)...\n",
            "Building Improved-HMM (with positional + co-occurrence)...\n",
            "\n",
            "=== Basic Count-HMM ===\n",
            "{'top1': 0.5385454240416072, 'top3': 0.8499286972569415, 'top5': 0.9350725610267595, 'cases': 11921}\n",
            "{'games': 500, 'win_rate': 0.348, 'avg_wrong': 5.15, 'avg_repeated': 0.0}\n",
            "\n",
            "=== Improved HMM ===\n",
            "{'top1': 0.529989094874591, 'top3': 0.8495092693565977, 'top5': 0.9331431926851774, 'cases': 11921}\n",
            "{'games': 500, 'win_rate': 0.354, 'avg_wrong': 5.136, 'avg_repeated': 0.0}\n"
          ]
        }
      ],
      "source": [
        "# === Cell 6: Enhanced Count-HMM Oracle with Positional & Co-occurrence Features ===\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List, Dict, Set\n",
        "\n",
        "def _mk_index():\n",
        "    idx = {c:i for i,c in enumerate(ALPHABET)}\n",
        "    rev = {i:c for c,i in idx.items()}\n",
        "    return idx, rev\n",
        "\n",
        "# --- small greedy simulator local to this cell (so no dependency on earlier \"simulate\") ---\n",
        "def _play_greedy(word: str, oracle) -> dict:\n",
        "    mask = ['_'] * len(word)\n",
        "    guessed = set()\n",
        "    lives = 6\n",
        "    wrong = 0\n",
        "    repeated = 0\n",
        "    while lives > 0 and '_' in mask:\n",
        "        probs = oracle.letter_posteriors(''.join(mask), guessed)\n",
        "        if probs:\n",
        "            guess = max(probs.items(), key=lambda kv: kv[1])[0]\n",
        "        else:\n",
        "            # fallback to first unguessed letter\n",
        "            choices = [c for c in ALPHABET if c not in guessed]\n",
        "            guess = choices[0] if choices else None\n",
        "        if guess is None:\n",
        "            break\n",
        "        if guess in guessed:\n",
        "            repeated += 1\n",
        "            continue\n",
        "        guessed.add(guess)\n",
        "        if guess in word:\n",
        "            for i, ch in enumerate(word):\n",
        "                if ch == guess:\n",
        "                    mask[i] = ch\n",
        "        else:\n",
        "            wrong += 1\n",
        "            lives -= 1\n",
        "    return {\"win\": ('_' not in mask), \"wrong\": wrong, \"repeated\": repeated}\n",
        "\n",
        "def simulate_greedy(words: list[str], oracle, games=200):\n",
        "    rng = np.random.default_rng(1)\n",
        "    sample = words if len(words) <= games else list(rng.choice(words, size=games, replace=False))\n",
        "    wins = 0\n",
        "    tot_wrong = 0\n",
        "    tot_rep = 0\n",
        "    for w in sample:\n",
        "        r = _play_greedy(w, oracle)\n",
        "        wins += int(r[\"win\"])\n",
        "        tot_wrong += r[\"wrong\"]\n",
        "        tot_rep += r[\"repeated\"]\n",
        "    return {\n",
        "        \"games\": len(sample),\n",
        "        \"win_rate\": wins/len(sample),\n",
        "        \"avg_wrong\": tot_wrong/len(sample),\n",
        "        \"avg_repeated\": tot_rep/len(sample)\n",
        "    }\n",
        "# --- end local simulator ---\n",
        "\n",
        "class CountHMMOracle:\n",
        "    \"\"\"\n",
        "    Bigram HMM from counts with add-alpha smoothing and emission masks.\n",
        "    letter_posteriors(mask, guessed) returns P(letter) over unguessed letters.\n",
        "    \"\"\"\n",
        "    def __init__(self, words: List[str], smooth: float = 0.5, by_length: bool = True):\n",
        "        self.idx, self.rev = _mk_index()\n",
        "        self.K = len(ALPHABET)\n",
        "        self.by_length = by_length\n",
        "        self.smooth = smooth\n",
        "        self.pi = {}   # length -> (K,)\n",
        "        self.A  = {}   # length -> (K,K)\n",
        "        groups = defaultdict(list)\n",
        "        for w in words:\n",
        "            w = w.strip().lower()\n",
        "            if not w or any(ch not in ALPHABET_SET for ch in w):\n",
        "                continue\n",
        "            groups[len(w)].append(w)\n",
        "        # estimate per length\n",
        "        for L, ws in groups.items():\n",
        "            pi = np.full(self.K, smooth, dtype=np.float64)\n",
        "            A  = np.full((self.K, self.K), smooth, dtype=np.float64)\n",
        "            for w in ws:\n",
        "                pi[self.idx[w[0]]] += 1.0\n",
        "                for a,b in zip(w[:-1], w[1:]):\n",
        "                    A[self.idx[a], self.idx[b]] += 1.0\n",
        "            pi /= pi.sum()\n",
        "            A  /= A.sum(axis=1, keepdims=True)\n",
        "            self.pi[L] = pi\n",
        "            self.A[L]  = A\n",
        "        # global fallback (if requested)\n",
        "        if not by_length:\n",
        "            if self.pi:\n",
        "                pis = np.stack(list(self.pi.values()))\n",
        "                As  = np.stack(list(self.A.values()))\n",
        "                self.pi = {None: pis.mean(axis=0)}\n",
        "                self.A  = {None: As.mean(axis=0)}\n",
        "            else:\n",
        "                self.pi = {None: np.full(self.K, 1.0/self.K)}\n",
        "                self.A  = {None: np.full((self.K,self.K), 1.0/self.K)}\n",
        "\n",
        "    def _params(self, L: int):\n",
        "        if self.by_length and L in self.pi:\n",
        "            return self.pi[L], self.A[L]\n",
        "        return self.pi.get(None, np.full(self.K,1.0/self.K)), self.A.get(None, np.full((self.K,self.K),1.0/self.K))\n",
        "\n",
        "    def letter_posteriors(self, mask: str, guessed: Set[str]) -> Dict[str, float]:\n",
        "        L = len(mask)\n",
        "        pi, A = self._params(L)\n",
        "        if pi is None or A is None:\n",
        "            rem = [c for c in ALPHABET if c not in guessed]\n",
        "            return {c: 1.0/len(rem) for c in rem} if rem else {c: 0.0 for c in ALPHABET}\n",
        "\n",
        "        # Emission masks E[t,s] ∈ {0,1}\n",
        "        E = np.ones((L, self.K), dtype=np.float64)\n",
        "        wrong = {g for g in guessed if g not in mask}\n",
        "        for t,ch in enumerate(mask):\n",
        "            if ch == '_':\n",
        "                for g in wrong:\n",
        "                    E[t, self.idx[g]] = 0.0\n",
        "            else:\n",
        "                E[t,:] = 0.0\n",
        "                E[t, self.idx[ch]] = 1.0\n",
        "\n",
        "        eps = 1e-12\n",
        "        log_pi = np.log(pi + eps)\n",
        "        log_A  = np.log(A  + eps)\n",
        "        log_E  = np.log(E  + eps)\n",
        "\n",
        "        # forward\n",
        "        alpha = np.full((L, self.K), -np.inf, dtype=np.float64)\n",
        "        alpha[0,:] = log_pi + log_E[0,:]\n",
        "        for t in range(1, L):\n",
        "            prev = alpha[t-1,:].reshape(-1,1) + log_A  # (K,K)\n",
        "            m = prev.max(axis=0)\n",
        "            alpha[t,:] = log_E[t,:] + (m + np.log(np.exp(prev - m).sum(axis=0) + eps))\n",
        "\n",
        "        # backward\n",
        "        beta = np.full((L, self.K), -np.inf, dtype=np.float64)\n",
        "        beta[-1,:] = 0.0\n",
        "        for t in range(L-2, -1, -1):\n",
        "            nxt = log_A + (log_E[t+1,:] + beta[t+1,:]).reshape(1,-1)\n",
        "            m = nxt.max(axis=1)\n",
        "            beta[t,:] = m + np.log(np.exp(nxt - m.reshape(-1,1)).sum(axis=1) + eps)\n",
        "\n",
        "        log_Z = alpha[-1,:].max() + np.log(np.exp(alpha[-1,:] - alpha[-1,:].max()).sum() + eps)\n",
        "        gamma = np.exp(alpha + beta - log_Z)  # (L,K)\n",
        "\n",
        "        # aggregate over blanks, exclude guessed\n",
        "        P = {c: 0.0 for c in ALPHABET}\n",
        "        for t,ch in enumerate(mask):\n",
        "            if ch == '_':\n",
        "                for s in range(self.K):\n",
        "                    c = self.rev[s]\n",
        "                    if c not in guessed and E[t,s] > 0.0:\n",
        "                        P[c] += gamma[t,s]\n",
        "        Z = sum(P.values())\n",
        "        if Z <= 0:\n",
        "            rem = [c for c in ALPHABET if c not in guessed]\n",
        "            return {c: 1.0/len(rem) for c in rem} if rem else {c: 0.0 for c in ALPHABET}\n",
        "        for c in P:\n",
        "            P[c] /= Z\n",
        "        return P\n",
        "\n",
        "\n",
        "class ImprovedCountHMMOracle:\n",
        "    \"\"\"\n",
        "    Enhanced HMM with:\n",
        "    - Bigram HMM (existing)\n",
        "    - Positional frequency analysis\n",
        "    - Letter co-occurrence patterns\n",
        "    \"\"\"\n",
        "    def __init__(self, words: List[str], smooth: float = 1.0):\n",
        "        # Base bigram HMM\n",
        "        self.bigram_hmm = CountHMMOracle(words, smooth=smooth, by_length=True)\n",
        "\n",
        "        # Build additional features\n",
        "        self.pos_freq = self._build_positional_freq(words)\n",
        "        self.cooccur = self._build_cooccurrence(words)\n",
        "        self.word_set = set(w.strip().lower() for w in words)\n",
        "\n",
        "    def _build_positional_freq(self, words):\n",
        "        pos_freq = defaultdict(lambda: defaultdict(Counter))\n",
        "        for w in words:\n",
        "            w = w.strip().lower()\n",
        "            if not w or any(ch not in ALPHABET_SET for ch in w):\n",
        "                continue\n",
        "            for pos, ch in enumerate(w):\n",
        "                pos_freq[len(w)][pos][ch] += 1\n",
        "        for L in pos_freq:\n",
        "            for pos in pos_freq[L]:\n",
        "                total = sum(pos_freq[L][pos].values())\n",
        "                if total > 0:\n",
        "                    for ch in pos_freq[L][pos]:\n",
        "                        pos_freq[L][pos][ch] /= total\n",
        "        return pos_freq\n",
        "\n",
        "    def _build_cooccurrence(self, words):\n",
        "        cooccur = defaultdict(Counter)\n",
        "        for w in words:\n",
        "            w = w.strip().lower()\n",
        "            if not w or any(ch not in ALPHABET_SET for ch in w):\n",
        "                continue\n",
        "            chars = set(w)\n",
        "            for c1 in chars:\n",
        "                for c2 in chars:\n",
        "                    if c1 != c2:\n",
        "                        cooccur[c1][c2] += 1\n",
        "        for c1 in cooccur:\n",
        "            total = sum(cooccur[c1].values())\n",
        "            if total > 0:\n",
        "                for c2 in cooccur[c1]:\n",
        "                    cooccur[c1][c2] /= total\n",
        "        return cooccur\n",
        "\n",
        "    def _positional_score(self, mask, guessed):\n",
        "        L = len(mask)\n",
        "        scores = defaultdict(float)\n",
        "        if L not in self.pos_freq:\n",
        "            return {}\n",
        "        for pos, ch in enumerate(mask):\n",
        "            if ch == '_':\n",
        "                for c in ALPHABET:\n",
        "                    if c not in guessed:\n",
        "                        scores[c] += self.pos_freq[L][pos].get(c, 0.0)\n",
        "        Z = sum(scores.values())\n",
        "        return {c: scores[c]/Z for c in scores} if Z > 0 else {}\n",
        "\n",
        "    def _cooccurrence_score(self, mask, guessed):\n",
        "        revealed = set(ch for ch in mask if ch != '_')\n",
        "        if not revealed:\n",
        "            return {}\n",
        "        scores = defaultdict(float)\n",
        "        for c in ALPHABET:\n",
        "            if c not in guessed:\n",
        "                for r in revealed:\n",
        "                    scores[c] += self.cooccur[r].get(c, 0.0)\n",
        "        Z = sum(scores.values())\n",
        "        return {c: scores[c]/Z for c in scores} if Z > 0 else {}\n",
        "\n",
        "    def letter_posteriors(self, mask: str, guessed: Set[str]) -> Dict[str, float]:\n",
        "        P_hmm = self.bigram_hmm.letter_posteriors(mask, guessed)\n",
        "        P_pos = self._positional_score(mask, guessed)\n",
        "        P_cooc = self._cooccurrence_score(mask, guessed)\n",
        "\n",
        "        vowel_boost = {}\n",
        "        if len(guessed) < 3:\n",
        "            vowel_boost = {'a': 1.2, 'e': 1.3, 'i': 1.1, 'o': 1.1, 'u': 1.0}\n",
        "\n",
        "        w_hmm, w_pos, w_cooc = 0.5, 0.3, 0.2\n",
        "        P = {}\n",
        "        for c in ALPHABET:\n",
        "            if c not in guessed:\n",
        "                score = (w_hmm * P_hmm.get(c, 0.0) +\n",
        "                         w_pos * P_pos.get(c, 0.0) +\n",
        "                         w_cooc * P_cooc.get(c, 0.0))\n",
        "                if vowel_boost:\n",
        "                    score *= vowel_boost.get(c, 1.0)\n",
        "                P[c] = score\n",
        "\n",
        "        Z = sum(P.values())\n",
        "        if Z > 0:\n",
        "            for c in P: P[c] /= Z\n",
        "        else:\n",
        "            rem = [c for c in ALPHABET if c not in guessed]\n",
        "            P = {c: 1.0/len(rem) for c in rem} if rem else {c: 0.0 for c in ALPHABET}\n",
        "        return P\n",
        "\n",
        "\n",
        "# Build both versions for comparison\n",
        "print(\"Building Count-HMM (basic bigram)...\")\n",
        "count_hmm = CountHMMOracle(corpus_words, smooth=1.0, by_length=True)\n",
        "\n",
        "print(\"Building Improved-HMM (with positional + co-occurrence)...\")\n",
        "improved_hmm = ImprovedCountHMMOracle(corpus_words, smooth=1.0)\n",
        "\n",
        "# Evaluate both (now using the local simulate_greedy)\n",
        "count_stats = evaluate_oracle_topk(count_hmm, test_words, revelation_levels=(0.2,0.4,0.6), tests_per_word=2)\n",
        "count_greedy = simulate_greedy(test_words, count_hmm, games=min(500, len(test_words)))\n",
        "\n",
        "improved_stats = evaluate_oracle_topk(improved_hmm, test_words, revelation_levels=(0.2,0.4,0.6), tests_per_word=2)\n",
        "improved_greedy = simulate_greedy(test_words, improved_hmm, games=min(500, len(test_words)))\n",
        "\n",
        "print(\"\\n=== Basic Count-HMM ===\")\n",
        "print(count_stats)\n",
        "print(count_greedy)\n",
        "\n",
        "print(\"\\n=== Improved HMM ===\")\n",
        "print(improved_stats)\n",
        "print(improved_greedy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr7sYuA8OBu8",
        "outputId": "cbb2f591-3ad7-4288-9281-77d4ded28dde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Hybrid (Basic HMM) ===\n",
            "{'top1': 0.5665632077845818, 'top3': 0.854039090680312, 'top5': 0.9354081033470346, 'cases': 11921}\n",
            "{'games': 500, 'win_rate': 0.356, 'avg_wrong': 5.072, 'avg_repeated': 0.0}\n",
            "\n",
            "=== Hybrid (Improved HMM) ===\n",
            "{'top1': 0.5662276654643067, 'top3': 0.8531163492995554, 'top5': 0.9342337052260716, 'cases': 11921}\n",
            "{'games': 500, 'win_rate': 0.352, 'avg_wrong': 5.098, 'avg_repeated': 0.0}\n"
          ]
        }
      ],
      "source": [
        "# === Cell 7 (fixed): Hybrid with Improved-HMM + self-contained greedy sim ===\n",
        "import numpy as np\n",
        "\n",
        "# Provide a local greedy simulator if not already defined (from Cell 6)\n",
        "if 'simulate_greedy' not in globals():\n",
        "    def _play_greedy_local(word: str, oracle) -> dict:\n",
        "        mask = ['_'] * len(word)\n",
        "        guessed = set()\n",
        "        lives = 6\n",
        "        wrong = 0\n",
        "        repeated = 0\n",
        "        while lives > 0 and '_' in mask:\n",
        "            probs = oracle.letter_posteriors(''.join(mask), guessed)\n",
        "            if probs:\n",
        "                guess = max(probs.items(), key=lambda kv: kv[1])[0]\n",
        "            else:\n",
        "                # fallback to first unguessed letter\n",
        "                choices = [c for c in ALPHABET if c not in guessed]\n",
        "                guess = choices[0] if choices else None\n",
        "            if guess is None:\n",
        "                break\n",
        "            if guess in guessed:\n",
        "                repeated += 1\n",
        "                continue\n",
        "            guessed.add(guess)\n",
        "            if guess in word:\n",
        "                for i, ch in enumerate(word):\n",
        "                    if ch == guess:\n",
        "                        mask[i] = ch\n",
        "            else:\n",
        "                wrong += 1\n",
        "                lives -= 1\n",
        "        return {\"win\": ('_' not in mask), \"wrong\": wrong, \"repeated\": repeated}\n",
        "\n",
        "    def simulate_greedy(words: list[str], oracle, games=200):\n",
        "        rng = np.random.default_rng(2)\n",
        "        sample = words if len(words) <= games else list(rng.choice(words, size=games, replace=False))\n",
        "        wins = 0\n",
        "        tot_wrong = 0\n",
        "        tot_rep = 0\n",
        "        for w in sample:\n",
        "            r = _play_greedy_local(w, oracle)\n",
        "            wins += int(r[\"win\"])\n",
        "            tot_wrong += r[\"wrong\"]\n",
        "            tot_rep += r[\"repeated\"]\n",
        "        return {\n",
        "            \"games\": len(sample),\n",
        "            \"win_rate\": wins/len(sample),\n",
        "            \"avg_wrong\": tot_wrong/len(sample),\n",
        "            \"avg_repeated\": tot_rep/len(sample)\n",
        "        }\n",
        "\n",
        "def hybrid_posteriors(mask: str, guessed: set[str], hmm_oracle, cfp_oracle, lam=0.5):\n",
        "    Ph = hmm_oracle.letter_posteriors(mask, guessed)\n",
        "    Pc = cfp_oracle.letter_posteriors(mask, guessed)\n",
        "    keys = {c for c in ALPHABET if c not in guessed}\n",
        "    P = {c: lam*Ph.get(c,0.0) + (1-lam)*Pc.get(c,0.0) for c in keys}\n",
        "    Z = sum(P.values())\n",
        "    if Z > 0:\n",
        "        for c in P:\n",
        "            P[c] /= Z\n",
        "    return P\n",
        "\n",
        "class HybridOracle:\n",
        "    def __init__(self, hmm_oracle, cfp_oracle, lam=0.5):\n",
        "        self.hmm = hmm_oracle\n",
        "        self.cfp = cfp_oracle\n",
        "        self.lam = lam\n",
        "    def letter_posteriors(self, mask, guessed):\n",
        "        return hybrid_posteriors(mask, guessed, self.hmm, self.cfp, self.lam)\n",
        "\n",
        "# Create hybrids with both HMM versions\n",
        "LAM = 0.5  # tune 0.3–0.7 if you want\n",
        "hyb_basic    = HybridOracle(count_hmm,    cfp, lam=LAM)\n",
        "hyb_improved = HybridOracle(improved_hmm, cfp, lam=LAM)\n",
        "\n",
        "hyb_basic_stats     = evaluate_oracle_topk(hyb_basic, test_words, revelation_levels=(0.2,0.4,0.6), tests_per_word=2)\n",
        "hyb_basic_greedy    = simulate_greedy(test_words, hyb_basic, games=min(500, len(test_words)))\n",
        "\n",
        "hyb_improved_stats  = evaluate_oracle_topk(hyb_improved, test_words, revelation_levels=(0.2,0.4,0.6), tests_per_word=2)\n",
        "hyb_improved_greedy = simulate_greedy(test_words, hyb_improved, games=min(500, len(test_words)))\n",
        "\n",
        "print(\"\\n=== Hybrid (Basic HMM) ===\")\n",
        "print(hyb_basic_stats)\n",
        "print(hyb_basic_greedy)\n",
        "\n",
        "print(\"\\n=== Hybrid (Improved HMM) ===\")\n",
        "print(hyb_improved_stats)\n",
        "print(hyb_improved_greedy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmkfWFTSOGbJ",
        "outputId": "dd8e4055-807b-4dab-b9b2-2de1aa9ceeef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CFP (Baseline) ===\n",
            "Top-1: 0.432 | Top-3: 0.669 | Top-5: 0.784 | Cases: 11921\n",
            "Greedy win_rate: 0.024 | avg_wrong: 5.94 | avg_repeated: 0.00 | games: 500\n",
            "Proxy Final Score: -14807.0\n",
            "\n",
            "=== Count-HMM (Basic) ===\n",
            "Top-1: 0.539 | Top-3: 0.850 | Top-5: 0.935 | Cases: 11921\n",
            "Greedy win_rate: 0.348 | avg_wrong: 5.15 | avg_repeated: 0.00 | games: 500\n",
            "Proxy Final Score: -12179.0\n",
            "\n",
            "=== Improved-HMM ===\n",
            "Top-1: 0.530 | Top-3: 0.850 | Top-5: 0.933 | Cases: 11921\n",
            "Greedy win_rate: 0.354 | avg_wrong: 5.14 | avg_repeated: 0.00 | games: 500\n",
            "Proxy Final Score: -12132.0\n",
            "\n",
            "=== Hybrid (Basic HMM + CFP) ===\n",
            "Top-1: 0.567 | Top-3: 0.854 | Top-5: 0.935 | Cases: 11921\n",
            "Greedy win_rate: 0.356 | avg_wrong: 5.07 | avg_repeated: 0.00 | games: 500\n",
            "Proxy Final Score: -11968.0\n",
            "\n",
            "=== Hybrid (Improved HMM + CFP) ===\n",
            "Top-1: 0.566 | Top-3: 0.853 | Top-5: 0.934 | Cases: 11921\n",
            "Greedy win_rate: 0.352 | avg_wrong: 5.10 | avg_repeated: 0.00 | games: 500\n",
            "Proxy Final Score: -12041.0\n",
            "\n",
            "============================================================\n",
            ">>> WINNER (by proxy final score): Hybrid (Basic HMM + CFP)\n",
            ">>> Final Score: -11968.0\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# === Cell 8 (robust): Head-to-head comparison & winner ===\n",
        "import numpy as np\n",
        "\n",
        "# 0) tiny greedy sim if not present (same as in Cell 7)\n",
        "if 'simulate_greedy' not in globals():\n",
        "    def _play_greedy_local(word: str, oracle) -> dict:\n",
        "        mask = ['_'] * len(word)\n",
        "        guessed = set()\n",
        "        lives = 6\n",
        "        wrong = 0\n",
        "        repeated = 0\n",
        "        while lives > 0 and '_' in mask:\n",
        "            probs = oracle.letter_posteriors(''.join(mask), guessed)\n",
        "            if probs:\n",
        "                guess = max(probs.items(), key=lambda kv: kv[1])[0]\n",
        "            else:\n",
        "                choices = [c for c in ALPHABET if c not in guessed]\n",
        "                guess = choices[0] if choices else None\n",
        "            if guess is None:\n",
        "                break\n",
        "            if guess in guessed:\n",
        "                repeated += 1\n",
        "                continue\n",
        "            guessed.add(guess)\n",
        "            if guess in word:\n",
        "                for i, ch in enumerate(word):\n",
        "                    if ch == guess:\n",
        "                        mask[i] = ch\n",
        "            else:\n",
        "                wrong += 1\n",
        "                lives -= 1\n",
        "        return {\"win\": ('_' not in mask), \"wrong\": wrong, \"repeated\": repeated}\n",
        "\n",
        "    def simulate_greedy(words: list[str], oracle, games=200):\n",
        "        rng = np.random.default_rng(3)\n",
        "        sample = words if len(words) <= games else list(rng.choice(words, size=games, replace=False))\n",
        "        wins = 0\n",
        "        tot_wrong = 0\n",
        "        tot_rep = 0\n",
        "        for w in sample:\n",
        "            r = _play_greedy_local(w, oracle)\n",
        "            wins += int(r[\"win\"])\n",
        "            tot_wrong += r[\"wrong\"]\n",
        "            tot_rep += r[\"repeated\"]\n",
        "        return {\n",
        "            \"games\": len(sample),\n",
        "            \"win_rate\": wins/len(sample),\n",
        "            \"avg_wrong\": tot_wrong/len(sample),\n",
        "            \"avg_repeated\": tot_rep/len(sample)\n",
        "        }\n",
        "\n",
        "def final_like_score(g):\n",
        "    \"\"\"Proxy of hackathon score using greedy stats.\"\"\"\n",
        "    G = g[\"games\"]; wr = g[\"win_rate\"]\n",
        "    tot_wrong = g[\"avg_wrong\"] * G\n",
        "    tot_rep   = g[\"avg_repeated\"] * G\n",
        "    return wr*2000 - (tot_wrong*5) - (tot_rep*2)\n",
        "\n",
        "def show(name, topk_stats, greedy_stats):\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(f\"Top-1: {topk_stats['top1']:.3f} | Top-3: {topk_stats['top3']:.3f} | Top-5: {topk_stats['top5']:.3f} | Cases: {topk_stats['cases']}\")\n",
        "    print(f\"Greedy win_rate: {greedy_stats['win_rate']:.3f} | avg_wrong: {greedy_stats['avg_wrong']:.2f} | avg_repeated: {greedy_stats['avg_repeated']:.2f} | games: {greedy_stats['games']}\")\n",
        "    print(f\"Proxy Final Score: {final_like_score(greedy_stats):.1f}\")\n",
        "\n",
        "# 1) Collect whatever oracles you have\n",
        "oracles = []\n",
        "oracles.append((\"CFP (Baseline)\",        cfp))\n",
        "if 'count_hmm'    in globals(): oracles.append((\"Count-HMM (Basic)\",       count_hmm))\n",
        "if 'improved_hmm' in globals(): oracles.append((\"Improved-HMM\",            improved_hmm))\n",
        "if 'hyb_basic'    in globals(): oracles.append((\"Hybrid (Basic HMM + CFP)\", hyb_basic))\n",
        "if 'hyb_improved' in globals(): oracles.append((\"Hybrid (Improved HMM + CFP)\", hyb_improved))\n",
        "\n",
        "# 2) Ensure stats objects exist; compute if missing\n",
        "def ensure_stats(name, oracle, topk_varname, greedy_varname):\n",
        "    topk = globals().get(topk_varname)\n",
        "    greedy = globals().get(greedy_varname)\n",
        "    if topk is None:\n",
        "        topk = evaluate_oracle_topk(oracle, test_words, revelation_levels=(0.2,0.4,0.6), tests_per_word=2)\n",
        "        globals()[topk_varname] = topk\n",
        "    if greedy is None:\n",
        "        greedy = simulate_greedy(test_words, oracle, games=min(500, len(test_words)))\n",
        "        globals()[greedy_varname] = greedy\n",
        "    show(name, topk, greedy)\n",
        "    return (name, greedy)\n",
        "\n",
        "name_map_to_vars = {\n",
        "    \"CFP (Baseline)\":                    (\"cfp_stats\", \"greedy_cfp\"),\n",
        "    \"Count-HMM (Basic)\":                 (\"count_stats\", \"count_greedy\"),\n",
        "    \"Improved-HMM\":                      (\"improved_stats\", \"improved_greedy\"),\n",
        "    \"Hybrid (Basic HMM + CFP)\":          (\"hyb_basic_stats\", \"hyb_basic_greedy\"),\n",
        "    \"Hybrid (Improved HMM + CFP)\":       (\"hyb_improved_stats\", \"hyb_improved_greedy\"),\n",
        "}\n",
        "\n",
        "candidates = []\n",
        "for (disp_name, oracle) in oracles:\n",
        "    tv, gv = name_map_to_vars[disp_name]\n",
        "    candidates.append(ensure_stats(disp_name, oracle, tv, gv))\n",
        "\n",
        "# 3) Pick winner by proxy score\n",
        "winner = max(candidates, key=lambda x: final_like_score(x[1]))\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\">>> WINNER (by proxy final score): {winner[0]}\")\n",
        "print(f\">>> Final Score: {final_like_score(winner[1]):.1f}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cov2OdcuOkDi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}