# ML-hackathon-Group-1
# Hackman AI Project - File Structure Guide

## Project Overview
This project implements AI agents for playing Hangman using Hidden Markov Models (HMM) and Reinforcement Learning (RL) approaches. The system evolves from basic HMM to hybrid models combining multiple techniques.

---

## File Descriptions

### 1. HMMCount.ipynb
Level: Basic Implementation  
Description: Initial HMM-based Hangman solver using count-based probabilities
- Implements fundamental HMM with letter frequency analysis
- Uses simple probability distributions for letter predictions
- Serves as the baseline model for comparison
- Focuses on corpus analysis and basic pattern recognition

Key Features:
- Corpus preprocessing and word length analysis
- Letter frequency calculations
- Basic HMM training and evaluation
- Simple game simulation

### 2. HMM_Hybrid(CFP+Countbased)__rl_Q_table_DQN.ipynb
Level: Intermediate - Advanced Implementation  
Description: Hybrid model combining multiple approaches with Reinforcement Learning
- Integrates Candidate Filtering (CFP) with count-based HMM
- Implements both Q-table and Deep Q-Network (DQN) RL agents
- Features dynamic weighting between different approaches
- Includes comprehensive training and evaluation pipelines

Key Features:
- Hybrid CFP + HMM probability combination
- Q-table based RL agent (saves as q_table.pkl)
- Deep Q-Network RL agent (saves as dqn.pth)
- Advanced state representation (100 features)
- Curriculum learning for RL training
- Multi-agent comparison and evaluation

### 3. hmm_hybrid_final_best.ipynb
Level: Final Implementation  
Description: Most refined and optimized version of the Hangman AI system
- Incorporates lessons learned from previous implementations
- Contains the most stable and best-performing model
- Includes all improvements and bug fixes
- Represents the final submission version

Key Features:
- Optimized hyperparameters
- Enhanced reward functions
- Improved state representations
- Better exploration strategies
- Comprehensive evaluation metrics
- Production-ready model architecture

---

## Data Files

### corpus.txt
- Purpose: Training dataset
- Content: Large collection of English words
- Usage: Used to train HMM transition probabilities and RL agents
- Format: One word per line, plain text

### test.txt  
- Purpose: Evaluation dataset
- Content: Separate set of words for testing performance
- Usage: Used for final evaluation and scoring
- Format: One word per line, plain text

---

## Model Output Files

### dqn.pth
- Type: PyTorch model file
- Description: Trained Deep Q-Network weights
- Generated by: HMM_Hybrid notebook
- Usage: RL agent that uses neural network for Q-value approximation

### q_table.pkl
- Type: Pickle file
- Description: Q-table storing state-action values
- Generated by: HMM_Hybrid notebook
- Usage: Tabular RL agent for simpler state representations




## Dependencies

- Python 3.7+
- NumPy
- PyTorch
- hmmlearn
- scikit-learn
- matplotlib
- seaborn

All dependencies are installed within the notebooks using pip commands.

---

## Evaluation Metrics

All implementations use the official scoring formula:
```
Final Score = (Success Rate × 2000) - (Total Wrong Guesses × 5) - (Total Repeated Guesses × 2)
```

Success is measured by winning games within 6 wrong guesses maximum.

---

## Key Concepts Implemented

- Hidden Markov Models for letter sequence prediction
- Candidate Filtering for word-based probability estimation
- Q-learning and Deep Q-Networks for reinforcement learning
- Hybrid model architectures combining multiple approaches
- Advanced state representations and reward engineering
- Exploration vs exploitation trade-off management

This project demonstrates the evolution from basic probabilistic models to sophisticated hybrid AI systems for word game solving.
