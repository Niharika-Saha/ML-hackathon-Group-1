{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYiw72pKa7WH",
        "outputId": "3a4b6230-917b-4d24-a119-08f4d56b87c4"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import string\n",
        "from collections import defaultdict, Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from hmmlearn import hmm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ecThAGa8jN",
        "outputId": "c5931206-7a65-40e5-f2c0-0a9d0dc278a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total words after preprocessing: 49979\n",
            "Word length distribution:\n",
            "  Length 1: 46 words\n",
            "  Length 2: 84 words\n",
            "  Length 3: 388 words\n",
            "  Length 4: 1169 words\n",
            "  Length 5: 2340 words\n",
            "  Length 6: 3755 words\n",
            "  Length 7: 5111 words\n",
            "  Length 8: 6348 words\n",
            "  Length 9: 6787 words\n",
            "  Length 10: 6465 words\n",
            "  Length 11: 5452 words\n",
            "  Length 12: 4292 words\n",
            "  Length 13: 3094 words\n",
            "  Length 14: 2019 words\n",
            "  Length 15: 1226 words\n",
            "  Length 16: 698 words\n",
            "  Length 17: 375 words\n",
            "  Length 18: 174 words\n",
            "  Length 19: 88 words\n",
            "  Length 20: 40 words\n",
            "  Length 21: 16 words\n",
            "  Length 22: 8 words\n",
            "  Length 23: 3 words\n",
            "  Length 24: 1 words\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Load and preprocess the corpus\n",
        "def load_and_preprocess_corpus(file_path):\n",
        "    \"\"\"\n",
        "    Load the corpus and preprocess words\n",
        "    - Convert to uppercase\n",
        "    - Remove words with non-alphabet characters\n",
        "    - Group by word length\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        words = [line.strip().upper() for line in f if line.strip()]\n",
        "\n",
        "    # Filter only alphabetic words\n",
        "    words = [word for word in words if word.isalpha()]\n",
        "\n",
        "    # Group words by length\n",
        "    words_by_length = defaultdict(list)\n",
        "    for word in words:\n",
        "        words_by_length[len(word)].append(word)\n",
        "\n",
        "    print(f\"Total words after preprocessing: {len(words)}\")\n",
        "    print(f\"Word length distribution:\")\n",
        "    for length in sorted(words_by_length.keys()):\n",
        "        print(f\"  Length {length}: {len(words_by_length[length])} words\")\n",
        "\n",
        "    return words, words_by_length\n",
        "\n",
        "# Load the corpus (upload your corpus.txt first)\n",
        "words, words_by_length = load_and_preprocess_corpus('corpus.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyviOITja_w0",
        "outputId": "727939c9-00a3-4390-d4ac-5537ff91130e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall letter frequency (top 10):\n",
            "  E: 49203 (10.37%)\n",
            "  A: 42089 (8.87%)\n",
            "  I: 42047 (8.86%)\n",
            "  O: 35808 (7.54%)\n",
            "  R: 33577 (7.07%)\n",
            "  N: 33314 (7.02%)\n",
            "  T: 32191 (6.78%)\n",
            "  S: 29044 (6.12%)\n",
            "  L: 27406 (5.77%)\n",
            "  C: 21718 (4.58%)\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Analyze letter frequencies and patterns\n",
        "def analyze_corpus(words_by_length):\n",
        "    \"\"\"\n",
        "    Analyze letter frequencies and positional distributions\n",
        "    \"\"\"\n",
        "    # Overall letter frequency\n",
        "    all_letters = ''.join([''.join(words) for words in words_by_length.values()])\n",
        "    letter_freq = Counter(all_letters)\n",
        "\n",
        "    print(\"Overall letter frequency (top 10):\")\n",
        "    for letter, freq in letter_freq.most_common(10):\n",
        "        print(f\"  {letter}: {freq} ({freq/len(all_letters)*100:.2f}%)\")\n",
        "\n",
        "    # Positional frequency analysis for different lengths\n",
        "    positional_freq = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for length, word_list in words_by_length.items():\n",
        "        for word in word_list:\n",
        "            for pos, letter in enumerate(word):\n",
        "                positional_freq[length][(pos, letter)] += 1\n",
        "\n",
        "    return letter_freq, positional_freq\n",
        "\n",
        "letter_freq, positional_freq = analyze_corpus(words_by_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4jxdAW0bESj",
        "outputId": "54a36155-1519-4b7e-9932-e00c6a36531f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available word lengths: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
            "Lengths 22, 23, 24 present: True, True, True\n",
            "Length 11: 5452 sequences\n",
            "Length 6: 3755 sequences\n",
            "Length 9: 6787 sequences\n",
            "Length 16: 698 sequences\n",
            "Length 14: 2019 sequences\n",
            "Length 10: 6465 sequences\n",
            "Length 8: 6348 sequences\n",
            "Length 12: 4292 sequences\n",
            "Length 13: 3094 sequences\n",
            "Length 5: 2340 sequences\n",
            "Length 18: 174 sequences\n",
            "Length 4: 1169 sequences\n",
            "Length 3: 388 sequences\n",
            "Length 7: 5111 sequences\n",
            "Length 15: 1226 sequences\n",
            "Length 17: 375 sequences\n",
            "Length 22: 8 sequences\n",
            "Length 19: 88 sequences\n",
            "Length 2: 84 sequences\n",
            "Length 1: 46 sequences\n",
            "Length 20: 40 sequences\n",
            "Length 21: 16 sequences\n",
            "Length 23: 3 sequences\n",
            "Length 24: 1 sequences\n",
            "‚úì INCLUDED - Length 22: 8 sequences\n",
            "‚úì INCLUDED - Length 23: 3 sequences\n",
            "‚úì INCLUDED - Length 24: 1 sequences\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Prepare HMM training data for each word length\n",
        "def prepare_hmm_training_data(words_by_length, min_words_threshold=5):\n",
        "    \"\"\"\n",
        "    Prepare training data for HMMs for each word length\n",
        "    Convert words to numerical sequences for HMM training\n",
        "\n",
        "    Parameters:\n",
        "    - words_by_length: Dictionary of words grouped by length\n",
        "    - min_words_threshold: Minimum number of words required to train HMM for a given length\n",
        "    \"\"\"\n",
        "    # Create letter to index mapping (A=0, B=1, ..., Z=25)\n",
        "    letters = string.ascii_uppercase\n",
        "    letter_to_idx = {letter: idx for idx, letter in enumerate(letters)}\n",
        "\n",
        "    training_data = {}\n",
        "\n",
        "    # Print available word lengths for debugging\n",
        "    available_lengths = sorted(words_by_length.keys())\n",
        "    print(f\"Available word lengths: {available_lengths}\")\n",
        "    print(f\"Lengths 22, 23, 24 present: {22 in words_by_length}, {23 in words_by_length}, {24 in words_by_length}\")\n",
        "\n",
        "    for length, word_list in words_by_length.items():\n",
        "        # Include all lengths including 22, 23, 24 if they have enough words\n",
        "        if len(word_list) < min_words_threshold:\n",
        "            print(f\"Skipping length {length}: only {len(word_list)} words (need at least {min_words_threshold})\")\n",
        "            continue\n",
        "\n",
        "        sequences = []\n",
        "        for word in word_list:\n",
        "            # Convert word to numerical sequence\n",
        "            seq = [letter_to_idx[char] for char in word]\n",
        "            sequences.append(seq)\n",
        "\n",
        "        training_data[length] = np.array(sequences)\n",
        "\n",
        "        print(f\"Length {length}: {len(sequences)} sequences\")\n",
        "\n",
        "    # Specifically check and report on lengths 22, 23, 24\n",
        "    for length in [22, 23, 24]:\n",
        "        if length in training_data:\n",
        "            print(f\"‚úì INCLUDED - Length {length}: {len(training_data[length])} sequences\")\n",
        "        elif length in words_by_length:\n",
        "            print(f\"‚úó EXCLUDED - Length {length}: {len(words_by_length[length])} words (below threshold)\")\n",
        "        else:\n",
        "            print(f\"‚úó NOT FOUND - Length {length}: No words in corpus\")\n",
        "\n",
        "    return training_data, letter_to_idx\n",
        "\n",
        "# Run with lower threshold to include more word lengths\n",
        "training_data, letter_to_idx = prepare_hmm_training_data(words_by_length, min_words_threshold=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "100oXZOg8OVl",
        "outputId": "5139ab75-d112-4e29-d45b-ca8af33a3ede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Hybrid CFP + Count-based HMM Model...\n",
            "Training Count-based HMMs for Hybrid Model...\n",
            "Length 11: 5452 sequences\n",
            "Length 6: 3755 sequences\n",
            "Length 9: 6787 sequences\n",
            "Length 16: 698 sequences\n",
            "Length 14: 2019 sequences\n",
            "Length 10: 6465 sequences\n",
            "Length 8: 6348 sequences\n",
            "Length 12: 4292 sequences\n",
            "Length 13: 3094 sequences\n",
            "Length 5: 2340 sequences\n",
            "Length 18: 174 sequences\n",
            "Length 4: 1169 sequences\n",
            "Length 3: 388 sequences\n",
            "Length 7: 5111 sequences\n",
            "Length 15: 1226 sequences\n",
            "Length 17: 375 sequences\n",
            "Length 22: 8 sequences\n",
            "Length 19: 88 sequences\n",
            "Length 2: 84 sequences\n",
            "Length 1: 46 sequences\n",
            "Length 20: 40 sequences\n",
            "Length 21: 16 sequences\n",
            "Length 23: 3 sequences\n",
            "Length 24: 1 sequences\n",
            "Trained 24 count-based HMMs\n",
            "Hybrid Model Initialized: CFP weight=0.7, HMM weight=0.3\n",
            "\n",
            "============================================================\n",
            "HYBRID MODEL READY!\n",
            "============================================================\n",
            "CFP Oracle: Word-based candidate filtering\n",
            "Count-based HMM: Statistical pattern learning\n",
            "Dynamic weighting: Adaptive confidence-based blending\n",
            "All word lengths supported\n",
            "Initial blend: 70% CFP + 30% HMM\n",
            "\n",
            "Ready for evaluation with 2000 games!\n"
          ]
        }
      ],
      "source": [
        "# Step 6: HYBRID CFP + Count-based HMM Training\n",
        "class HybridHangmanModel:\n",
        "    \"\"\"\n",
        "    Combines the best of CFP (accuracy) and HMM (generalization)\n",
        "    \"\"\"\n",
        "    def __init__(self, corpus_words, training_data, letter_to_idx, alpha=0.3):\n",
        "        self.cfp = CandidateFilterOracle(corpus_words)\n",
        "        self.count_hmms = train_count_hmm_models(training_data)\n",
        "        self.letter_to_idx = letter_to_idx\n",
        "        self.letters = string.ascii_uppercase\n",
        "        self.alpha = alpha  # Weight for HMM (0-1), CFP weight = 1-alpha\n",
        "\n",
        "        print(f\"Hybrid Model Initialized: CFP weight={1-alpha:.1f}, HMM weight={alpha:.1f}\")\n",
        "\n",
        "    def get_letter_probabilities(self, masked_word, guessed_letters):\n",
        "        \"\"\"\n",
        "        Combine CFP and Count-based HMM probabilities\n",
        "        \"\"\"\n",
        "        # Get CFP probabilities (high accuracy)\n",
        "        cfp_probs = self.cfp.get_letter_probabilities(masked_word, guessed_letters)\n",
        "\n",
        "        # Get HMM probabilities (good generalization)\n",
        "        hmm_probs = self._get_hmm_probabilities(masked_word, guessed_letters)\n",
        "\n",
        "        # If CFP has no candidates, rely more on HMM\n",
        "        if not cfp_probs or max(cfp_probs.values()) == 0:\n",
        "            return hmm_probs\n",
        "\n",
        "        # If HMM failed, rely on CFP\n",
        "        if not hmm_probs:\n",
        "            return cfp_probs\n",
        "\n",
        "        # Combine probabilities\n",
        "        hybrid_probs = {}\n",
        "        for letter in self.letters:\n",
        "            if letter not in guessed_letters:\n",
        "                cfp_prob = cfp_probs.get(letter, 0)\n",
        "                hmm_prob = hmm_probs.get(letter, 0)\n",
        "\n",
        "                # Dynamic weighting: if CFP is confident, trust it more\n",
        "                cfp_confidence = max(cfp_probs.values())\n",
        "                dynamic_alpha = self.alpha * (1 - cfp_confidence)  # Less HMM weight if CFP is confident\n",
        "\n",
        "                hybrid_prob = (1 - dynamic_alpha) * cfp_prob + dynamic_alpha * hmm_prob\n",
        "                hybrid_probs[letter] = hybrid_prob\n",
        "\n",
        "        # Normalize\n",
        "        total = sum(hybrid_probs.values())\n",
        "        if total > 0:\n",
        "            hybrid_probs = {letter: prob/total for letter, prob in hybrid_probs.items()}\n",
        "\n",
        "        return hybrid_probs\n",
        "\n",
        "    def _get_hmm_probabilities(self, masked_word, guessed_letters):\n",
        "        \"\"\"Get probabilities from count-based HMM\"\"\"\n",
        "        word_length = len(masked_word)\n",
        "\n",
        "        if word_length not in self.count_hmms:\n",
        "            return {}\n",
        "\n",
        "        model = self.count_hmms[word_length]\n",
        "\n",
        "        # Prepare observations\n",
        "        observations = []\n",
        "        for char in masked_word:\n",
        "            if char == '_':\n",
        "                observations.append(-1)  # Missing\n",
        "            else:\n",
        "                observations.append(self.letter_to_idx[char])\n",
        "\n",
        "        try:\n",
        "            # Get posteriors using count-based HMM\n",
        "            posteriors = model.forward_backward(observations)\n",
        "\n",
        "            # Aggregate probabilities for blank positions\n",
        "            letter_probs = np.zeros(26)\n",
        "            for pos, char in enumerate(masked_word):\n",
        "                if char == '_':\n",
        "                    for letter_idx in range(26):\n",
        "                        letter = self.idx_to_letter(letter_idx)\n",
        "                        if letter not in guessed_letters:\n",
        "                            letter_probs[letter_idx] += posteriors[pos, letter_idx]\n",
        "\n",
        "            # Normalize\n",
        "            if np.sum(letter_probs) > 0:\n",
        "                letter_probs /= np.sum(letter_probs)\n",
        "\n",
        "            return {self.idx_to_letter(i): letter_probs[i]\n",
        "                    for i in range(26) if self.idx_to_letter(i) not in guessed_letters}\n",
        "\n",
        "        except Exception as e:\n",
        "            return {}\n",
        "\n",
        "    def idx_to_letter(self, idx):\n",
        "        \"\"\"Convert index to letter\"\"\"\n",
        "        return chr(65 + idx)\n",
        "\n",
        "# COUNT-BASED HMM IMPLEMENTATION (from previous)\n",
        "class CountBasedHMM:\n",
        "    def __init__(self):\n",
        "        self.transition_probs = None\n",
        "        self.emission_probs = None\n",
        "        self.initial_probs = None\n",
        "\n",
        "    def train(self, sequences, alpha=0.1):\n",
        "        n_states = 26\n",
        "\n",
        "        # Initialize counts with smoothing\n",
        "        transition_counts = np.ones((n_states, n_states)) * alpha\n",
        "        emission_counts = np.ones((n_states, n_states)) * alpha\n",
        "        initial_counts = np.ones(n_states) * alpha\n",
        "\n",
        "        # Count transitions and emissions\n",
        "        for seq in sequences:\n",
        "            if len(seq) > 0:\n",
        "                initial_counts[seq[0]] += 1\n",
        "\n",
        "            for i in range(len(seq)):\n",
        "                emission_counts[seq[i], seq[i]] += 1\n",
        "                if i < len(seq) - 1:\n",
        "                    transition_counts[seq[i], seq[i+1]] += 1\n",
        "\n",
        "        # Convert to probabilities\n",
        "        self.initial_probs = initial_counts / np.sum(initial_counts)\n",
        "        self.transition_probs = transition_counts / np.sum(transition_counts, axis=1, keepdims=True)\n",
        "        self.emission_probs = emission_counts / np.sum(emission_counts, axis=1, keepdims=True)\n",
        "\n",
        "    def forward_backward(self, observations):\n",
        "        n_positions = len(observations)\n",
        "        n_states = 26\n",
        "\n",
        "        # Forward pass\n",
        "        forward = np.zeros((n_positions, n_states))\n",
        "        for state in range(n_states):\n",
        "            if observations[0] == -1:\n",
        "                forward[0, state] = self.initial_probs[state]\n",
        "            else:\n",
        "                forward[0, state] = self.initial_probs[state] * self.emission_probs[state, observations[0]]\n",
        "\n",
        "        for t in range(1, n_positions):\n",
        "            for j in range(n_states):\n",
        "                sum_prob = 0\n",
        "                for i in range(n_states):\n",
        "                    sum_prob += forward[t-1, i] * self.transition_probs[i, j]\n",
        "\n",
        "                if observations[t] == -1:\n",
        "                    forward[t, j] = sum_prob\n",
        "                else:\n",
        "                    forward[t, j] = sum_prob * self.emission_probs[j, observations[t]]\n",
        "\n",
        "        # Backward pass\n",
        "        backward = np.ones((n_positions, n_states))\n",
        "        for t in range(n_positions-2, -1, -1):\n",
        "            for i in range(n_states):\n",
        "                sum_prob = 0\n",
        "                for j in range(n_states):\n",
        "                    if observations[t+1] == -1:\n",
        "                        emission_prob = 1.0\n",
        "                    else:\n",
        "                        emission_prob = self.emission_probs[j, observations[t+1]]\n",
        "                    sum_prob += self.transition_probs[i, j] * emission_prob * backward[t+1, j]\n",
        "                backward[t, i] = sum_prob\n",
        "\n",
        "        # Combine\n",
        "        posteriors = forward * backward\n",
        "        posteriors = posteriors / np.sum(posteriors, axis=1, keepdims=True)\n",
        "        return posteriors\n",
        "\n",
        "\n",
        "def train_count_hmm_models(training_data):\n",
        "    \"\"\"Train count-based HMMs for all word lengths\"\"\"\n",
        "    count_hmms = {}\n",
        "\n",
        "    print(\"Training Count-based HMMs for Hybrid Model...\")\n",
        "    for length, sequences in training_data.items():\n",
        "        if len(sequences) < 1:\n",
        "            continue\n",
        "\n",
        "        print(f\"Length {length}: {len(sequences)} sequences\")\n",
        "        model = CountBasedHMM()\n",
        "        model.train(sequences, alpha=0.1)\n",
        "        count_hmms[length] = model\n",
        "\n",
        "    print(f\"Trained {len(count_hmms)} count-based HMMs\")\n",
        "    return count_hmms\n",
        "\n",
        "# CFP ORACLE (from previous)\n",
        "class CandidateFilterOracle:\n",
        "    def __init__(self, corpus_words):\n",
        "        self.by_len = defaultdict(list)\n",
        "        for word in corpus_words:\n",
        "            w = word.strip().upper()\n",
        "            if w and w.isalpha():\n",
        "                self.by_len[len(w)].append(w)\n",
        "\n",
        "    @staticmethod\n",
        "    def matches_mask(word, mask, wrong_letters):\n",
        "        if len(word) != len(mask):\n",
        "            return False\n",
        "        if any(letter in word for letter in wrong_letters):\n",
        "            return False\n",
        "        for wc, mc in zip(word, mask):\n",
        "            if mc != '_' and wc != mc:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def get_letter_probabilities(self, masked_word, guessed_letters):\n",
        "        word_length = len(masked_word)\n",
        "        revealed_letters = set(char for char in masked_word if char != '_')\n",
        "        wrong_letters = guessed_letters - revealed_letters\n",
        "\n",
        "        # Get candidate words\n",
        "        candidates = [\n",
        "            word for word in self.by_len.get(word_length, [])\n",
        "            if self.matches_mask(word, masked_word, wrong_letters)\n",
        "        ]\n",
        "\n",
        "        if not candidates:\n",
        "            return self._fallback_probs(guessed_letters)\n",
        "\n",
        "        # Count letter frequencies in blank positions\n",
        "        blank_positions = [i for i, char in enumerate(masked_word) if char == '_']\n",
        "        letter_counts = Counter()\n",
        "\n",
        "        for word in candidates:\n",
        "            for pos in blank_positions:\n",
        "                letter_counts[word[pos]] += 1\n",
        "\n",
        "        # Convert to probabilities\n",
        "        total_count = sum(letter_counts.values())\n",
        "        prob_dict = {}\n",
        "        for letter in string.ascii_uppercase:\n",
        "            if letter not in guessed_letters:\n",
        "                prob_dict[letter] = letter_counts[letter] / total_count if total_count > 0 else 0\n",
        "\n",
        "        # Normalize\n",
        "        total_prob = sum(prob_dict.values())\n",
        "        if total_prob > 0:\n",
        "            prob_dict = {letter: prob/total_prob for letter, prob in prob_dict.items()}\n",
        "        else:\n",
        "            prob_dict = self._fallback_probs(guessed_letters)\n",
        "\n",
        "        return prob_dict\n",
        "\n",
        "    def _fallback_probs(self, guessed_letters):\n",
        "        available = [l for l in string.ascii_uppercase if l not in guessed_letters]\n",
        "        prob = 1.0 / len(available) if available else 0\n",
        "        return {letter: prob for letter in available}\n",
        "\n",
        "# INITIALIZE HYBRID MODEL\n",
        "print(\"Initializing Hybrid CFP + Count-based HMM Model...\")\n",
        "hybrid_model = HybridHangmanModel(words, training_data, letter_to_idx, alpha=0.3)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HYBRID MODEL READY!\")\n",
        "print(\"=\"*60)\n",
        "print(\"CFP Oracle: Word-based candidate filtering\")\n",
        "print(\"Count-based HMM: Statistical pattern learning\")\n",
        "print(\"Dynamic weighting: Adaptive confidence-based blending\")\n",
        "print(\"All word lengths supported\")\n",
        "print(f\"Initial blend: {70}% CFP + {30}% HMM\")\n",
        "\n",
        "# Update your main HMM reference to use the hybrid model\n",
        "hangman_hmm = hybrid_model\n",
        "\n",
        "print(\"\\nReady for evaluation with 2000 games!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1APELXJbXA-",
        "outputId": "21a79b3a-33c4-42ce-c603-d7d312db64a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Empty 5-letter word:\n",
            "Masked word: _ _ _ _ _\n",
            "Guessed letters: \n",
            "Top 5 letter predictions:\n",
            "  A: 0.1073\n",
            "  E: 0.0981\n",
            "  O: 0.0694\n",
            "  R: 0.0676\n",
            "  I: 0.0634\n",
            "\n",
            "5-letter word starting with A:\n",
            "Masked word: A _ _ _ _\n",
            "Guessed letters: A\n",
            "Top 5 letter predictions:\n",
            "  E: 0.1023\n",
            "  I: 0.0946\n",
            "  O: 0.0846\n",
            "  N: 0.0731\n",
            "  S: 0.0701\n",
            "\n",
            "5-letter word with E at position 3:\n",
            "Masked word: _ _ _ E _\n",
            "Guessed letters: E\n",
            "Top 5 letter predictions:\n",
            "  R: 0.1329\n",
            "  A: 0.0755\n",
            "  N: 0.0711\n",
            "  L: 0.0675\n",
            "  T: 0.0672\n",
            "\n",
            "Empty 6-letter word:\n",
            "Masked word: _ _ _ _ _ _\n",
            "Guessed letters: \n",
            "Top 5 letter predictions:\n",
            "  E: 0.1116\n",
            "  A: 0.1021\n",
            "  R: 0.0712\n",
            "  I: 0.0709\n",
            "  N: 0.0615\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Test the HMM with example game states\n",
        "def test_hmm_predictions():\n",
        "    \"\"\"Test HMM predictions with various game states\"\"\"\n",
        "\n",
        "    test_cases = [\n",
        "        # (masked_word, guessed_letters, description)\n",
        "        (['_', '_', '_', '_', '_'], set(), \"Empty 5-letter word\"),\n",
        "        (['A', '_', '_', '_', '_'], set('A'), \"5-letter word starting with A\"),\n",
        "        (['_', '_', '_', 'E', '_'], set('E'), \"5-letter word with E at position 3\"),\n",
        "        (['_', '_', '_', '_', '_', '_'], set(), \"Empty 6-letter word\"),\n",
        "    ]\n",
        "\n",
        "    for masked_word, guessed_letters, description in test_cases:\n",
        "        print(f\"\\n{description}:\")\n",
        "        print(f\"Masked word: {' '.join(masked_word)}\")\n",
        "        print(f\"Guessed letters: {''.join(sorted(guessed_letters))}\")\n",
        "\n",
        "        probs = hangman_hmm.get_letter_probabilities(masked_word, guessed_letters)\n",
        "\n",
        "        # Show top 5 predictions\n",
        "        top_letters = sorted(probs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "        print(\"Top 5 letter predictions:\")\n",
        "        for letter, prob in top_letters:\n",
        "            print(f\"  {letter}: {prob:.4f}\")\n",
        "\n",
        "test_hmm_predictions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wanux8QS0PJ",
        "outputId": "9a64b330-0f54-4df8-ae90-cad1786242a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading test words for official evaluation...\n",
            "Loaded 2000 test words for evaluation\n",
            "Starting official 2000-game evaluation...\n",
            "üéØ OFFICIAL EVALUATION - 2000 HANGMAN GAMES\n",
            "============================================================\n",
            "Playing 2000 games with 6 wrong guesses allowed per game\n",
            "\n",
            "üéÆ Played 0/2000 games...\n",
            "üéÆ Played 500/2000 games...\n",
            "üéÆ Played 1000/2000 games...\n",
            "üéÆ Played 1500/2000 games...\n",
            "\n",
            "======================================================================\n",
            "üèÜ OFFICIAL EVALUATION RESULTS\n",
            "======================================================================\n",
            "üìä GAME STATISTICS:\n",
            "   Total Games Played: 2000\n",
            "   Games Won: 703\n",
            "   Games Lost: 1297\n",
            "   Success Rate: 0.351 (703/2000)\n",
            "\n",
            "üéØ PERFORMANCE METRICS:\n",
            "   Total Wrong Guesses: 10213\n",
            "   Total Repeated Guesses: 0\n",
            "   Average Wrong Guesses per Game: 5.11\n",
            "   Average Repeated Guesses per Game: 0.00\n",
            "\n",
            "üí∞ SCORE BREAKDOWN:\n",
            "   Success Component: 703.00\n",
            "   Wrong Guesses Penalty: -51065.00\n",
            "   Repeated Guesses Penalty: -0.00\n",
            "   FINAL SCORE: -50362.00\n",
            "\n",
            "üìà ADDITIONAL INSIGHTS:\n",
            "   Performance by Word Length:\n",
            "     Length 2: 0/2 won (0.0%)\n",
            "     Length 3: 0/9 won (0.0%)\n",
            "     Length 4: 4/37 won (10.8%)\n",
            "     Length 5: 10/91 won (11.0%)\n",
            "     Length 6: 24/138 won (17.4%)\n",
            "     Length 7: 39/205 won (19.0%)\n",
            "     Length 8: 63/246 won (25.6%)\n",
            "     Length 9: 75/274 won (27.4%)\n",
            "     Length 10: 108/282 won (38.3%)\n",
            "     Length 11: 102/226 won (45.1%)\n",
            "     Length 12: 84/164 won (51.2%)\n",
            "     Length 13: 67/128 won (52.3%)\n",
            "     Length 14: 43/86 won (50.0%)\n",
            "     Length 15: 35/47 won (74.5%)\n",
            "     Length 16: 25/33 won (75.8%)\n",
            "     Length 17: 13/17 won (76.5%)\n",
            "     Length 18: 6/8 won (75.0%)\n",
            "     Length 19: 3/3 won (100.0%)\n",
            "     Length 20: 1/2 won (50.0%)\n",
            "     Length 21: 0/1 won (0.0%)\n",
            "     Length 22: 1/1 won (100.0%)\n",
            "   Guess Efficiency: 55.2% (12572/22785 correct guesses)\n",
            "üìÑ Detailed results saved to evaluation_results.txt\n",
            "\n",
            "==================================================\n",
            "üìã PERFORMANCE ASSESSMENT\n",
            "==================================================\n",
            "FINAL SCORE: -50362.00\n",
            "ASSESSMENT: NEEDS WORK üîß\n",
            "FEEDBACK: Focus on improving success rate and reducing wrong guesses.\n",
            "\n",
            "üéâ EVALUATION COMPLETE!\n",
            "üìä Check 'evaluation_results.txt' for detailed game-by-game results\n"
          ]
        }
      ],
      "source": [
        "# Step 7: OFFICIAL EVALUATION - 2000 Games with Official Scoring Formula\n",
        "def official_evaluation(hangman_hmm, test_words, num_games=2000, max_wrong_guesses=6):\n",
        "    \"\"\"\n",
        "    Official evaluation as per problem statement\n",
        "    Plays 2000 games and calculates the official score\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from collections import defaultdict\n",
        "\n",
        "    print(\"OFFICIAL EVALUATION - 2000 HANGMAN GAMES\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Playing {num_games} games with {max_wrong_guesses} wrong guesses allowed per game\")\n",
        "    print()\n",
        "\n",
        "    # Initialize metrics\n",
        "    results = {\n",
        "        'games_won': 0,\n",
        "        'games_lost': 0,\n",
        "        'total_wrong_guesses': 0,\n",
        "        'total_repeated_guesses': 0,\n",
        "        'games_details': [],\n",
        "        'score_breakdown': defaultdict(int)\n",
        "    }\n",
        "\n",
        "    # Play specified number of games\n",
        "    for game_id in range(min(num_games, len(test_words))):\n",
        "        if game_id % 500 == 0:\n",
        "            print(f\"Played {game_id}/{num_games} games...\")\n",
        "\n",
        "        target_word = test_words[game_id]\n",
        "        game_result = play_single_game(hangman_hmm, target_word, max_wrong_guesses, game_id + 1)\n",
        "\n",
        "        # Aggregate results\n",
        "        if game_result['won']:\n",
        "            results['games_won'] += 1\n",
        "        else:\n",
        "            results['games_lost'] += 1\n",
        "\n",
        "        results['total_wrong_guesses'] += game_result['wrong_guesses']\n",
        "        results['total_repeated_guesses'] += game_result['repeated_guesses']\n",
        "        results['games_details'].append(game_result)\n",
        "\n",
        "    # Calculate official score\n",
        "    official_score = calculate_official_score(results, num_games)\n",
        "\n",
        "    # Print comprehensive results\n",
        "    print_official_results(results, official_score, num_games)\n",
        "\n",
        "    return results, official_score\n",
        "\n",
        "def play_single_game(hangman_hmm, target_word, max_wrong_guesses, game_id):\n",
        "    \"\"\"\n",
        "    Play a single Hangman game and return detailed results\n",
        "    \"\"\"\n",
        "    masked_word = ['_'] * len(target_word)\n",
        "    guessed_letters = set()\n",
        "    wrong_guesses = 0\n",
        "    repeated_guesses = 0\n",
        "    game_log = []\n",
        "\n",
        "    # Game loop\n",
        "    while wrong_guesses < max_wrong_guesses and '_' in masked_word:\n",
        "        # Get letter probabilities from HMM\n",
        "        probs = hangman_hmm.get_letter_probabilities(masked_word, guessed_letters)\n",
        "\n",
        "        if not probs:\n",
        "            # No probabilities available, use fallback\n",
        "            available_letters = [chr(i) for i in range(65, 91) if chr(i) not in guessed_letters]\n",
        "            if not available_letters:\n",
        "                break\n",
        "            next_letter = available_letters[0]\n",
        "        else:\n",
        "            # Choose letter with highest probability\n",
        "            next_letter = max(probs.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "        # Check for repeated guess\n",
        "        if next_letter in guessed_letters:\n",
        "            repeated_guesses += 1\n",
        "            game_log.append(f\"Repeated guess: {next_letter}\")\n",
        "            continue\n",
        "\n",
        "        # Add to guessed letters\n",
        "        guessed_letters.add(next_letter)\n",
        "\n",
        "        # Check if letter is in target word\n",
        "        if next_letter in target_word:\n",
        "            # Update masked word\n",
        "            for i, char in enumerate(target_word):\n",
        "                if char == next_letter:\n",
        "                    masked_word[i] = next_letter\n",
        "            game_log.append(f\"Correct: {next_letter} -> {' '.join(masked_word)}\")\n",
        "        else:\n",
        "            wrong_guesses += 1\n",
        "            game_log.append(f\"Wrong: {next_letter} ({wrong_guesses}/{max_wrong_guesses} wrong)\")\n",
        "\n",
        "    # Determine game outcome\n",
        "    won = '_' not in masked_word\n",
        "    actual_word = ''.join(target_word)\n",
        "    guessed_word = ''.join(masked_word)\n",
        "\n",
        "    return {\n",
        "        'game_id': game_id,\n",
        "        'target_word': actual_word,\n",
        "        'won': won,\n",
        "        'wrong_guesses': wrong_guesses,\n",
        "        'repeated_guesses': repeated_guesses,\n",
        "        'total_guesses': len(guessed_letters),\n",
        "        'final_word': guessed_word,\n",
        "        'game_log': game_log\n",
        "    }\n",
        "\n",
        "def calculate_official_score(results, num_games):\n",
        "    \"\"\"\n",
        "    Calculate official score using the formula:\n",
        "    Final Score = (Success Rate * 2000) - (Total Wrong Guesses * 5) - (Total Repeated Guesses * 2)\n",
        "    \"\"\"\n",
        "    success_rate = results['games_won'] / num_games\n",
        "    total_wrong_guesses = results['total_wrong_guesses']\n",
        "    total_repeated_guesses = results['total_repeated_guesses']\n",
        "\n",
        "    score = (success_rate * 2000) - (total_wrong_guesses * 5) - (total_repeated_guesses * 2)\n",
        "\n",
        "    # Store breakdown for analysis\n",
        "    results['score_breakdown']['success_component'] = success_rate * 2000\n",
        "    results['score_breakdown']['wrong_penalty'] = total_wrong_guesses * 5\n",
        "    results['score_breakdown']['repeated_penalty'] = total_repeated_guesses * 2\n",
        "    results['score_breakdown']['success_rate'] = success_rate\n",
        "    results['score_breakdown']['total_games'] = num_games\n",
        "\n",
        "    return score\n",
        "\n",
        "def print_official_results(results, official_score, num_games):\n",
        "    \"\"\"\n",
        "    Print comprehensive evaluation results\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"OFFICIAL EVALUATION RESULTS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Basic statistics\n",
        "    print(f\"GAME STATISTICS:\")\n",
        "    print(f\"   Total Games Played: {num_games}\")\n",
        "    print(f\"   Games Won: {results['games_won']}\")\n",
        "    print(f\"   Games Lost: {results['games_lost']}\")\n",
        "    print(f\"   Success Rate: {results['games_won']/num_games:.3f} ({results['games_won']}/{num_games})\")\n",
        "\n",
        "    print(f\"\\nPERFORMANCE METRICS:\")\n",
        "    print(f\"   Total Wrong Guesses: {results['total_wrong_guesses']}\")\n",
        "    print(f\"   Total Repeated Guesses: {results['total_repeated_guesses']}\")\n",
        "    print(f\"   Average Wrong Guesses per Game: {results['total_wrong_guesses']/num_games:.2f}\")\n",
        "    print(f\"   Average Repeated Guesses per Game: {results['total_repeated_guesses']/num_games:.2f}\")\n",
        "\n",
        "    print(f\"\\nSCORE BREAKDOWN:\")\n",
        "    print(f\"   Success Component: {results['score_breakdown']['success_component']:.2f}\")\n",
        "    print(f\"   Wrong Guesses Penalty: -{results['score_breakdown']['wrong_penalty']:.2f}\")\n",
        "    print(f\"   Repeated Guesses Penalty: -{results['score_breakdown']['repeated_penalty']:.2f}\")\n",
        "    print(f\"   FINAL SCORE: {official_score:.2f}\")\n",
        "\n",
        "    # Additional analysis\n",
        "    print(f\"\\nADDITIONAL INSIGHTS:\")\n",
        "\n",
        "    # Word length analysis\n",
        "    won_by_length = defaultdict(int)\n",
        "    lost_by_length = defaultdict(int)\n",
        "\n",
        "    for game in results['games_details']:\n",
        "        length = len(game['target_word'])\n",
        "        if game['won']:\n",
        "            won_by_length[length] += 1\n",
        "        else:\n",
        "            lost_by_length[length] += 1\n",
        "\n",
        "    print(f\"   Performance by Word Length:\")\n",
        "    for length in sorted(set(won_by_length.keys()) | set(lost_by_length.keys())):\n",
        "        won = won_by_length[length]\n",
        "        total = won + lost_by_length.get(length, 0)\n",
        "        if total > 0:\n",
        "            success_rate = won / total\n",
        "            print(f\"     Length {length}: {won}/{total} won ({success_rate:.1%})\")\n",
        "\n",
        "    # Efficiency analysis\n",
        "    total_correct_guesses = sum(game['total_guesses'] - game['wrong_guesses'] for game in results['games_details'])\n",
        "    total_guesses = sum(game['total_guesses'] for game in results['games_details'])\n",
        "    efficiency = total_correct_guesses / total_guesses if total_guesses > 0 else 0\n",
        "\n",
        "    print(f\"   Guess Efficiency: {efficiency:.1%} ({total_correct_guesses}/{total_guesses} correct guesses)\")\n",
        "\n",
        "# Load test words for evaluation\n",
        "def load_test_words_for_evaluation(file_path, num_words=2000):\n",
        "    \"\"\"Load test words for official evaluation\"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        words = [line.strip().upper() for line in f if line.strip()]\n",
        "\n",
        "    words = [word for word in words if word.isalpha()]\n",
        "\n",
        "    if len(words) < num_words:\n",
        "        print(f\"Warning: Only {len(words)} test words available, using all of them\")\n",
        "        return words\n",
        "    else:\n",
        "        return words[:num_words]\n",
        "\n",
        "# RUN OFFICIAL EVALUATION\n",
        "print(\"Loading test words for official evaluation...\")\n",
        "test_words_eval = load_test_words_for_evaluation('test.txt', num_words=2000)\n",
        "\n",
        "print(f\"Loaded {len(test_words_eval)} test words for evaluation\")\n",
        "print(\"Starting official 2000-game evaluation...\")\n",
        "\n",
        "# Run the official evaluation\n",
        "results, official_score = official_evaluation(hangman_hmm, test_words_eval, num_games=2000, max_wrong_guesses=6)\n",
        "\n",
        "# Save detailed results\n",
        "def save_detailed_results(results, official_score, filename=\"evaluation_results.txt\"):\n",
        "    \"\"\"Save detailed evaluation results to file\"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"OFFICIAL HANGMAN EVALUATION RESULTS\\n\")\n",
        "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "        f.write(f\"FINAL SCORE: {official_score:.2f}\\n\\n\")\n",
        "\n",
        "        f.write(\"SUMMARY STATISTICS:\\n\")\n",
        "        f.write(f\"Games Played: {results['score_breakdown']['total_games']}\\n\")\n",
        "        f.write(f\"Games Won: {results['games_won']}\\n\")\n",
        "        f.write(f\"Success Rate: {results['score_breakdown']['success_rate']:.3f}\\n\")\n",
        "        f.write(f\"Total Wrong Guesses: {results['total_wrong_guesses']}\\n\")\n",
        "        f.write(f\"Total Repeated Guesses: {results['total_repeated_guesses']}\\n\\n\")\n",
        "\n",
        "        f.write(\"SCORE BREAKDOWN:\\n\")\n",
        "        f.write(f\"Success Component: {results['score_breakdown']['success_component']:.2f}\\n\")\n",
        "        f.write(f\"Wrong Guesses Penalty: -{results['score_breakdown']['wrong_penalty']:.2f}\\n\")\n",
        "        f.write(f\"Repeated Guesses Penalty: -{results['score_breakdown']['repeated_penalty']:.2f}\\n\\n\")\n",
        "\n",
        "        f.write(\"FIRST 10 GAME RESULTS:\\n\")\n",
        "        for game in results['games_details'][:10]:\n",
        "            status = \"WON\" if game['won'] else \"LOST\"\n",
        "            f.write(f\"Game {game['game_id']}: {game['target_word']} -> {status} \"\n",
        "                   f\"(Wrong: {game['wrong_guesses']}, Repeated: {game['repeated_guesses']})\\n\")\n",
        "\n",
        "    print(f\"Detailed results saved to {filename}\")\n",
        "\n",
        "# Save results\n",
        "save_detailed_results(results, official_score)\n",
        "\n",
        "# Performance assessment\n",
        "def assess_performance(score):\n",
        "    \"\"\"Assess the performance based on final score\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"PERFORMANCE ASSESSMENT\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if score >= 1500:\n",
        "        assessment = \"EXCELLENT\"\n",
        "        feedback = \"Outstanding performance! Your agent is highly efficient.\"\n",
        "    elif score >= 1000:\n",
        "        assessment = \"VERY GOOD\"\n",
        "        feedback = \"Strong performance with good success rate and efficiency.\"\n",
        "    elif score >= 500:\n",
        "        assessment = \"GOOD\"\n",
        "        feedback = \"Solid performance with room for optimization.\"\n",
        "    elif score >= 0:\n",
        "        assessment = \"FAIR\"\n",
        "        feedback = \"Basic functionality achieved, needs improvement in efficiency.\"\n",
        "    else:\n",
        "        assessment = \"NEEDS WORK\"\n",
        "        feedback = \"Focus on improving success rate and reducing wrong guesses.\"\n",
        "\n",
        "    print(f\"FINAL SCORE: {score:.2f}\")\n",
        "    print(f\"ASSESSMENT: {assessment}\")\n",
        "    print(f\"FEEDBACK: {feedback}\")\n",
        "\n",
        "# Final assessment\n",
        "assess_performance(official_score)\n",
        "\n",
        "print(f\"\\nEVALUATION COMPLETE!\")\n",
        "print(f\"Check 'evaluation_results.txt' for detailed game-by-game results\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
