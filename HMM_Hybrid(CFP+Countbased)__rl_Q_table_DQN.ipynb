{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niharika-Saha/ML-hackathon-Group-1/blob/main/HMM_Hybrid(CFP%2BCountbased)__rl_Q_table_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYiw72pKa7WH"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install required packages\n",
        "!pip install hmmlearn\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "# Step 2: Import libraries\n",
        "import numpy as np\n",
        "import string\n",
        "from collections import defaultdict, Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from hmmlearn import hmm\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load and preprocess the corpus\n",
        "def load_and_preprocess_corpus(file_path):\n",
        "    \"\"\"\n",
        "    Load the corpus and preprocess words\n",
        "    - Convert to uppercase\n",
        "    - Remove words with non-alphabet characters\n",
        "    - Group by word length\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        words = [line.strip().upper() for line in f if line.strip()]\n",
        "\n",
        "    # Filter only alphabetic words\n",
        "    words = [word for word in words if word.isalpha()]\n",
        "\n",
        "    # Group words by length\n",
        "    words_by_length = defaultdict(list)\n",
        "    for word in words:\n",
        "        words_by_length[len(word)].append(word)\n",
        "\n",
        "    print(f\"Total words after preprocessing: {len(words)}\")\n",
        "    print(f\"Word length distribution:\")\n",
        "    for length in sorted(words_by_length.keys()):\n",
        "        print(f\"  Length {length}: {len(words_by_length[length])} words\")\n",
        "\n",
        "    return words, words_by_length\n",
        "\n",
        "# Load the corpus (upload your corpus.txt first)\n",
        "words, words_by_length = load_and_preprocess_corpus('corpus.txt')"
      ],
      "metadata": {
        "id": "j9ecThAGa8jN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86665dc-0160-45b3-9212-9535eedd8a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words after preprocessing: 49979\n",
            "Word length distribution:\n",
            "  Length 1: 46 words\n",
            "  Length 2: 84 words\n",
            "  Length 3: 388 words\n",
            "  Length 4: 1169 words\n",
            "  Length 5: 2340 words\n",
            "  Length 6: 3755 words\n",
            "  Length 7: 5111 words\n",
            "  Length 8: 6348 words\n",
            "  Length 9: 6787 words\n",
            "  Length 10: 6465 words\n",
            "  Length 11: 5452 words\n",
            "  Length 12: 4292 words\n",
            "  Length 13: 3094 words\n",
            "  Length 14: 2019 words\n",
            "  Length 15: 1226 words\n",
            "  Length 16: 698 words\n",
            "  Length 17: 375 words\n",
            "  Length 18: 174 words\n",
            "  Length 19: 88 words\n",
            "  Length 20: 40 words\n",
            "  Length 21: 16 words\n",
            "  Length 22: 8 words\n",
            "  Length 23: 3 words\n",
            "  Length 24: 1 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Analyze letter frequencies and patterns\n",
        "def analyze_corpus(words_by_length):\n",
        "    \"\"\"\n",
        "    Analyze letter frequencies and positional distributions\n",
        "    \"\"\"\n",
        "    # Overall letter frequency\n",
        "    all_letters = ''.join([''.join(words) for words in words_by_length.values()])\n",
        "    letter_freq = Counter(all_letters)\n",
        "\n",
        "    print(\"Overall letter frequency (top 10):\")\n",
        "    for letter, freq in letter_freq.most_common(10):\n",
        "        print(f\"  {letter}: {freq} ({freq/len(all_letters)*100:.2f}%)\")\n",
        "\n",
        "    # Positional frequency analysis for different lengths\n",
        "    positional_freq = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for length, word_list in words_by_length.items():\n",
        "        for word in word_list:\n",
        "            for pos, letter in enumerate(word):\n",
        "                positional_freq[length][(pos, letter)] += 1\n",
        "\n",
        "    return letter_freq, positional_freq\n",
        "\n",
        "letter_freq, positional_freq = analyze_corpus(words_by_length)"
      ],
      "metadata": {
        "id": "yyviOITja_w0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4888008-f36d-46b9-bdee-001df3e103f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall letter frequency (top 10):\n",
            "  E: 49203 (10.37%)\n",
            "  A: 42089 (8.87%)\n",
            "  I: 42047 (8.86%)\n",
            "  O: 35808 (7.54%)\n",
            "  R: 33577 (7.07%)\n",
            "  N: 33314 (7.02%)\n",
            "  T: 32191 (6.78%)\n",
            "  S: 29044 (6.12%)\n",
            "  L: 27406 (5.77%)\n",
            "  C: 21718 (4.58%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Prepare HMM training data for each word length\n",
        "def prepare_hmm_training_data(words_by_length, min_words_threshold=5):\n",
        "    \"\"\"\n",
        "    Prepare training data for HMMs for each word length\n",
        "    Convert words to numerical sequences for HMM training\n",
        "\n",
        "    Parameters:\n",
        "    - words_by_length: Dictionary of words grouped by length\n",
        "    - min_words_threshold: Minimum number of words required to train HMM for a given length\n",
        "    \"\"\"\n",
        "    # Create letter to index mapping (A=0, B=1, ..., Z=25)\n",
        "    letters = string.ascii_uppercase\n",
        "    letter_to_idx = {letter: idx for idx, letter in enumerate(letters)}\n",
        "\n",
        "    training_data = {}\n",
        "\n",
        "    # Print available word lengths for debugging\n",
        "    available_lengths = sorted(words_by_length.keys())\n",
        "    print(f\"Available word lengths: {available_lengths}\")\n",
        "    print(f\"Lengths 22, 23, 24 present: {22 in words_by_length}, {23 in words_by_length}, {24 in words_by_length}\")\n",
        "\n",
        "    for length, word_list in words_by_length.items():\n",
        "        # Include all lengths including 22, 23, 24 if they have enough words\n",
        "        if len(word_list) < min_words_threshold:\n",
        "            print(f\"Skipping length {length}: only {len(word_list)} words (need at least {min_words_threshold})\")\n",
        "            continue\n",
        "\n",
        "        sequences = []\n",
        "        for word in word_list:\n",
        "            # Convert word to numerical sequence\n",
        "            seq = [letter_to_idx[char] for char in word]\n",
        "            sequences.append(seq)\n",
        "\n",
        "        training_data[length] = np.array(sequences)\n",
        "\n",
        "        print(f\"Length {length}: {len(sequences)} sequences\")\n",
        "\n",
        "    # Specifically check and report on lengths 22, 23, 24\n",
        "    for length in [22, 23, 24]:\n",
        "        if length in training_data:\n",
        "            print(f\"âœ“ INCLUDED - Length {length}: {len(training_data[length])} sequences\")\n",
        "        elif length in words_by_length:\n",
        "            print(f\"âœ— EXCLUDED - Length {length}: {len(words_by_length[length])} words (below threshold)\")\n",
        "        else:\n",
        "            print(f\"âœ— NOT FOUND - Length {length}: No words in corpus\")\n",
        "\n",
        "    return training_data, letter_to_idx\n",
        "\n",
        "# Run with lower threshold to include more word lengths\n",
        "training_data, letter_to_idx = prepare_hmm_training_data(words_by_length, min_words_threshold=1)"
      ],
      "metadata": {
        "id": "w4jxdAW0bESj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338becba-091b-4dbd-d3ff-19b822ab3f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available word lengths: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
            "Lengths 22, 23, 24 present: True, True, True\n",
            "Length 11: 5452 sequences\n",
            "Length 6: 3755 sequences\n",
            "Length 9: 6787 sequences\n",
            "Length 16: 698 sequences\n",
            "Length 14: 2019 sequences\n",
            "Length 10: 6465 sequences\n",
            "Length 8: 6348 sequences\n",
            "Length 12: 4292 sequences\n",
            "Length 13: 3094 sequences\n",
            "Length 5: 2340 sequences\n",
            "Length 18: 174 sequences\n",
            "Length 4: 1169 sequences\n",
            "Length 3: 388 sequences\n",
            "Length 7: 5111 sequences\n",
            "Length 15: 1226 sequences\n",
            "Length 17: 375 sequences\n",
            "Length 22: 8 sequences\n",
            "Length 19: 88 sequences\n",
            "Length 2: 84 sequences\n",
            "Length 1: 46 sequences\n",
            "Length 20: 40 sequences\n",
            "Length 21: 16 sequences\n",
            "Length 23: 3 sequences\n",
            "Length 24: 1 sequences\n",
            "âœ“ INCLUDED - Length 22: 8 sequences\n",
            "âœ“ INCLUDED - Length 23: 3 sequences\n",
            "âœ“ INCLUDED - Length 24: 1 sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "muVwuh3GbKm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "100oXZOg8OVl",
        "outputId": "ce4cfbba-d0aa-4768-f613-11ad4f7d47cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Initializing Hybrid CFP + Count-based HMM Model...\n",
            "ðŸš€ Training Count-based HMMs for Hybrid Model...\n",
            "   ðŸ“Š Length 11: 5452 sequences\n",
            "   ðŸ“Š Length 6: 3755 sequences\n",
            "   ðŸ“Š Length 9: 6787 sequences\n",
            "   ðŸ“Š Length 16: 698 sequences\n",
            "   ðŸ“Š Length 14: 2019 sequences\n",
            "   ðŸ“Š Length 10: 6465 sequences\n",
            "   ðŸ“Š Length 8: 6348 sequences\n",
            "   ðŸ“Š Length 12: 4292 sequences\n",
            "   ðŸ“Š Length 13: 3094 sequences\n",
            "   ðŸ“Š Length 5: 2340 sequences\n",
            "   ðŸ“Š Length 18: 174 sequences\n",
            "   ðŸ“Š Length 4: 1169 sequences\n",
            "   ðŸ“Š Length 3: 388 sequences\n",
            "   ðŸ“Š Length 7: 5111 sequences\n",
            "   ðŸ“Š Length 15: 1226 sequences\n",
            "   ðŸ“Š Length 17: 375 sequences\n",
            "   ðŸ“Š Length 22: 8 sequences\n",
            "   ðŸ“Š Length 19: 88 sequences\n",
            "   ðŸ“Š Length 2: 84 sequences\n",
            "   ðŸ“Š Length 1: 46 sequences\n",
            "   ðŸ“Š Length 20: 40 sequences\n",
            "   ðŸ“Š Length 21: 16 sequences\n",
            "   ðŸ“Š Length 23: 3 sequences\n",
            "   ðŸ“Š Length 24: 1 sequences\n",
            "âœ… Trained 24 count-based HMMs\n",
            "ðŸŽ¯ Hybrid Model Initialized: CFP weight=0.7, HMM weight=0.3\n",
            "\n",
            "============================================================\n",
            "ðŸ† HYBRID MODEL READY!\n",
            "============================================================\n",
            "âœ… CFP Oracle: Word-based candidate filtering\n",
            "âœ… Count-based HMM: Statistical pattern learning\n",
            "âœ… Dynamic weighting: Adaptive confidence-based blending\n",
            "âœ… All word lengths supported\n",
            "âœ… Initial blend: 70% CFP + 30% HMM\n",
            "\n",
            "ðŸŽ¯ Ready for evaluation with 2000 games!\n"
          ]
        }
      ],
      "source": [
        "# Step 6: HYBRID CFP + Count-based HMM Training\n",
        "class HybridHangmanModel:\n",
        "    \"\"\"\n",
        "    Combines the best of CFP (accuracy) and HMM (generalization)\n",
        "    \"\"\"\n",
        "    def __init__(self, corpus_words, training_data, letter_to_idx, alpha=0.3):\n",
        "        self.cfp = CandidateFilterOracle(corpus_words)\n",
        "        self.count_hmms = train_count_hmm_models(training_data)\n",
        "        self.letter_to_idx = letter_to_idx\n",
        "        self.letters = string.ascii_uppercase\n",
        "        self.alpha = alpha  # Weight for HMM (0-1), CFP weight = 1-alpha\n",
        "\n",
        "        print(f\"ðŸŽ¯ Hybrid Model Initialized: CFP weight={1-alpha:.1f}, HMM weight={alpha:.1f}\")\n",
        "\n",
        "    def get_letter_probabilities(self, masked_word, guessed_letters):\n",
        "        \"\"\"\n",
        "        Combine CFP and Count-based HMM probabilities\n",
        "        \"\"\"\n",
        "        # Get CFP probabilities (high accuracy)\n",
        "        cfp_probs = self.cfp.get_letter_probabilities(masked_word, guessed_letters)\n",
        "\n",
        "        # Get HMM probabilities (good generalization)\n",
        "        hmm_probs = self._get_hmm_probabilities(masked_word, guessed_letters)\n",
        "\n",
        "        # If CFP has no candidates, rely more on HMM\n",
        "        if not cfp_probs or max(cfp_probs.values()) == 0:\n",
        "            return hmm_probs\n",
        "\n",
        "        # If HMM failed, rely on CFP\n",
        "        if not hmm_probs:\n",
        "            return cfp_probs\n",
        "\n",
        "        # Combine probabilities\n",
        "        hybrid_probs = {}\n",
        "        for letter in self.letters:\n",
        "            if letter not in guessed_letters:\n",
        "                cfp_prob = cfp_probs.get(letter, 0)\n",
        "                hmm_prob = hmm_probs.get(letter, 0)\n",
        "\n",
        "                # Dynamic weighting: if CFP is confident, trust it more\n",
        "                cfp_confidence = max(cfp_probs.values())\n",
        "                dynamic_alpha = self.alpha * (1 - cfp_confidence)  # Less HMM weight if CFP is confident\n",
        "\n",
        "                hybrid_prob = (1 - dynamic_alpha) * cfp_prob + dynamic_alpha * hmm_prob\n",
        "                hybrid_probs[letter] = hybrid_prob\n",
        "\n",
        "        # Normalize\n",
        "        total = sum(hybrid_probs.values())\n",
        "        if total > 0:\n",
        "            hybrid_probs = {letter: prob/total for letter, prob in hybrid_probs.items()}\n",
        "\n",
        "        return hybrid_probs\n",
        "\n",
        "    def _get_hmm_probabilities(self, masked_word, guessed_letters):\n",
        "        \"\"\"Get probabilities from count-based HMM\"\"\"\n",
        "        word_length = len(masked_word)\n",
        "\n",
        "        if word_length not in self.count_hmms:\n",
        "            return {}\n",
        "\n",
        "        model = self.count_hmms[word_length]\n",
        "\n",
        "        # Prepare observations\n",
        "        observations = []\n",
        "        for char in masked_word:\n",
        "            if char == '_':\n",
        "                observations.append(-1)  # Missing\n",
        "            else:\n",
        "                observations.append(self.letter_to_idx[char])\n",
        "\n",
        "        try:\n",
        "            # Get posteriors using count-based HMM\n",
        "            posteriors = model.forward_backward(observations)\n",
        "\n",
        "            # Aggregate probabilities for blank positions\n",
        "            letter_probs = np.zeros(26)\n",
        "            for pos, char in enumerate(masked_word):\n",
        "                if char == '_':\n",
        "                    for letter_idx in range(26):\n",
        "                        letter = self.idx_to_letter(letter_idx)\n",
        "                        if letter not in guessed_letters:\n",
        "                            letter_probs[letter_idx] += posteriors[pos, letter_idx]\n",
        "\n",
        "            # Normalize\n",
        "            if np.sum(letter_probs) > 0:\n",
        "                letter_probs /= np.sum(letter_probs)\n",
        "\n",
        "            return {self.idx_to_letter(i): letter_probs[i]\n",
        "                    for i in range(26) if self.idx_to_letter(i) not in guessed_letters}\n",
        "\n",
        "        except Exception as e:\n",
        "            return {}\n",
        "\n",
        "    def idx_to_letter(self, idx):\n",
        "        \"\"\"Convert index to letter\"\"\"\n",
        "        return chr(65 + idx)\n",
        "\n",
        "# COUNT-BASED HMM IMPLEMENTATION (from previous)\n",
        "class CountBasedHMM:\n",
        "    def __init__(self):\n",
        "        self.transition_probs = None\n",
        "        self.emission_probs = None\n",
        "        self.initial_probs = None\n",
        "\n",
        "    def train(self, sequences, alpha=0.1):\n",
        "        n_states = 26\n",
        "\n",
        "        # Initialize counts with smoothing\n",
        "        transition_counts = np.ones((n_states, n_states)) * alpha\n",
        "        emission_counts = np.ones((n_states, n_states)) * alpha\n",
        "        initial_counts = np.ones(n_states) * alpha\n",
        "\n",
        "        # Count transitions and emissions\n",
        "        for seq in sequences:\n",
        "            if len(seq) > 0:\n",
        "                initial_counts[seq[0]] += 1\n",
        "\n",
        "            for i in range(len(seq)):\n",
        "                emission_counts[seq[i], seq[i]] += 1\n",
        "                if i < len(seq) - 1:\n",
        "                    transition_counts[seq[i], seq[i+1]] += 1\n",
        "\n",
        "        # Convert to probabilities\n",
        "        self.initial_probs = initial_counts / np.sum(initial_counts)\n",
        "        self.transition_probs = transition_counts / np.sum(transition_counts, axis=1, keepdims=True)\n",
        "        self.emission_probs = emission_counts / np.sum(emission_counts, axis=1, keepdims=True)\n",
        "\n",
        "    def forward_backward(self, observations):\n",
        "        n_positions = len(observations)\n",
        "        n_states = 26\n",
        "\n",
        "        # Forward pass\n",
        "        forward = np.zeros((n_positions, n_states))\n",
        "        for state in range(n_states):\n",
        "            if observations[0] == -1:\n",
        "                forward[0, state] = self.initial_probs[state]\n",
        "            else:\n",
        "                forward[0, state] = self.initial_probs[state] * self.emission_probs[state, observations[0]]\n",
        "\n",
        "        for t in range(1, n_positions):\n",
        "            for j in range(n_states):\n",
        "                sum_prob = 0\n",
        "                for i in range(n_states):\n",
        "                    sum_prob += forward[t-1, i] * self.transition_probs[i, j]\n",
        "\n",
        "                if observations[t] == -1:\n",
        "                    forward[t, j] = sum_prob\n",
        "                else:\n",
        "                    forward[t, j] = sum_prob * self.emission_probs[j, observations[t]]\n",
        "\n",
        "        # Backward pass\n",
        "        backward = np.ones((n_positions, n_states))\n",
        "        for t in range(n_positions-2, -1, -1):\n",
        "            for i in range(n_states):\n",
        "                sum_prob = 0\n",
        "                for j in range(n_states):\n",
        "                    if observations[t+1] == -1:\n",
        "                        emission_prob = 1.0\n",
        "                    else:\n",
        "                        emission_prob = self.emission_probs[j, observations[t+1]]\n",
        "                    sum_prob += self.transition_probs[i, j] * emission_prob * backward[t+1, j]\n",
        "                backward[t, i] = sum_prob\n",
        "\n",
        "        # Combine\n",
        "        posteriors = forward * backward\n",
        "        posteriors = posteriors / np.sum(posteriors, axis=1, keepdims=True)\n",
        "        return posteriors\n",
        "\n",
        "\n",
        "def train_count_hmm_models(training_data):\n",
        "    \"\"\"Train count-based HMMs for all word lengths\"\"\"\n",
        "    count_hmms = {}\n",
        "\n",
        "    print(\"ðŸš€ Training Count-based HMMs for Hybrid Model...\")\n",
        "    for length, sequences in training_data.items():\n",
        "        if len(sequences) < 1:\n",
        "            continue\n",
        "\n",
        "        print(f\"   ðŸ“Š Length {length}: {len(sequences)} sequences\")\n",
        "        model = CountBasedHMM()\n",
        "        model.train(sequences, alpha=0.1)\n",
        "        count_hmms[length] = model\n",
        "\n",
        "    print(f\"âœ… Trained {len(count_hmms)} count-based HMMs\")\n",
        "    return count_hmms\n",
        "\n",
        "# CFP ORACLE (from previous)\n",
        "class CandidateFilterOracle:\n",
        "    def __init__(self, corpus_words):\n",
        "        self.by_len = defaultdict(list)\n",
        "        for word in corpus_words:\n",
        "            w = word.strip().upper()\n",
        "            if w and w.isalpha():\n",
        "                self.by_len[len(w)].append(w)\n",
        "\n",
        "    @staticmethod\n",
        "    def matches_mask(word, mask, wrong_letters):\n",
        "        if len(word) != len(mask):\n",
        "            return False\n",
        "        if any(letter in word for letter in wrong_letters):\n",
        "            return False\n",
        "        for wc, mc in zip(word, mask):\n",
        "            if mc != '_' and wc != mc:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def get_letter_probabilities(self, masked_word, guessed_letters):\n",
        "        word_length = len(masked_word)\n",
        "        revealed_letters = set(char for char in masked_word if char != '_')\n",
        "        wrong_letters = guessed_letters - revealed_letters\n",
        "\n",
        "        # Get candidate words\n",
        "        candidates = [\n",
        "            word for word in self.by_len.get(word_length, [])\n",
        "            if self.matches_mask(word, masked_word, wrong_letters)\n",
        "        ]\n",
        "\n",
        "        if not candidates:\n",
        "            return self._fallback_probs(guessed_letters)\n",
        "\n",
        "        # Count letter frequencies in blank positions\n",
        "        blank_positions = [i for i, char in enumerate(masked_word) if char == '_']\n",
        "        letter_counts = Counter()\n",
        "\n",
        "        for word in candidates:\n",
        "            for pos in blank_positions:\n",
        "                letter_counts[word[pos]] += 1\n",
        "\n",
        "        # Convert to probabilities\n",
        "        total_count = sum(letter_counts.values())\n",
        "        prob_dict = {}\n",
        "        for letter in string.ascii_uppercase:\n",
        "            if letter not in guessed_letters:\n",
        "                prob_dict[letter] = letter_counts[letter] / total_count if total_count > 0 else 0\n",
        "\n",
        "        # Normalize\n",
        "        total_prob = sum(prob_dict.values())\n",
        "        if total_prob > 0:\n",
        "            prob_dict = {letter: prob/total_prob for letter, prob in prob_dict.items()}\n",
        "        else:\n",
        "            prob_dict = self._fallback_probs(guessed_letters)\n",
        "\n",
        "        return prob_dict\n",
        "\n",
        "    def _fallback_probs(self, guessed_letters):\n",
        "        available = [l for l in string.ascii_uppercase if l not in guessed_letters]\n",
        "        prob = 1.0 / len(available) if available else 0\n",
        "        return {letter: prob for letter in available}\n",
        "\n",
        "# ðŸš€ INITIALIZE HYBRID MODEL\n",
        "print(\"ðŸŽ¯ Initializing Hybrid CFP + Count-based HMM Model...\")\n",
        "hybrid_model = HybridHangmanModel(words, training_data, letter_to_idx, alpha=0.3)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ† HYBRID MODEL READY!\")\n",
        "print(\"=\"*60)\n",
        "print(\"âœ… CFP Oracle: Word-based candidate filtering\")\n",
        "print(\"âœ… Count-based HMM: Statistical pattern learning\")\n",
        "print(\"âœ… Dynamic weighting: Adaptive confidence-based blending\")\n",
        "print(\"âœ… All word lengths supported\")\n",
        "print(f\"âœ… Initial blend: {70}% CFP + {30}% HMM\")\n",
        "\n",
        "# Update your main HMM reference to use the hybrid model\n",
        "hangman_hmm = hybrid_model\n",
        "\n",
        "print(\"\\nðŸŽ¯ Ready for evaluation with 2000 games!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Reinforcement Learning Agent for Hangman\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict, deque\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class HangmanEnvironment:\n",
        "    \"\"\"\n",
        "    Hangman Game Environment for RL Agent\n",
        "    \"\"\"\n",
        "    def __init__(self, target_word, max_wrong_guesses=6):\n",
        "        self.target_word = target_word.upper()\n",
        "        self.max_wrong_guesses = max_wrong_guesses\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the environment to initial state\"\"\"\n",
        "        self.masked_word = ['_'] * len(self.target_word)\n",
        "        self.guessed_letters = set()\n",
        "        self.wrong_guesses = 0\n",
        "        self.revealed_letters = set()\n",
        "        self.done = False\n",
        "        self.won = False\n",
        "\n",
        "        return self.get_state()\n",
        "\n",
        "    def get_state(self):\n",
        "        \"\"\"Get current state representation\"\"\"\n",
        "        return {\n",
        "            'masked_word': ''.join(self.masked_word),\n",
        "            'guessed_letters': self.guessed_letters.copy(),\n",
        "            'wrong_guesses': self.wrong_guesses,\n",
        "            'max_wrong_guesses': self.max_wrong_guesses,\n",
        "            'revealed_letters': self.revealed_letters.copy(),\n",
        "            'word_length': len(self.target_word)\n",
        "        }\n",
        "\n",
        "    def step(self, action_letter, hmm_probabilities=None):\n",
        "        \"\"\"\n",
        "        Execute an action (guess a letter)\n",
        "        Returns: next_state, reward, done, info\n",
        "        \"\"\"\n",
        "        if self.done:\n",
        "            raise Exception(\"Game has already ended\")\n",
        "\n",
        "        letter = action_letter.upper()\n",
        "        reward = 0\n",
        "        info = {}\n",
        "\n",
        "        # Check for repeated guess\n",
        "        if letter in self.guessed_letters:\n",
        "            reward = -2  # Penalty for repeated guess\n",
        "            info['repeated'] = True\n",
        "            info['correct'] = False\n",
        "            return self.get_state(), reward, self.done, info\n",
        "\n",
        "        # Add to guessed letters\n",
        "        self.guessed_letters.add(letter)\n",
        "\n",
        "        # Check if letter is in target word\n",
        "        if letter in self.target_word:\n",
        "            # Update masked word\n",
        "            positions_found = []\n",
        "            for i, char in enumerate(self.target_word):\n",
        "                if char == letter:\n",
        "                    self.masked_word[i] = letter\n",
        "                    positions_found.append(i)\n",
        "\n",
        "            self.revealed_letters.add(letter)\n",
        "\n",
        "            # Reward for correct guess\n",
        "            base_reward = 1.0\n",
        "            # Bonus for revealing multiple positions\n",
        "            position_bonus = 0.5 * len(positions_found)\n",
        "            # Bonus if this completes the word\n",
        "            completion_bonus = 10.0 if '_' not in self.masked_word else 0\n",
        "\n",
        "            reward = base_reward + position_bonus + completion_bonus\n",
        "            info['correct'] = True\n",
        "            info['positions_found'] = positions_found\n",
        "            info['completion'] = ('_' not in self.masked_word)\n",
        "\n",
        "        else:\n",
        "            # Wrong guess penalty\n",
        "            self.wrong_guesses += 1\n",
        "            reward = -1.0\n",
        "            info['correct'] = False\n",
        "            info['wrong_guesses_remaining'] = self.max_wrong_guesses - self.wrong_guesses\n",
        "\n",
        "        # Check game termination\n",
        "        if '_' not in self.masked_word:\n",
        "            self.done = True\n",
        "            self.won = True\n",
        "            reward += 20.0  # Big bonus for winning\n",
        "            info['termination'] = 'win'\n",
        "        elif self.wrong_guesses >= self.max_wrong_guesses:\n",
        "            self.done = True\n",
        "            self.won = False\n",
        "            reward -= 10.0  # Big penalty for losing\n",
        "            info['termination'] = 'loss'\n",
        "        else:\n",
        "            info['termination'] = 'continue'\n",
        "\n",
        "        # Add HMM confidence bonus/penalty if probabilities are provided\n",
        "        if hmm_probabilities is not None and letter in hmm_probabilities:\n",
        "            hmm_confidence = hmm_probabilities[letter]\n",
        "            confidence_bonus = 0.5 * hmm_confidence\n",
        "            reward += confidence_bonus\n",
        "            info['hmm_confidence'] = hmm_confidence\n",
        "\n",
        "        return self.get_state(), reward, self.done, info\n",
        "\n",
        "    def render(self):\n",
        "        \"\"\"Display current game state\"\"\"\n",
        "        print(f\"Word: {' '.join(self.masked_word)}\")\n",
        "        print(f\"Guessed: {''.join(sorted(self.guessed_letters))}\")\n",
        "        print(f\"Wrong guesses: {self.wrong_guesses}/{self.max_wrong_guesses}\")\n",
        "        print(f\"Status: {'WON' if self.won else 'LOST' if self.done else 'IN PROGRESS'}\")\n",
        "\n",
        "class StateEncoder:\n",
        "    \"\"\"\n",
        "    Encodes game state into numerical features for neural network\n",
        "    \"\"\"\n",
        "    def __init__(self, word_length=15):\n",
        "        self.word_length = word_length\n",
        "        self.letters = string.ascii_uppercase\n",
        "        self.letter_to_idx = {letter: idx for idx, letter in enumerate(self.letters)}\n",
        "\n",
        "    def encode(self, state, hmm_probs=None):\n",
        "        \"\"\"\n",
        "        Encode state into feature vector\n",
        "        Features:\n",
        "        - Masked word one-hot encoding (word_length * 27)\n",
        "        - Guessed letters (26)\n",
        "        - Wrong guesses count (normalized)\n",
        "        - HMM probabilities (26)\n",
        "        - Word length encoding\n",
        "        \"\"\"\n",
        "        features = []\n",
        "\n",
        "        # 1. Masked word encoding (one-hot for each position)\n",
        "        masked_encoding = []\n",
        "        for char in state['masked_word']:\n",
        "            if char == '_':\n",
        "                # Unknown position\n",
        "                pos_encoding = [0] * 26 + [1]  # 26 letters + 1 for unknown\n",
        "            else:\n",
        "                # Known letter\n",
        "                pos_encoding = [0] * 26\n",
        "                pos_encoding[self.letter_to_idx[char]] = 1\n",
        "                pos_encoding.append(0)  # Not unknown\n",
        "            masked_encoding.extend(pos_encoding)\n",
        "\n",
        "        # Pad or truncate to fixed length\n",
        "        target_length = self.word_length * 27\n",
        "        if len(masked_encoding) < target_length:\n",
        "            masked_encoding.extend([0] * (target_length - len(masked_encoding)))\n",
        "        else:\n",
        "            masked_encoding = masked_encoding[:target_length]\n",
        "\n",
        "        features.extend(masked_encoding)\n",
        "\n",
        "        # 2. Guessed letters (one-hot)\n",
        "        guessed_encoding = [0] * 26\n",
        "        for letter in state['guessed_letters']:\n",
        "            if letter in self.letter_to_idx:\n",
        "                guessed_encoding[self.letter_to_idx[letter]] = 1\n",
        "        features.extend(guessed_encoding)\n",
        "\n",
        "        # 3. Wrong guesses (normalized)\n",
        "        wrong_guesses_norm = state['wrong_guesses'] / state['max_wrong_guesses']\n",
        "        features.append(wrong_guesses_norm)\n",
        "\n",
        "        # 4. HMM probabilities\n",
        "        if hmm_probs is not None:\n",
        "            hmm_encoding = [hmm_probs.get(letter, 0.0) for letter in self.letters]\n",
        "        else:\n",
        "            hmm_encoding = [0.0] * 26\n",
        "        features.extend(hmm_encoding)\n",
        "\n",
        "        # 5. Word length (normalized)\n",
        "        word_length_norm = len(state['masked_word']) / 20.0  # Assuming max length 20\n",
        "        features.append(word_length_norm)\n",
        "\n",
        "        return np.array(features, dtype=np.float32)\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    \"\"\"\n",
        "    Deep Q-Network for Hangman RL Agent\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, hidden_dims=[512, 256, 128]):\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            prev_dim = hidden_dim\n",
        "\n",
        "        layers.append(nn.Linear(prev_dim, output_dim))\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class HangmanRLAgent:\n",
        "    \"\"\"\n",
        "    Reinforcement Learning Agent for Hangman\n",
        "    \"\"\"\n",
        "    def __init__(self, state_encoder, hmm_model, learning_rate=0.001, gamma=0.99):\n",
        "        self.state_encoder = state_encoder\n",
        "        self.hmm_model = hmm_model\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # Calculate input dimension\n",
        "        self.input_dim = (state_encoder.word_length * 27) + 26 + 1 + 26 + 1\n",
        "        self.output_dim = 26  # One output for each possible letter\n",
        "\n",
        "        # Neural networks\n",
        "        self.policy_net = DQN(self.input_dim, self.output_dim)\n",
        "        self.target_net = DQN(self.input_dim, self.output_dim)\n",
        "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=learning_rate)\n",
        "\n",
        "        # RL parameters\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.batch_size = 64\n",
        "        self.memory = deque(maxlen=10000)\n",
        "        self.update_target_every = 1000\n",
        "        self.steps_done = 0\n",
        "\n",
        "        # Initialize target network\n",
        "        self.update_target_network()\n",
        "\n",
        "    def update_target_network(self):\n",
        "        \"\"\"Update target network with policy network weights\"\"\"\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "\n",
        "    def get_action(self, state, training=True):\n",
        "        \"\"\"\n",
        "        Choose action using epsilon-greedy policy\n",
        "        \"\"\"\n",
        "        available_letters = [l for l in string.ascii_uppercase if l not in state['guessed_letters']]\n",
        "\n",
        "        if not available_letters:\n",
        "            return None  # No available actions\n",
        "\n",
        "        # Get HMM probabilities for available letters\n",
        "        hmm_probs = self.hmm_model.get_letter_probabilities(\n",
        "            state['masked_word'], state['guessed_letters']\n",
        "        )\n",
        "\n",
        "        # Epsilon-greedy exploration\n",
        "        if training and random.random() < self.epsilon:\n",
        "            # Explore: choose random available letter\n",
        "            return random.choice(available_letters)\n",
        "        else:\n",
        "            # Exploit: choose best action according to Q-network\n",
        "            state_tensor = self._state_to_tensor(state, hmm_probs)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                q_values = self.policy_net(state_tensor)\n",
        "\n",
        "            # Convert Q-values to action probabilities, masking unavailable letters\n",
        "            action_probs = {}\n",
        "            for letter in string.ascii_uppercase:\n",
        "                if letter in available_letters:\n",
        "                    action_idx = self.state_encoder.letter_to_idx[letter]\n",
        "                    action_probs[letter] = q_values[0, action_idx].item()\n",
        "                else:\n",
        "                    action_probs[letter] = -float('inf')\n",
        "\n",
        "            # Choose action with highest Q-value\n",
        "            return max(action_probs, key=action_probs.get)\n",
        "\n",
        "    def _state_to_tensor(self, state, hmm_probs):\n",
        "        \"\"\"Convert state to tensor for neural network\"\"\"\n",
        "        state_features = self.state_encoder.encode(state, hmm_probs)\n",
        "        return torch.FloatTensor(state_features).unsqueeze(0)\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done, hmm_probs):\n",
        "        \"\"\"Store experience in replay memory\"\"\"\n",
        "        state_features = self.state_encoder.encode(state, hmm_probs)\n",
        "\n",
        "        # Get next state HMM probabilities\n",
        "        next_hmm_probs = self.hmm_model.get_letter_probabilities(\n",
        "            next_state['masked_word'], next_state['guessed_letters']\n",
        "        )\n",
        "        next_state_features = self.state_encoder.encode(next_state, next_hmm_probs)\n",
        "\n",
        "        action_idx = self.state_encoder.letter_to_idx[action]\n",
        "\n",
        "        self.memory.append((\n",
        "            state_features,\n",
        "            action_idx,\n",
        "            reward,\n",
        "            next_state_features,\n",
        "            done\n",
        "        ))\n",
        "\n",
        "    def replay(self):\n",
        "        \"\"\"Train on batch from replay memory\"\"\"\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        batch = random.sample(self.memory, self.batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "        states = torch.FloatTensor(np.array(states))\n",
        "        actions = torch.LongTensor(actions).unsqueeze(1)\n",
        "        rewards = torch.FloatTensor(rewards)\n",
        "        next_states = torch.FloatTensor(np.array(next_states))\n",
        "        dones = torch.BoolTensor(dones)\n",
        "\n",
        "        # Current Q values\n",
        "        current_q_values = self.policy_net(states).gather(1, actions).squeeze()\n",
        "\n",
        "        # Next Q values from target network\n",
        "        with torch.no_grad():\n",
        "            next_q_values = self.target_net(next_states).max(1)[0]\n",
        "            next_q_values[dones] = 0.0  # No future rewards for terminal states\n",
        "\n",
        "        # Target Q values\n",
        "        target_q_values = rewards + self.gamma * next_q_values\n",
        "\n",
        "        # Compute loss\n",
        "        loss = F.mse_loss(current_q_values, target_q_values)\n",
        "\n",
        "        # Optimize\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Update exploration rate\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "        # Update target network\n",
        "        self.steps_done += 1\n",
        "        if self.steps_done % self.update_target_every == 0:\n",
        "            self.update_target_network()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "class RLTrainer:\n",
        "    \"\"\"\n",
        "    Trainer for RL Agent\n",
        "    \"\"\"\n",
        "    def __init__(self, agent, words_dataset):\n",
        "        self.agent = agent\n",
        "        self.words_dataset = words_dataset\n",
        "\n",
        "    def train(self, episodes=10000, eval_every=1000, num_eval_games=100):\n",
        "        \"\"\"Train the RL agent\"\"\"\n",
        "        print(\"ðŸš€ Starting RL Training...\")\n",
        "        print(f\"Episodes: {episodes}, Evaluation every: {eval_every} episodes\")\n",
        "\n",
        "        training_stats = {\n",
        "            'episode_rewards': [],\n",
        "            'episode_lengths': [],\n",
        "            'success_rates': [],\n",
        "            'epsilon_values': []\n",
        "        }\n",
        "\n",
        "        for episode in range(episodes):\n",
        "            # Sample a random word\n",
        "            target_word = random.choice(self.words_dataset)\n",
        "            env = HangmanEnvironment(target_word)\n",
        "\n",
        "            state = env.reset()\n",
        "            total_reward = 0\n",
        "            steps = 0\n",
        "\n",
        "            while not env.done:\n",
        "                # Get HMM probabilities for current state\n",
        "                hmm_probs = self.agent.hmm_model.get_letter_probabilities(\n",
        "                    state['masked_word'], state['guessed_letters']\n",
        "                )\n",
        "\n",
        "                # Choose action\n",
        "                action = self.agent.get_action(state, training=True)\n",
        "\n",
        "                if action is None:\n",
        "                    break  # No available actions\n",
        "\n",
        "                # Take action\n",
        "                next_state, reward, done, info = env.step(action, hmm_probs)\n",
        "\n",
        "                # Store experience\n",
        "                self.agent.remember(state, action, reward, next_state, done, hmm_probs)\n",
        "\n",
        "                # Train\n",
        "                loss = self.agent.replay()\n",
        "\n",
        "                state = next_state\n",
        "                total_reward += reward\n",
        "                steps += 1\n",
        "\n",
        "            # Log episode statistics\n",
        "            training_stats['episode_rewards'].append(total_reward)\n",
        "            training_stats['episode_lengths'].append(steps)\n",
        "            training_stats['epsilon_values'].append(self.agent.epsilon)\n",
        "\n",
        "            # Print progress\n",
        "            if (episode + 1) % 100 == 0:\n",
        "                avg_reward = np.mean(training_stats['episode_rewards'][-100:])\n",
        "                avg_length = np.mean(training_stats['episode_lengths'][-100:])\n",
        "                print(f\"Episode {episode + 1}: Avg Reward = {avg_reward:.2f}, \"\n",
        "                      f\"Avg Length = {avg_length:.2f}, Epsilon = {self.agent.epsilon:.3f}\")\n",
        "\n",
        "            # Evaluate\n",
        "            if (episode + 1) % eval_every == 0:\n",
        "                success_rate = self.evaluate(num_eval_games, training=False)\n",
        "                training_stats['success_rates'].append(success_rate)\n",
        "                print(f\"ðŸŽ¯ Evaluation after {episode + 1} episodes: Success Rate = {success_rate:.3f}\")\n",
        "\n",
        "        return training_stats\n",
        "\n",
        "    def evaluate(self, num_games=100, training=False):\n",
        "        \"\"\"Evaluate the trained agent\"\"\"\n",
        "        wins = 0\n",
        "\n",
        "        for i in range(num_games):\n",
        "            target_word = random.choice(self.words_dataset)\n",
        "            env = HangmanEnvironment(target_word)\n",
        "            state = env.reset()\n",
        "\n",
        "            while not env.done:\n",
        "                action = self.agent.get_action(state, training=training)\n",
        "\n",
        "                if action is None:\n",
        "                    break\n",
        "\n",
        "                # Get HMM probabilities for reward calculation\n",
        "                hmm_probs = self.agent.hmm_model.get_letter_probabilities(\n",
        "                    state['masked_word'], state['guessed_letters']\n",
        "                )\n",
        "\n",
        "                next_state, reward, done, info = env.step(action, hmm_probs)\n",
        "                state = next_state\n",
        "\n",
        "            if env.won:\n",
        "                wins += 1\n",
        "\n",
        "        return wins / num_games\n",
        "\n",
        "# Step 10: Initialize and Train RL Agent\n",
        "print(\"ðŸŽ¯ Initializing RL Agent...\")\n",
        "\n",
        "# Create state encoder\n",
        "state_encoder = StateEncoder(word_length=15)\n",
        "\n",
        "# Initialize RL agent\n",
        "rl_agent = HangmanRLAgent(state_encoder, hangman_hmm, learning_rate=0.001, gamma=0.99)\n",
        "\n",
        "print(\"âœ… RL Agent Initialized!\")\n",
        "print(f\"   Input dimension: {rl_agent.input_dim}\")\n",
        "print(f\"   Output dimension: {rl_agent.output_dim}\")\n",
        "print(f\"   Initial epsilon: {rl_agent.epsilon}\")\n",
        "\n",
        "# Train RL agent\n",
        "print(\"\\nðŸš€ Starting RL Training...\")\n",
        "trainer = RLTrainer(rl_agent, words[:5000])  # Use first 5000 words for training\n",
        "\n",
        "# Train for a reasonable number of episodes\n",
        "training_stats = trainer.train(episodes=5000, eval_every=1000, num_eval_games=200)\n",
        "\n",
        "print(\"\\nâœ… RL Training Complete!\")\n",
        "\n",
        "# Step 11: Final Evaluation with RL Agent\n",
        "def rl_official_evaluation(rl_agent, test_words, num_games=2000, max_wrong_guesses=6):\n",
        "    \"\"\"Official evaluation using the trained RL agent\"\"\"\n",
        "    print(\"ðŸŽ¯ RL OFFICIAL EVALUATION - 2000 HANGMAN GAMES\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    results = {\n",
        "        'games_won': 0,\n",
        "        'games_lost': 0,\n",
        "        'total_wrong_guesses': 0,\n",
        "        'total_repeated_guesses': 0,\n",
        "        'games_details': [],\n",
        "        'score_breakdown': defaultdict(int)\n",
        "    }\n",
        "\n",
        "    for game_id in range(min(num_games, len(test_words))):\n",
        "        if game_id % 500 == 0:\n",
        "            print(f\"ðŸŽ® Played {game_id}/{num_games} games...\")\n",
        "\n",
        "        target_word = test_words[game_id]\n",
        "        env = HangmanEnvironment(target_word, max_wrong_guesses)\n",
        "        state = env.reset()\n",
        "\n",
        "        while not env.done:\n",
        "            action = rl_agent.get_action(state, training=False)\n",
        "\n",
        "            if action is None:\n",
        "                break\n",
        "\n",
        "            # Get HMM probabilities for reward (not used in evaluation, just for consistency)\n",
        "            hmm_probs = rl_agent.hmm_model.get_letter_probabilities(\n",
        "                state['masked_word'], state['guessed_letters']\n",
        "            )\n",
        "\n",
        "            next_state, reward, done, info = env.step(action, hmm_probs)\n",
        "            state = next_state\n",
        "\n",
        "        # Record results\n",
        "        game_result = {\n",
        "            'game_id': game_id + 1,\n",
        "            'target_word': target_word,\n",
        "            'won': env.won,\n",
        "            'wrong_guesses': env.wrong_guesses,\n",
        "            'repeated_guesses': len([l for l in env.guessed_letters if l not in env.revealed_letters]),\n",
        "            'total_guesses': len(env.guessed_letters),\n",
        "            'final_word': ''.join(env.masked_word)\n",
        "        }\n",
        "\n",
        "        if env.won:\n",
        "            results['games_won'] += 1\n",
        "        else:\n",
        "            results['games_lost'] += 1\n",
        "\n",
        "        results['total_wrong_guesses'] += env.wrong_guesses\n",
        "        results['total_repeated_guesses'] += game_result['repeated_guesses']\n",
        "        results['games_details'].append(game_result)\n",
        "\n",
        "    # Calculate official score\n",
        "    official_score = calculate_official_score(results, num_games)\n",
        "\n",
        "    # Print results\n",
        "    print_official_results(results, official_score, num_games)\n",
        "\n",
        "    return results, official_score\n",
        "\n",
        "# Run RL evaluation\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸ† RL AGENT FINAL EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "rl_results, rl_official_score = rl_official_evaluation(rl_agent, test_words_eval, num_games=2000)\n",
        "\n",
        "# Save RL results\n",
        "def save_rl_results(results, score, filename=\"rl_evaluation_results.txt\"):\n",
        "    \"\"\"Save RL evaluation results\"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"RL HANGMAN AGENT EVALUATION RESULTS\\\\n\")\n",
        "        f.write(\"=\" * 50 + \"\\\\n\\\\n\")\n",
        "\n",
        "        f.write(f\"FINAL SCORE: {score:.2f}\\\\n\\\\n\")\n",
        "\n",
        "        f.write(\"SUMMARY STATISTICS:\\\\n\")\n",
        "        f.write(f\"Games Played: {len(results['games_details'])}\\\\n\")\n",
        "        f.write(f\"Games Won: {results['games_won']}\\\\n\")\n",
        "        f.write(f\"Success Rate: {results['games_won']/len(results['games_details']):.3f}\\\\n\")\n",
        "        f.write(f\"Total Wrong Guesses: {results['total_wrong_guesses']}\\\\n\")\n",
        "        f.write(f\"Total Repeated Guesses: {results['total_repeated_guesses']}\\\\n\\\\n\")\n",
        "\n",
        "        f.write(\"FIRST 10 GAME RESULTS:\\\\n\")\n",
        "        for game in results['games_details'][:10]:\n",
        "            status = \"WON\" if game['won'] else \"LOST\"\n",
        "            f.write(f\"Game {game['game_id']}: {game['target_word']} -> {status} \"\n",
        "                   f\"(Wrong: {game['wrong_guesses']}, Repeated: {game['repeated_guesses']})\\\\n\")\n",
        "\n",
        "    print(f\"ðŸ“„ RL results saved to {filename}\")\n",
        "\n",
        "save_rl_results(rl_results, rl_official_score)\n",
        "\n",
        "# Compare with original HMM performance\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸ“Š PERFORMANCE COMPARISON: HMM vs RL\")\n",
        "print(\"=\"*70)\n",
        "print(f\"HMM Only - Final Score: {official_score:.2f}\")\n",
        "print(f\"RL Agent - Final Score: {rl_official_score:.2f}\")\n",
        "print(f\"Improvement: {rl_official_score - official_score:+.2f}\")\n",
        "\n",
        "# Final assessment\n",
        "assess_performance(rl_official_score)\n",
        "\n",
        "print(f\"\\\\nðŸŽ‰ RL EVALUATION COMPLETE!\")\n",
        "print(f\"ðŸ“Š Check 'rl_evaluation_results.txt' for detailed results\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9W3Dr0N1XGw",
        "outputId": "20aae5da-ae57-4576-bd22-5b4af29a13e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Initializing RL Agent...\n",
            "âœ… RL Agent Initialized!\n",
            "   Input dimension: 459\n",
            "   Output dimension: 26\n",
            "   Initial epsilon: 1.0\n",
            "\n",
            "ðŸš€ Starting RL Training...\n",
            "ðŸš€ Starting RL Training...\n",
            "Episodes: 5000, Evaluation every: 1000 episodes\n",
            "Episode 100: Avg Reward = -9.05, Avg Length = 9.47, Epsilon = 0.012\n",
            "Episode 200: Avg Reward = -7.52, Avg Length = 10.33, Epsilon = 0.010\n",
            "Episode 300: Avg Reward = -5.57, Avg Length = 10.35, Epsilon = 0.010\n",
            "Episode 400: Avg Reward = -5.13, Avg Length = 10.63, Epsilon = 0.010\n",
            "Episode 500: Avg Reward = -3.61, Avg Length = 11.02, Epsilon = 0.010\n",
            "Episode 600: Avg Reward = -3.47, Avg Length = 11.02, Epsilon = 0.010\n",
            "Episode 700: Avg Reward = -1.71, Avg Length = 10.85, Epsilon = 0.010\n",
            "Episode 800: Avg Reward = 2.58, Avg Length = 10.83, Epsilon = 0.010\n",
            "Episode 900: Avg Reward = 2.70, Avg Length = 11.04, Epsilon = 0.010\n",
            "Episode 1000: Avg Reward = -4.30, Avg Length = 10.95, Epsilon = 0.010\n",
            "ðŸŽ¯ Evaluation after 1000 episodes: Success Rate = 0.220\n",
            "Episode 1100: Avg Reward = 6.23, Avg Length = 11.20, Epsilon = 0.010\n",
            "Episode 1200: Avg Reward = 6.29, Avg Length = 11.44, Epsilon = 0.010\n",
            "Episode 1300: Avg Reward = 1.01, Avg Length = 10.63, Epsilon = 0.010\n",
            "Episode 1400: Avg Reward = 8.05, Avg Length = 10.68, Epsilon = 0.010\n",
            "Episode 1500: Avg Reward = 5.48, Avg Length = 11.20, Epsilon = 0.010\n",
            "Episode 1600: Avg Reward = 3.10, Avg Length = 11.30, Epsilon = 0.010\n",
            "Episode 1700: Avg Reward = 5.49, Avg Length = 11.56, Epsilon = 0.010\n",
            "Episode 1800: Avg Reward = 4.05, Avg Length = 11.27, Epsilon = 0.010\n",
            "Episode 1900: Avg Reward = 4.03, Avg Length = 11.08, Epsilon = 0.010\n",
            "Episode 2000: Avg Reward = 5.57, Avg Length = 11.31, Epsilon = 0.010\n",
            "ðŸŽ¯ Evaluation after 2000 episodes: Success Rate = 0.255\n",
            "Episode 2100: Avg Reward = 5.91, Avg Length = 11.20, Epsilon = 0.010\n",
            "Episode 2200: Avg Reward = 8.67, Avg Length = 10.80, Epsilon = 0.010\n",
            "Episode 2300: Avg Reward = 4.96, Avg Length = 11.19, Epsilon = 0.010\n",
            "Episode 2400: Avg Reward = 5.62, Avg Length = 10.77, Epsilon = 0.010\n",
            "Episode 2500: Avg Reward = 9.44, Avg Length = 11.41, Epsilon = 0.010\n",
            "Episode 2600: Avg Reward = 5.51, Avg Length = 11.39, Epsilon = 0.010\n",
            "Episode 2700: Avg Reward = 5.04, Avg Length = 11.29, Epsilon = 0.010\n",
            "Episode 2800: Avg Reward = 3.72, Avg Length = 11.04, Epsilon = 0.010\n",
            "Episode 2900: Avg Reward = 9.58, Avg Length = 11.07, Epsilon = 0.010\n",
            "Episode 3000: Avg Reward = 8.16, Avg Length = 11.23, Epsilon = 0.010\n",
            "ðŸŽ¯ Evaluation after 3000 episodes: Success Rate = 0.340\n",
            "Episode 3100: Avg Reward = 7.85, Avg Length = 10.83, Epsilon = 0.010\n",
            "Episode 3200: Avg Reward = 5.31, Avg Length = 10.95, Epsilon = 0.010\n",
            "Episode 3300: Avg Reward = 9.63, Avg Length = 11.12, Epsilon = 0.010\n",
            "Episode 3400: Avg Reward = 5.18, Avg Length = 10.75, Epsilon = 0.010\n",
            "Episode 3500: Avg Reward = 6.53, Avg Length = 11.27, Epsilon = 0.010\n",
            "Episode 3600: Avg Reward = 1.52, Avg Length = 10.60, Epsilon = 0.010\n",
            "Episode 3700: Avg Reward = 5.31, Avg Length = 10.88, Epsilon = 0.010\n",
            "Episode 3800: Avg Reward = 7.34, Avg Length = 11.18, Epsilon = 0.010\n",
            "Episode 3900: Avg Reward = 7.40, Avg Length = 11.14, Epsilon = 0.010\n",
            "Episode 4000: Avg Reward = 5.18, Avg Length = 10.90, Epsilon = 0.010\n",
            "ðŸŽ¯ Evaluation after 4000 episodes: Success Rate = 0.285\n",
            "Episode 4100: Avg Reward = 7.13, Avg Length = 11.17, Epsilon = 0.010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Test the HMM with example game states\n",
        "def test_hmm_predictions():\n",
        "    \"\"\"Test HMM predictions with various game states\"\"\"\n",
        "\n",
        "    test_cases = [\n",
        "        # (masked_word, guessed_letters, description)\n",
        "        (['_', '_', '_', '_', '_'], set(), \"Empty 5-letter word\"),\n",
        "        (['A', '_', '_', '_', '_'], set('A'), \"5-letter word starting with A\"),\n",
        "        (['_', '_', '_', 'E', '_'], set('E'), \"5-letter word with E at position 3\"),\n",
        "        (['_', '_', '_', '_', '_', '_'], set(), \"Empty 6-letter word\"),\n",
        "    ]\n",
        "\n",
        "    for masked_word, guessed_letters, description in test_cases:\n",
        "        print(f\"\\n{description}:\")\n",
        "        print(f\"Masked word: {' '.join(masked_word)}\")\n",
        "        print(f\"Guessed letters: {''.join(sorted(guessed_letters))}\")\n",
        "\n",
        "        probs = hangman_hmm.get_letter_probabilities(masked_word, guessed_letters)\n",
        "\n",
        "        # Show top 5 predictions\n",
        "        top_letters = sorted(probs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "        print(\"Top 5 letter predictions:\")\n",
        "        for letter, prob in top_letters:\n",
        "            print(f\"  {letter}: {prob:.4f}\")\n",
        "\n",
        "test_hmm_predictions()"
      ],
      "metadata": {
        "id": "z1APELXJbXA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f23005-8ac1-48d6-9871-13877e305b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Empty 5-letter word:\n",
            "Masked word: _ _ _ _ _\n",
            "Guessed letters: \n",
            "Top 5 letter predictions:\n",
            "  A: 0.1073\n",
            "  E: 0.0981\n",
            "  O: 0.0694\n",
            "  R: 0.0676\n",
            "  I: 0.0634\n",
            "\n",
            "5-letter word starting with A:\n",
            "Masked word: A _ _ _ _\n",
            "Guessed letters: A\n",
            "Top 5 letter predictions:\n",
            "  E: 0.1023\n",
            "  I: 0.0946\n",
            "  O: 0.0846\n",
            "  N: 0.0731\n",
            "  S: 0.0701\n",
            "\n",
            "5-letter word with E at position 3:\n",
            "Masked word: _ _ _ E _\n",
            "Guessed letters: E\n",
            "Top 5 letter predictions:\n",
            "  R: 0.1329\n",
            "  A: 0.0755\n",
            "  N: 0.0711\n",
            "  L: 0.0675\n",
            "  T: 0.0672\n",
            "\n",
            "Empty 6-letter word:\n",
            "Masked word: _ _ _ _ _ _\n",
            "Guessed letters: \n",
            "Top 5 letter predictions:\n",
            "  E: 0.1116\n",
            "  A: 0.1021\n",
            "  R: 0.0712\n",
            "  I: 0.0709\n",
            "  N: 0.0615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: OFFICIAL EVALUATION - 2000 Games with Official Scoring Formula\n",
        "def official_evaluation(hangman_hmm, test_words, num_games=2000, max_wrong_guesses=6):\n",
        "    \"\"\"\n",
        "    Official evaluation as per problem statement\n",
        "    Plays 2000 games and calculates the official score\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from collections import defaultdict\n",
        "\n",
        "    print(\"ðŸŽ¯ OFFICIAL EVALUATION - 2000 HANGMAN GAMES\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Playing {num_games} games with {max_wrong_guesses} wrong guesses allowed per game\")\n",
        "    print()\n",
        "\n",
        "    # Initialize metrics\n",
        "    results = {\n",
        "        'games_won': 0,\n",
        "        'games_lost': 0,\n",
        "        'total_wrong_guesses': 0,\n",
        "        'total_repeated_guesses': 0,\n",
        "        'games_details': [],\n",
        "        'score_breakdown': defaultdict(int)\n",
        "    }\n",
        "\n",
        "    # Play specified number of games\n",
        "    for game_id in range(min(num_games, len(test_words))):\n",
        "        if game_id % 500 == 0:\n",
        "            print(f\"ðŸŽ® Played {game_id}/{num_games} games...\")\n",
        "\n",
        "        target_word = test_words[game_id]\n",
        "        game_result = play_single_game(hangman_hmm, target_word, max_wrong_guesses, game_id + 1)\n",
        "\n",
        "        # Aggregate results\n",
        "        if game_result['won']:\n",
        "            results['games_won'] += 1\n",
        "        else:\n",
        "            results['games_lost'] += 1\n",
        "\n",
        "        results['total_wrong_guesses'] += game_result['wrong_guesses']\n",
        "        results['total_repeated_guesses'] += game_result['repeated_guesses']\n",
        "        results['games_details'].append(game_result)\n",
        "\n",
        "    # Calculate official score\n",
        "    official_score = calculate_official_score(results, num_games)\n",
        "\n",
        "    # Print comprehensive results\n",
        "    print_official_results(results, official_score, num_games)\n",
        "\n",
        "    return results, official_score\n",
        "\n",
        "def play_single_game(hangman_hmm, target_word, max_wrong_guesses, game_id):\n",
        "    \"\"\"\n",
        "    Play a single Hangman game and return detailed results\n",
        "    \"\"\"\n",
        "    masked_word = ['_'] * len(target_word)\n",
        "    guessed_letters = set()\n",
        "    wrong_guesses = 0\n",
        "    repeated_guesses = 0\n",
        "    game_log = []\n",
        "\n",
        "    # Game loop\n",
        "    while wrong_guesses < max_wrong_guesses and '_' in masked_word:\n",
        "        # Get letter probabilities from HMM\n",
        "        probs = hangman_hmm.get_letter_probabilities(masked_word, guessed_letters)\n",
        "\n",
        "        if not probs:\n",
        "            # No probabilities available, use fallback\n",
        "            available_letters = [chr(i) for i in range(65, 91) if chr(i) not in guessed_letters]\n",
        "            if not available_letters:\n",
        "                break\n",
        "            next_letter = available_letters[0]\n",
        "        else:\n",
        "            # Choose letter with highest probability\n",
        "            next_letter = max(probs.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "        # Check for repeated guess\n",
        "        if next_letter in guessed_letters:\n",
        "            repeated_guesses += 1\n",
        "            game_log.append(f\"Repeated guess: {next_letter}\")\n",
        "            continue\n",
        "\n",
        "        # Add to guessed letters\n",
        "        guessed_letters.add(next_letter)\n",
        "\n",
        "        # Check if letter is in target word\n",
        "        if next_letter in target_word:\n",
        "            # Update masked word\n",
        "            for i, char in enumerate(target_word):\n",
        "                if char == next_letter:\n",
        "                    masked_word[i] = next_letter\n",
        "            game_log.append(f\"Correct: {next_letter} -> {' '.join(masked_word)}\")\n",
        "        else:\n",
        "            wrong_guesses += 1\n",
        "            game_log.append(f\"Wrong: {next_letter} ({wrong_guesses}/{max_wrong_guesses} wrong)\")\n",
        "\n",
        "    # Determine game outcome\n",
        "    won = '_' not in masked_word\n",
        "    actual_word = ''.join(target_word)\n",
        "    guessed_word = ''.join(masked_word)\n",
        "\n",
        "    return {\n",
        "        'game_id': game_id,\n",
        "        'target_word': actual_word,\n",
        "        'won': won,\n",
        "        'wrong_guesses': wrong_guesses,\n",
        "        'repeated_guesses': repeated_guesses,\n",
        "        'total_guesses': len(guessed_letters),\n",
        "        'final_word': guessed_word,\n",
        "        'game_log': game_log\n",
        "    }\n",
        "\n",
        "def calculate_official_score(results, num_games):\n",
        "    \"\"\"\n",
        "    Calculate official score using the formula:\n",
        "    Final Score = (Success Rate * 2000) - (Total Wrong Guesses * 5) - (Total Repeated Guesses * 2)\n",
        "    \"\"\"\n",
        "    success_rate = results['games_won'] / num_games\n",
        "    total_wrong_guesses = results['total_wrong_guesses']\n",
        "    total_repeated_guesses = results['total_repeated_guesses']\n",
        "\n",
        "    score = (success_rate * 2000) - (total_wrong_guesses * 5) - (total_repeated_guesses * 2)\n",
        "\n",
        "    # Store breakdown for analysis\n",
        "    results['score_breakdown']['success_component'] = success_rate * 2000\n",
        "    results['score_breakdown']['wrong_penalty'] = total_wrong_guesses * 5\n",
        "    results['score_breakdown']['repeated_penalty'] = total_repeated_guesses * 2\n",
        "    results['score_breakdown']['success_rate'] = success_rate\n",
        "    results['score_breakdown']['total_games'] = num_games\n",
        "\n",
        "    return score\n",
        "\n",
        "def print_official_results(results, official_score, num_games):\n",
        "    \"\"\"\n",
        "    Print comprehensive evaluation results\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"ðŸ† OFFICIAL EVALUATION RESULTS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Basic statistics\n",
        "    print(f\"ðŸ“Š GAME STATISTICS:\")\n",
        "    print(f\"   Total Games Played: {num_games}\")\n",
        "    print(f\"   Games Won: {results['games_won']}\")\n",
        "    print(f\"   Games Lost: {results['games_lost']}\")\n",
        "    print(f\"   Success Rate: {results['games_won']/num_games:.3f} ({results['games_won']}/{num_games})\")\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ PERFORMANCE METRICS:\")\n",
        "    print(f\"   Total Wrong Guesses: {results['total_wrong_guesses']}\")\n",
        "    print(f\"   Total Repeated Guesses: {results['total_repeated_guesses']}\")\n",
        "    print(f\"   Average Wrong Guesses per Game: {results['total_wrong_guesses']/num_games:.2f}\")\n",
        "    print(f\"   Average Repeated Guesses per Game: {results['total_repeated_guesses']/num_games:.2f}\")\n",
        "\n",
        "    print(f\"\\nðŸ’° SCORE BREAKDOWN:\")\n",
        "    print(f\"   Success Component: {results['score_breakdown']['success_component']:.2f}\")\n",
        "    print(f\"   Wrong Guesses Penalty: -{results['score_breakdown']['wrong_penalty']:.2f}\")\n",
        "    print(f\"   Repeated Guesses Penalty: -{results['score_breakdown']['repeated_penalty']:.2f}\")\n",
        "    print(f\"   FINAL SCORE: {official_score:.2f}\")\n",
        "\n",
        "    # Additional analysis\n",
        "    print(f\"\\nðŸ“ˆ ADDITIONAL INSIGHTS:\")\n",
        "\n",
        "    # Word length analysis\n",
        "    won_by_length = defaultdict(int)\n",
        "    lost_by_length = defaultdict(int)\n",
        "\n",
        "    for game in results['games_details']:\n",
        "        length = len(game['target_word'])\n",
        "        if game['won']:\n",
        "            won_by_length[length] += 1\n",
        "        else:\n",
        "            lost_by_length[length] += 1\n",
        "\n",
        "    print(f\"   Performance by Word Length:\")\n",
        "    for length in sorted(set(won_by_length.keys()) | set(lost_by_length.keys())):\n",
        "        won = won_by_length[length]\n",
        "        total = won + lost_by_length.get(length, 0)\n",
        "        if total > 0:\n",
        "            success_rate = won / total\n",
        "            print(f\"     Length {length}: {won}/{total} won ({success_rate:.1%})\")\n",
        "\n",
        "    # Efficiency analysis\n",
        "    total_correct_guesses = sum(game['total_guesses'] - game['wrong_guesses'] for game in results['games_details'])\n",
        "    total_guesses = sum(game['total_guesses'] for game in results['games_details'])\n",
        "    efficiency = total_correct_guesses / total_guesses if total_guesses > 0 else 0\n",
        "\n",
        "    print(f\"   Guess Efficiency: {efficiency:.1%} ({total_correct_guesses}/{total_guesses} correct guesses)\")\n",
        "\n",
        "# Load test words for evaluation\n",
        "def load_test_words_for_evaluation(file_path, num_words=2000):\n",
        "    \"\"\"Load test words for official evaluation\"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        words = [line.strip().upper() for line in f if line.strip()]\n",
        "\n",
        "    words = [word for word in words if word.isalpha()]\n",
        "\n",
        "    if len(words) < num_words:\n",
        "        print(f\"âš ï¸  Warning: Only {len(words)} test words available, using all of them\")\n",
        "        return words\n",
        "    else:\n",
        "        return words[:num_words]\n",
        "\n",
        "# ðŸš€ RUN OFFICIAL EVALUATION\n",
        "print(\"Loading test words for official evaluation...\")\n",
        "test_words_eval = load_test_words_for_evaluation('test.txt', num_words=2000)\n",
        "\n",
        "print(f\"Loaded {len(test_words_eval)} test words for evaluation\")\n",
        "print(\"Starting official 2000-game evaluation...\")\n",
        "\n",
        "# Run the official evaluation\n",
        "results, official_score = official_evaluation(hangman_hmm, test_words_eval, num_games=2000, max_wrong_guesses=6)\n",
        "\n",
        "# Save detailed results\n",
        "def save_detailed_results(results, official_score, filename=\"evaluation_results.txt\"):\n",
        "    \"\"\"Save detailed evaluation results to file\"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"OFFICIAL HANGMAN EVALUATION RESULTS\\n\")\n",
        "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "        f.write(f\"FINAL SCORE: {official_score:.2f}\\n\\n\")\n",
        "\n",
        "        f.write(\"SUMMARY STATISTICS:\\n\")\n",
        "        f.write(f\"Games Played: {results['score_breakdown']['total_games']}\\n\")\n",
        "        f.write(f\"Games Won: {results['games_won']}\\n\")\n",
        "        f.write(f\"Success Rate: {results['score_breakdown']['success_rate']:.3f}\\n\")\n",
        "        f.write(f\"Total Wrong Guesses: {results['total_wrong_guesses']}\\n\")\n",
        "        f.write(f\"Total Repeated Guesses: {results['total_repeated_guesses']}\\n\\n\")\n",
        "\n",
        "        f.write(\"SCORE BREAKDOWN:\\n\")\n",
        "        f.write(f\"Success Component: {results['score_breakdown']['success_component']:.2f}\\n\")\n",
        "        f.write(f\"Wrong Guesses Penalty: -{results['score_breakdown']['wrong_penalty']:.2f}\\n\")\n",
        "        f.write(f\"Repeated Guesses Penalty: -{results['score_breakdown']['repeated_penalty']:.2f}\\n\\n\")\n",
        "\n",
        "        f.write(\"FIRST 10 GAME RESULTS:\\n\")\n",
        "        for game in results['games_details'][:10]:\n",
        "            status = \"WON\" if game['won'] else \"LOST\"\n",
        "            f.write(f\"Game {game['game_id']}: {game['target_word']} -> {status} \"\n",
        "                   f\"(Wrong: {game['wrong_guesses']}, Repeated: {game['repeated_guesses']})\\n\")\n",
        "\n",
        "    print(f\"ðŸ“„ Detailed results saved to {filename}\")\n",
        "\n",
        "# Save results\n",
        "save_detailed_results(results, official_score)\n",
        "\n",
        "# Performance assessment\n",
        "def assess_performance(score):\n",
        "    \"\"\"Assess the performance based on final score\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"ðŸ“‹ PERFORMANCE ASSESSMENT\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if score >= 1500:\n",
        "        assessment = \"EXCELLENT ðŸ†\"\n",
        "        feedback = \"Outstanding performance! Your agent is highly efficient.\"\n",
        "    elif score >= 1000:\n",
        "        assessment = \"VERY GOOD ðŸ¥ˆ\"\n",
        "        feedback = \"Strong performance with good success rate and efficiency.\"\n",
        "    elif score >= 500:\n",
        "        assessment = \"GOOD ðŸ¥‰\"\n",
        "        feedback = \"Solid performance with room for optimization.\"\n",
        "    elif score >= 0:\n",
        "        assessment = \"FAIR ðŸ“Š\"\n",
        "        feedback = \"Basic functionality achieved, needs improvement in efficiency.\"\n",
        "    else:\n",
        "        assessment = \"NEEDS WORK ðŸ”§\"\n",
        "        feedback = \"Focus on improving success rate and reducing wrong guesses.\"\n",
        "\n",
        "    print(f\"FINAL SCORE: {score:.2f}\")\n",
        "    print(f\"ASSESSMENT: {assessment}\")\n",
        "    print(f\"FEEDBACK: {feedback}\")\n",
        "\n",
        "# Final assessment\n",
        "assess_performance(official_score)\n",
        "\n",
        "print(f\"\\nðŸŽ‰ EVALUATION COMPLETE!\")\n",
        "print(f\"ðŸ“Š Check 'evaluation_results.txt' for detailed game-by-game results\")"
      ],
      "metadata": {
        "id": "4wanux8QS0PJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3be4a79-cc8e-4a6f-b23f-4f7840ac3a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test words for official evaluation...\n",
            "Loaded 2000 test words for evaluation\n",
            "Starting official 2000-game evaluation...\n",
            "ðŸŽ¯ OFFICIAL EVALUATION - 2000 HANGMAN GAMES\n",
            "============================================================\n",
            "Playing 2000 games with 6 wrong guesses allowed per game\n",
            "\n",
            "ðŸŽ® Played 0/2000 games...\n",
            "ðŸŽ® Played 500/2000 games...\n",
            "ðŸŽ® Played 1000/2000 games...\n",
            "ðŸŽ® Played 1500/2000 games...\n",
            "\n",
            "======================================================================\n",
            "ðŸ† OFFICIAL EVALUATION RESULTS\n",
            "======================================================================\n",
            "ðŸ“Š GAME STATISTICS:\n",
            "   Total Games Played: 2000\n",
            "   Games Won: 703\n",
            "   Games Lost: 1297\n",
            "   Success Rate: 0.351 (703/2000)\n",
            "\n",
            "ðŸŽ¯ PERFORMANCE METRICS:\n",
            "   Total Wrong Guesses: 10213\n",
            "   Total Repeated Guesses: 0\n",
            "   Average Wrong Guesses per Game: 5.11\n",
            "   Average Repeated Guesses per Game: 0.00\n",
            "\n",
            "ðŸ’° SCORE BREAKDOWN:\n",
            "   Success Component: 703.00\n",
            "   Wrong Guesses Penalty: -51065.00\n",
            "   Repeated Guesses Penalty: -0.00\n",
            "   FINAL SCORE: -50362.00\n",
            "\n",
            "ðŸ“ˆ ADDITIONAL INSIGHTS:\n",
            "   Performance by Word Length:\n",
            "     Length 2: 0/2 won (0.0%)\n",
            "     Length 3: 0/9 won (0.0%)\n",
            "     Length 4: 4/37 won (10.8%)\n",
            "     Length 5: 10/91 won (11.0%)\n",
            "     Length 6: 24/138 won (17.4%)\n",
            "     Length 7: 39/205 won (19.0%)\n",
            "     Length 8: 63/246 won (25.6%)\n",
            "     Length 9: 75/274 won (27.4%)\n",
            "     Length 10: 108/282 won (38.3%)\n",
            "     Length 11: 102/226 won (45.1%)\n",
            "     Length 12: 84/164 won (51.2%)\n",
            "     Length 13: 67/128 won (52.3%)\n",
            "     Length 14: 43/86 won (50.0%)\n",
            "     Length 15: 35/47 won (74.5%)\n",
            "     Length 16: 25/33 won (75.8%)\n",
            "     Length 17: 13/17 won (76.5%)\n",
            "     Length 18: 6/8 won (75.0%)\n",
            "     Length 19: 3/3 won (100.0%)\n",
            "     Length 20: 1/2 won (50.0%)\n",
            "     Length 21: 0/1 won (0.0%)\n",
            "     Length 22: 1/1 won (100.0%)\n",
            "   Guess Efficiency: 55.2% (12572/22785 correct guesses)\n",
            "ðŸ“„ Detailed results saved to evaluation_results.txt\n",
            "\n",
            "==================================================\n",
            "ðŸ“‹ PERFORMANCE ASSESSMENT\n",
            "==================================================\n",
            "FINAL SCORE: -50362.00\n",
            "ASSESSMENT: NEEDS WORK ðŸ”§\n",
            "FEEDBACK: Focus on improving success rate and reducing wrong guesses.\n",
            "\n",
            "ðŸŽ‰ EVALUATION COMPLETE!\n",
            "ðŸ“Š Check 'evaluation_results.txt' for detailed game-by-game results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: UNIVERSAL EVALUATION - Works for both HMM and RL agents\n",
        "def universal_evaluation(agent, test_words, num_games=2000, max_wrong_guesses=6, agent_type=\"hmm\"):\n",
        "    \"\"\"\n",
        "    Universal evaluation that works for both HMM and RL agents\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from collections import defaultdict\n",
        "\n",
        "    print(f\"ðŸŽ¯ UNIVERSAL EVALUATION - {num_games} HANGMAN GAMES\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Agent Type: {agent_type.upper()}\")\n",
        "    print(f\"Playing {num_games} games with {max_wrong_guesses} wrong guesses allowed per game\")\n",
        "    print()\n",
        "\n",
        "    # Initialize metrics\n",
        "    results = {\n",
        "        'games_won': 0,\n",
        "        'games_lost': 0,\n",
        "        'total_wrong_guesses': 0,\n",
        "        'total_repeated_guesses': 0,\n",
        "        'games_details': [],\n",
        "        'score_breakdown': defaultdict(int)\n",
        "    }\n",
        "\n",
        "    # Play specified number of games\n",
        "    for game_id in range(min(num_games, len(test_words))):\n",
        "        if game_id % 500 == 0:\n",
        "            print(f\"ðŸŽ® Played {game_id}/{num_games} games...\")\n",
        "\n",
        "        target_word = test_words[game_id]\n",
        "\n",
        "        if agent_type.lower() == \"hmm\":\n",
        "            game_result = play_single_game_hmm(agent, target_word, max_wrong_guesses, game_id + 1)\n",
        "        else:  # RL agent\n",
        "            game_result = play_single_game_rl(agent, target_word, max_wrong_guesses, game_id + 1)\n",
        "\n",
        "        # Aggregate results\n",
        "        if game_result['won']:\n",
        "            results['games_won'] += 1\n",
        "        else:\n",
        "            results['games_lost'] += 1\n",
        "\n",
        "        results['total_wrong_guesses'] += game_result['wrong_guesses']\n",
        "        results['total_repeated_guesses'] += game_result['repeated_guesses']\n",
        "        results['games_details'].append(game_result)\n",
        "\n",
        "    # Calculate official score\n",
        "    official_score = calculate_official_score(results, num_games)\n",
        "\n",
        "    # Print comprehensive results\n",
        "    print_universal_results(results, official_score, num_games, agent_type)\n",
        "\n",
        "    return results, official_score\n",
        "\n",
        "def play_single_game_hmm(hmm_agent, target_word, max_wrong_guesses, game_id):\n",
        "    \"\"\"\n",
        "    Play a single game with HMM agent (original logic)\n",
        "    \"\"\"\n",
        "    masked_word = ['_'] * len(target_word)\n",
        "    guessed_letters = set()\n",
        "    wrong_guesses = 0\n",
        "    repeated_guesses = 0\n",
        "    game_log = []\n",
        "\n",
        "    # Game loop\n",
        "    while wrong_guesses < max_wrong_guesses and '_' in masked_word:\n",
        "        # Get letter probabilities from HMM\n",
        "        probs = hmm_agent.get_letter_probabilities(masked_word, guessed_letters)\n",
        "\n",
        "        if not probs:\n",
        "            # No probabilities available, use fallback\n",
        "            available_letters = [chr(i) for i in range(65, 91) if chr(i) not in guessed_letters]\n",
        "            if not available_letters:\n",
        "                break\n",
        "            next_letter = available_letters[0]\n",
        "        else:\n",
        "            # Choose letter with highest probability\n",
        "            next_letter = max(probs.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "        # Check for repeated guess\n",
        "        if next_letter in guessed_letters:\n",
        "            repeated_guesses += 1\n",
        "            game_log.append(f\"Repeated guess: {next_letter}\")\n",
        "            continue\n",
        "\n",
        "        # Add to guessed letters\n",
        "        guessed_letters.add(next_letter)\n",
        "\n",
        "        # Check if letter is in target word\n",
        "        if next_letter in target_word:\n",
        "            # Update masked word\n",
        "            for i, char in enumerate(target_word):\n",
        "                if char == next_letter:\n",
        "                    masked_word[i] = next_letter\n",
        "            game_log.append(f\"Correct: {next_letter} -> {' '.join(masked_word)}\")\n",
        "        else:\n",
        "            wrong_guesses += 1\n",
        "            game_log.append(f\"Wrong: {next_letter} ({wrong_guesses}/{max_wrong_guesses} wrong)\")\n",
        "\n",
        "    # Determine game outcome\n",
        "    won = '_' not in masked_word\n",
        "    actual_word = ''.join(target_word)\n",
        "    guessed_word = ''.join(masked_word)\n",
        "\n",
        "    return {\n",
        "        'game_id': game_id,\n",
        "        'target_word': actual_word,\n",
        "        'won': won,\n",
        "        'wrong_guesses': wrong_guesses,\n",
        "        'repeated_guesses': repeated_guesses,\n",
        "        'total_guesses': len(guessed_letters),\n",
        "        'final_word': guessed_word,\n",
        "        'game_log': game_log\n",
        "    }\n",
        "\n",
        "def play_single_game_rl(rl_agent, target_word, max_wrong_guesses, game_id):\n",
        "    \"\"\"\n",
        "    Play a single game with RL agent\n",
        "    \"\"\"\n",
        "    # Create environment for RL agent\n",
        "    env = HangmanEnvironment(target_word, max_wrong_guesses)\n",
        "    state = env.reset()\n",
        "\n",
        "    game_log = []\n",
        "    repeated_guesses = 0\n",
        "\n",
        "    # Game loop\n",
        "    while not env.done:\n",
        "        # RL agent chooses action directly\n",
        "        action = rl_agent.get_action(state, training=False)\n",
        "\n",
        "        if action is None:\n",
        "            break\n",
        "\n",
        "        # Check for repeated guess (RL agents shouldn't do this, but just in case)\n",
        "        if action in env.guessed_letters:\n",
        "            repeated_guesses += 1\n",
        "            game_log.append(f\"Repeated guess: {action}\")\n",
        "            continue\n",
        "\n",
        "        # Get HMM probabilities for logging (if available)\n",
        "        hmm_probs = None\n",
        "        if hasattr(rl_agent, 'hmm_model'):\n",
        "            hmm_probs = rl_agent.hmm_model.get_letter_probabilities(\n",
        "                state['masked_word'], state['guessed_letters']\n",
        "            )\n",
        "\n",
        "        # Take action in environment\n",
        "        next_state, reward, done, info = env.step(action, hmm_probs)\n",
        "\n",
        "        # Log the result\n",
        "        if info.get('correct', False):\n",
        "            game_log.append(f\"Correct: {action} -> {' '.join(next_state['masked_word'])}\")\n",
        "        else:\n",
        "            if not info.get('repeated', False):\n",
        "                game_log.append(f\"Wrong: {action} ({env.wrong_guesses}/{max_wrong_guesses} wrong)\")\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    # Determine game outcome\n",
        "    won = env.won\n",
        "    actual_word = target_word\n",
        "    guessed_word = ''.join(env.masked_word)\n",
        "\n",
        "    return {\n",
        "        'game_id': game_id,\n",
        "        'target_word': actual_word,\n",
        "        'won': won,\n",
        "        'wrong_guesses': env.wrong_guesses,\n",
        "        'repeated_guesses': repeated_guesses,\n",
        "        'total_guesses': len(env.guessed_letters),\n",
        "        'final_word': guessed_word,\n",
        "        'game_log': game_log\n",
        "    }\n",
        "\n",
        "def calculate_official_score(results, num_games):\n",
        "    \"\"\"Same as before\"\"\"\n",
        "    success_rate = results['games_won'] / num_games\n",
        "    total_wrong_guesses = results['total_wrong_guesses']\n",
        "    total_repeated_guesses = results['total_repeated_guesses']\n",
        "\n",
        "    score = (success_rate * 2000) - (total_wrong_guesses * 5) - (total_repeated_guesses * 2)\n",
        "\n",
        "    # Store breakdown for analysis\n",
        "    results['score_breakdown']['success_component'] = success_rate * 2000\n",
        "    results['score_breakdown']['wrong_penalty'] = total_wrong_guesses * 5\n",
        "    results['score_breakdown']['repeated_penalty'] = total_repeated_guesses * 2\n",
        "    results['score_breakdown']['success_rate'] = success_rate\n",
        "    results['score_breakdown']['total_games'] = num_games\n",
        "\n",
        "    return score\n",
        "\n",
        "def print_universal_results(results, official_score, num_games, agent_type):\n",
        "    \"\"\"\n",
        "    Print comprehensive evaluation results for any agent type\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"ðŸ† {agent_type.upper()} AGENT EVALUATION RESULTS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Basic statistics\n",
        "    print(f\"ðŸ“Š GAME STATISTICS:\")\n",
        "    print(f\"   Agent Type: {agent_type.upper()}\")\n",
        "    print(f\"   Total Games Played: {num_games}\")\n",
        "    print(f\"   Games Won: {results['games_won']}\")\n",
        "    print(f\"   Games Lost: {results['games_lost']}\")\n",
        "    print(f\"   Success Rate: {results['games_won']/num_games:.3f} ({results['games_won']}/{num_games})\")\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ PERFORMANCE METRICS:\")\n",
        "    print(f\"   Total Wrong Guesses: {results['total_wrong_guesses']}\")\n",
        "    print(f\"   Total Repeated Guesses: {results['total_repeated_guesses']}\")\n",
        "    print(f\"   Average Wrong Guesses per Game: {results['total_wrong_guesses']/num_games:.2f}\")\n",
        "    print(f\"   Average Repeated Guesses per Game: {results['total_repeated_guesses']/num_games:.2f}\")\n",
        "\n",
        "    print(f\"\\nðŸ’° SCORE BREAKDOWN:\")\n",
        "    print(f\"   Success Component: {results['score_breakdown']['success_component']:.2f}\")\n",
        "    print(f\"   Wrong Guesses Penalty: -{results['score_breakdown']['wrong_penalty']:.2f}\")\n",
        "    print(f\"   Repeated Guesses Penalty: -{results['score_breakdown']['repeated_penalty']:.2f}\")\n",
        "    print(f\"   FINAL SCORE: {official_score:.2f}\")\n",
        "\n",
        "    # Additional analysis\n",
        "    print(f\"\\nðŸ“ˆ ADDITIONAL INSIGHTS:\")\n",
        "\n",
        "    # Word length analysis\n",
        "    from collections import defaultdict\n",
        "    won_by_length = defaultdict(int)\n",
        "    lost_by_length = defaultdict(int)\n",
        "\n",
        "    for game in results['games_details']:\n",
        "        length = len(game['target_word'])\n",
        "        if game['won']:\n",
        "            won_by_length[length] += 1\n",
        "        else:\n",
        "            lost_by_length[length] += 1\n",
        "\n",
        "    print(f\"   Performance by Word Length:\")\n",
        "    for length in sorted(set(won_by_length.keys()) | set(lost_by_length.keys())):\n",
        "        won = won_by_length[length]\n",
        "        total = won + lost_by_length.get(length, 0)\n",
        "        if total > 0:\n",
        "            success_rate = won / total\n",
        "            print(f\"     Length {length}: {won}/{total} won ({success_rate:.1%})\")\n",
        "\n",
        "    # Efficiency analysis\n",
        "    total_correct_guesses = sum(game['total_guesses'] - game['wrong_guesses'] for game in results['games_details'])\n",
        "    total_guesses = sum(game['total_guesses'] for game in results['games_details'])\n",
        "    efficiency = total_correct_guesses / total_guesses if total_guesses > 0 else 0\n",
        "\n",
        "    print(f\"   Guess Efficiency: {efficiency:.1%} ({total_correct_guesses}/{total_guesses} correct guesses)\")\n",
        "\n",
        "# ðŸš€ RUN UNIVERSAL EVALUATION FOR BOTH AGENT TYPES\n",
        "def evaluate_all_agents(hmm_agent, rl_agents_dict, test_words, num_games=2000):\n",
        "    \"\"\"\n",
        "    Evaluate all agents and compare performance\n",
        "    \"\"\"\n",
        "    print(\"ðŸ¤– COMPREHENSIVE AGENT EVALUATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    all_results = {}\n",
        "\n",
        "    # Evaluate HMM agent\n",
        "    print(\"\\nðŸ” Evaluating HMM Agent...\")\n",
        "    hmm_results, hmm_score = universal_evaluation(\n",
        "        hmm_agent, test_words, num_games, agent_type=\"hmm\"\n",
        "    )\n",
        "    all_results['HMM_Agent'] = {'results': hmm_results, 'score': hmm_score}\n",
        "\n",
        "    # Evaluate each RL agent\n",
        "    for rl_agent_name, rl_agent in rl_agents_dict.items():\n",
        "        print(f\"\\nðŸ” Evaluating {rl_agent_name}...\")\n",
        "        rl_results, rl_score = universal_evaluation(\n",
        "            rl_agent, test_words, num_games, agent_type=rl_agent_name.lower()\n",
        "        )\n",
        "        all_results[rl_agent_name] = {'results': rl_results, 'score': rl_score}\n",
        "\n",
        "    # Print comparison\n",
        "    print_comparison(all_results)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def print_comparison(all_results):\n",
        "    \"\"\"\n",
        "    Print comparison between all agents\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"ðŸ† FINAL AGENT COMPARISON\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    best_score = -float('inf')\n",
        "    best_agent = None\n",
        "\n",
        "    for agent_name, data in all_results.items():\n",
        "        score = data['score']\n",
        "        success_rate = data['results']['score_breakdown']['success_rate']\n",
        "\n",
        "        print(f\"\\n{agent_name}:\")\n",
        "        print(f\"  Success Rate: {success_rate:.3f} ({data['results']['games_won']}/2000)\")\n",
        "        print(f\"  Final Score: {score:.2f}\")\n",
        "        print(f\"  Avg Wrong Guesses: {data['results']['total_wrong_guesses']/2000:.2f}\")\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_agent = agent_name\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ BEST PERFORMING AGENT: {best_agent}\")\n",
        "    print(f\"ðŸ† BEST SCORE: {best_score:.2f}\")\n",
        "\n",
        "# Usage Example:\n",
        "# After your current HMM evaluation, add this:\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸš€ STARTING RL AGENT EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Your RL agents (assuming you've trained them)\n",
        "rl_agents_dict = {\n",
        "    \"DQN_Agent\": dqn_agent,\n",
        "    \"QTable_Agent\": qtable_agent\n",
        "}\n",
        "\n",
        "# Evaluate all agents\n",
        "all_agent_results = evaluate_all_agents(\n",
        "    hangman_hmm,\n",
        "    rl_agents_dict,\n",
        "    test_words_eval,\n",
        "    num_games=2000\n",
        ")\n",
        "\n",
        "print(\"\\nðŸŽ‰ UNIVERSAL EVALUATION COMPLETE!\")"
      ],
      "metadata": {
        "id": "Dwlezhdg9FlL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}